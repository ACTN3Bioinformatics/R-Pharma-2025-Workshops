<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>descriptions – R/Pharma 2025</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-7fd3a81f91483ada774992105079aaf8.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">R/Pharma 2025</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./workshops/index.html"> 
<span class="menu-text">Workshops</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./presentations/index.html"> 
<span class="menu-text">Presentations</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-insights" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Insights</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-insights">    
        <li>
    <a class="dropdown-item" href="./summary/trends-insights.html">
 <span class="dropdown-text">Trends &amp; Analysis</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./summary/tools-catalog.html">
 <span class="dropdown-text">Tools Catalog</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./summary/career-insights.html">
 <span class="dropdown-text">Career Insights</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="./about.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/ACTN3Bioinformatics/R-Pharma-2025-Workshops"> <i class="bi bi-github" role="img" aria-label="GitHub">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#r-pharma-2025-workshops" id="toc-r-pharma-2025-workshops" class="nav-link active" data-scroll-target="#r-pharma-2025-workshops">R-Pharma-2025-Workshops</a>
  <ul class="collapse">
  <li><a href="#workshop-flexible-clinical-trial-design-simulation-and-analysis-with-the-r-package-rpact" id="toc-workshop-flexible-clinical-trial-design-simulation-and-analysis-with-the-r-package-rpact" class="nav-link" data-scroll-target="#workshop-flexible-clinical-trial-design-simulation-and-analysis-with-the-r-package-rpact"><strong>WORKSHOP: Flexible Clinical Trial Design, Simulation, and Analysis with the R Package rpact</strong></a></li>
  <li><a href="#workshop-debugging-stan-programs" id="toc-workshop-debugging-stan-programs" class="nav-link" data-scroll-target="#workshop-debugging-stan-programs"><strong>WORKSHOP: Debugging Stan Programs</strong></a></li>
  <li><a href="#workshop-introduction-to-building-better-r-packages" id="toc-workshop-introduction-to-building-better-r-packages" class="nav-link" data-scroll-target="#workshop-introduction-to-building-better-r-packages"><strong>WORKSHOP: Introduction to building (better) R packages</strong></a></li>
  <li><a href="#workshop-getting-started-with-llm-apis-in-r" id="toc-workshop-getting-started-with-llm-apis-in-r" class="nav-link" data-scroll-target="#workshop-getting-started-with-llm-apis-in-r"><strong>WORKSHOP: Getting Started with LLM APIs in R</strong></a></li>
  <li><a href="#workshop-hands-on-with-cardinal-harmonizing-clinical-reporting-with-opensource-tlgs" id="toc-workshop-hands-on-with-cardinal-harmonizing-clinical-reporting-with-opensource-tlgs" class="nav-link" data-scroll-target="#workshop-hands-on-with-cardinal-harmonizing-clinical-reporting-with-opensource-tlgs"><strong>WORKSHOP: Hands on with Cardinal: Harmonizing Clinical Reporting with Open‑Source TLGs</strong></a></li>
  <li><a href="#workshop-advanced-clinical-reporting-with-officer-and-flextable" id="toc-workshop-advanced-clinical-reporting-with-officer-and-flextable" class="nav-link" data-scroll-target="#workshop-advanced-clinical-reporting-with-officer-and-flextable"><strong>WORKSHOP: Advanced Clinical Reporting with officer and flextable</strong></a></li>
  <li><a href="#workshop-creating-polished-branded-documents-with-quarto" id="toc-workshop-creating-polished-branded-documents-with-quarto" class="nav-link" data-scroll-target="#workshop-creating-polished-branded-documents-with-quarto"><strong>WORKSHOP: Creating Polished, Branded Documents with Quarto</strong></a></li>
  <li><a href="#workshop-polars-the-blazing-fast-python-framework-for-modern-clinical-trial-data-exploration" id="toc-workshop-polars-the-blazing-fast-python-framework-for-modern-clinical-trial-data-exploration" class="nav-link" data-scroll-target="#workshop-polars-the-blazing-fast-python-framework-for-modern-clinical-trial-data-exploration"><strong>WORKSHOP: Polars: The Blazing Fast Python Framework for Modern Clinical Trial Data Exploration</strong></a></li>
  <li><a href="#workshop-how-to-use-pointblank-to-understand-validate-and-document-your-data" id="toc-workshop-how-to-use-pointblank-to-understand-validate-and-document-your-data" class="nav-link" data-scroll-target="#workshop-how-to-use-pointblank-to-understand-validate-and-document-your-data"><strong>WORKSHOP: How to use pointblank to understand, validate, and document your data</strong></a></li>
  <li><a href="#practical-ai-for-data-science" id="toc-practical-ai-for-data-science" class="nav-link" data-scroll-target="#practical-ai-for-data-science"><strong>Practical AI for data science</strong></a></li>
  <li><a href="#duckplyr-analyze-large-data-with-duckdb-and-dplyr-compatibility" id="toc-duckplyr-analyze-large-data-with-duckdb-and-dplyr-compatibility" class="nav-link" data-scroll-target="#duckplyr-analyze-large-data-with-duckdb-and-dplyr-compatibility"><strong>duckplyr: Analyze large data with DuckDB and dplyr compatibility</strong></a></li>
  <li><a href="#beyond-training-evolving-strategies-to-teach-and-support-r-adoption-in-pharma" id="toc-beyond-training-evolving-strategies-to-teach-and-support-r-adoption-in-pharma" class="nav-link" data-scroll-target="#beyond-training-evolving-strategies-to-teach-and-support-r-adoption-in-pharma"><strong>Beyond Training: Evolving Strategies to Teach and Support R Adoption in Pharma</strong></a></li>
  <li><a href="#validating-shiny-apps-in-regulated-environments" id="toc-validating-shiny-apps-in-regulated-environments" class="nav-link" data-scroll-target="#validating-shiny-apps-in-regulated-environments"><strong>Validating Shiny Apps in Regulated Environments</strong></a></li>
  <li><a href="#beyond-gtsummary-how-the-crane-package-extends-the-framework-for-pharmaceutical-reporting" id="toc-beyond-gtsummary-how-the-crane-package-extends-the-framework-for-pharmaceutical-reporting" class="nav-link" data-scroll-target="#beyond-gtsummary-how-the-crane-package-extends-the-framework-for-pharmaceutical-reporting"><strong>Beyond {gtsummary}: How the {crane} Package Extends the Framework for Pharmaceutical Reporting</strong></a></li>
  <li><a href="#llumen-an-agentic-llm-framework-for-biomedical-documents-databases-foundation-models" id="toc-llumen-an-agentic-llm-framework-for-biomedical-documents-databases-foundation-models" class="nav-link" data-scroll-target="#llumen-an-agentic-llm-framework-for-biomedical-documents-databases-foundation-models"><strong>{llumen}: An agentic LLM framework for biomedical documents, databases &amp; foundation models</strong></a></li>
  <li><a href="#build-model-context-protocol-servers-and-clients-in-r" id="toc-build-model-context-protocol-servers-and-clients-in-r" class="nav-link" data-scroll-target="#build-model-context-protocol-servers-and-clients-in-r"><strong>Build Model Context Protocol servers and clients in R</strong></a></li>
  <li><a href="#mosaic-open-source-ars-driven-automation-of-standard-tfls" id="toc-mosaic-open-source-ars-driven-automation-of-standard-tfls" class="nav-link" data-scroll-target="#mosaic-open-source-ars-driven-automation-of-standard-tfls"><strong>Mosaic: Open-Source, ARS-Driven Automation of Standard TFLs</strong></a></li>
  <li><a href="#integrating-collaborative-programming-with-automated-traceability-and-reproducibility-in-pharma" id="toc-integrating-collaborative-programming-with-automated-traceability-and-reproducibility-in-pharma" class="nav-link" data-scroll-target="#integrating-collaborative-programming-with-automated-traceability-and-reproducibility-in-pharma"><strong>Integrating Collaborative Programming with Automated Traceability and Reproducibility in Pharma</strong></a></li>
  <li><a href="#tabpfn-a-deep-learning-solution-for-tabular-data" id="toc-tabpfn-a-deep-learning-solution-for-tabular-data" class="nav-link" data-scroll-target="#tabpfn-a-deep-learning-solution-for-tabular-data"><strong>TabPFN: A Deep-Learning Solution for Tabular Data</strong></a></li>
  <li><a href="#the-llm-lounge-live-coding-and-conversation-on-using-ai-for-data-science" id="toc-the-llm-lounge-live-coding-and-conversation-on-using-ai-for-data-science" class="nav-link" data-scroll-target="#the-llm-lounge-live-coding-and-conversation-on-using-ai-for-data-science"><strong>The LLM Lounge: Live-coding and conversation on using AI for data science</strong></a></li>
  <li><a href="#llm-powered-gtsummary-qc-ready-clinical-tables-in-minutes" id="toc-llm-powered-gtsummary-qc-ready-clinical-tables-in-minutes" class="nav-link" data-scroll-target="#llm-powered-gtsummary-qc-ready-clinical-tables-in-minutes"><strong>LLM-Powered {gtsummary}: QC-Ready Clinical Tables in Minutes</strong></a></li>
  <li><a href="#post-approval-drug-exposure-estimation-using-an-r-shiny-app" id="toc-post-approval-drug-exposure-estimation-using-an-r-shiny-app" class="nav-link" data-scroll-target="#post-approval-drug-exposure-estimation-using-an-r-shiny-app"><strong>Post-Approval Drug Exposure Estimation Using an R Shiny App</strong></a></li>
  <li><a href="#implementing-an-end-to-end-nca-software-using-shiny" id="toc-implementing-an-end-to-end-nca-software-using-shiny" class="nav-link" data-scroll-target="#implementing-an-end-to-end-nca-software-using-shiny"><strong>Implementing an end-to-end NCA software using Shiny</strong></a></li>
  <li><a href="#integrating-llm-using-r-shiny-for-clinical-data-review-by-ensuring-data-privacy-and-validity" id="toc-integrating-llm-using-r-shiny-for-clinical-data-review-by-ensuring-data-privacy-and-validity" class="nav-link" data-scroll-target="#integrating-llm-using-r-shiny-for-clinical-data-review-by-ensuring-data-privacy-and-validity"><strong>Integrating LLM using R Shiny for Clinical Data Review by Ensuring Data Privacy and Validity</strong></a></li>
  <li><a href="#r-we-there-yet-admirals-journey-transitioning-from-active-development-to-stability" id="toc-r-we-there-yet-admirals-journey-transitioning-from-active-development-to-stability" class="nav-link" data-scroll-target="#r-we-there-yet-admirals-journey-transitioning-from-active-development-to-stability"><strong>R we there yet? {admiral}’s journey transitioning from active development to stability</strong></a></li>
  <li><a href="#workshop-r-classification-unleashing-predictive-power-with-tidymodels" id="toc-workshop-r-classification-unleashing-predictive-power-with-tidymodels" class="nav-link" data-scroll-target="#workshop-r-classification-unleashing-predictive-power-with-tidymodels"><strong>Workshop: R-Classification: Unleashing Predictive Power with tidymodels</strong></a></li>
  <li><a href="#workshop-a-guided-tour-to-building-and-integrating-llm-based-tooling-with-r" id="toc-workshop-a-guided-tour-to-building-and-integrating-llm-based-tooling-with-r" class="nav-link" data-scroll-target="#workshop-a-guided-tour-to-building-and-integrating-llm-based-tooling-with-r"><strong>Workshop: A Guided Tour to Building and Integrating LLM Based Tooling with R</strong></a></li>
  <li><a href="#gsks-journey-to-clinical-study-reporting-using-open-source" id="toc-gsks-journey-to-clinical-study-reporting-using-open-source" class="nav-link" data-scroll-target="#gsks-journey-to-clinical-study-reporting-using-open-source"><strong>GSK’s journey to Clinical Study Reporting Using Open Source</strong></a></li>
  <li><a href="#leveraging-ellmer-and-gpt-to-integrate-ai-agents-into-shiny-applications-for-accelerating-trials" id="toc-leveraging-ellmer-and-gpt-to-integrate-ai-agents-into-shiny-applications-for-accelerating-trials" class="nav-link" data-scroll-target="#leveraging-ellmer-and-gpt-to-integrate-ai-agents-into-shiny-applications-for-accelerating-trials"><strong>Leveraging ellmer and GPT to Integrate AI Agents into Shiny Applications for Accelerating Trials</strong></a></li>
  <li><a href="#autoslider-streamlining-slide-deck-generation-for-clinical-reporting-events" id="toc-autoslider-streamlining-slide-deck-generation-for-clinical-reporting-events" class="nav-link" data-scroll-target="#autoslider-streamlining-slide-deck-generation-for-clinical-reporting-events"><strong>autoslideR: Streamlining slide deck generation for clinical reporting events</strong></a></li>
  <li><a href="#putting-the-r-in-rwd" id="toc-putting-the-r-in-rwd" class="nav-link" data-scroll-target="#putting-the-r-in-rwd"><strong>Putting the ‘R’ in RWD</strong></a></li>
  <li><a href="#generating-synthetic-data-with-synthpop-in-r" id="toc-generating-synthetic-data-with-synthpop-in-r" class="nav-link" data-scroll-target="#generating-synthetic-data-with-synthpop-in-r"><strong>Generating Synthetic Data with synthpop in R</strong></a></li>
  <li><a href="#genai-in-production---moving-beyond-prototypes" id="toc-genai-in-production---moving-beyond-prototypes" class="nav-link" data-scroll-target="#genai-in-production---moving-beyond-prototypes"><strong>GenAI in Production - moving beyond prototypes</strong></a></li>
  <li><a href="#building-the-ultimate-r-ai-assistant" id="toc-building-the-ultimate-r-ai-assistant" class="nav-link" data-scroll-target="#building-the-ultimate-r-ai-assistant"><strong>Building the Ultimate R AI Assistant</strong></a></li>
  <li><a href="#the-dependency-whisperer-ai-that-sees-what-you-might-miss" id="toc-the-dependency-whisperer-ai-that-sees-what-you-might-miss" class="nav-link" data-scroll-target="#the-dependency-whisperer-ai-that-sees-what-you-might-miss"><strong>The Dependency Whisperer: AI That Sees What You Might Miss</strong></a></li>
  <li><a href="#bayesertools-r-package-for-exposure-response-analysis-with-bayesian-approaches" id="toc-bayesertools-r-package-for-exposure-response-analysis-with-bayesian-approaches" class="nav-link" data-scroll-target="#bayesertools-r-package-for-exposure-response-analysis-with-bayesian-approaches"><strong>BayesERtools: R package for exposure-response analysis with Bayesian approaches</strong></a></li>
  <li><a href="#adapting-to-regulatory-guidance-covariate-adjustment-and-r-enabled-submissions" id="toc-adapting-to-regulatory-guidance-covariate-adjustment-and-r-enabled-submissions" class="nav-link" data-scroll-target="#adapting-to-regulatory-guidance-covariate-adjustment-and-r-enabled-submissions"><strong>Adapting to Regulatory Guidance: Covariate Adjustment and R-enabled Submissions</strong></a></li>
  <li><a href="#r-library-validation-using-acceptance-test-driven-development" id="toc-r-library-validation-using-acceptance-test-driven-development" class="nav-link" data-scroll-target="#r-library-validation-using-acceptance-test-driven-development"><strong>R library validation using Acceptance-Test Driven Development</strong></a></li>
  <li><a href="#workshop-r-validation-discussion-metric-repos-for-open-quality-assessment" id="toc-workshop-r-validation-discussion-metric-repos-for-open-quality-assessment" class="nav-link" data-scroll-target="#workshop-r-validation-discussion-metric-repos-for-open-quality-assessment"><strong>WORKSHOP: R Validation Discussion: Metric Repos for Open Quality Assessment</strong></a></li>
  <li><a href="#workshop-datasetjson---read-and-write-cdisc-dataset-json-formatted-datasets-in-r-and-python" id="toc-workshop-datasetjson---read-and-write-cdisc-dataset-json-formatted-datasets-in-r-and-python" class="nav-link" data-scroll-target="#workshop-datasetjson---read-and-write-cdisc-dataset-json-formatted-datasets-in-r-and-python"><strong>WORKSHOP: datasetjson - Read and write CDISC Dataset JSON formatted datasets in R and Python</strong></a></li>
  <li><a href="#workshop-sdtm-programming-in-r-using-sdtm.oak-package" id="toc-workshop-sdtm-programming-in-r-using-sdtm.oak-package" class="nav-link" data-scroll-target="#workshop-sdtm-programming-in-r-using-sdtm.oak-package"><strong>WORKSHOP: SDTM programming in R using {sdtm.oak} package</strong></a></li>
  <li><a href="#workshop-python-for-clinical-study-report-and-submission" id="toc-workshop-python-for-clinical-study-report-and-submission" class="nav-link" data-scroll-target="#workshop-python-for-clinical-study-report-and-submission"><strong>WORKSHOP: Python for Clinical Study Report and Submission</strong></a></li>
  <li><a href="#workshop-supercharge-your-shiny-app-by-offloading-computations-to-a-hpc-cluster" id="toc-workshop-supercharge-your-shiny-app-by-offloading-computations-to-a-hpc-cluster" class="nav-link" data-scroll-target="#workshop-supercharge-your-shiny-app-by-offloading-computations-to-a-hpc-cluster"><strong>WORKSHOP: Supercharge your shiny app by offloading computations to a HPC cluster</strong></a></li>
  <li><a href="#workshop-bayesian-survival-and-multistate-models-using-r-and-stan" id="toc-workshop-bayesian-survival-and-multistate-models-using-r-and-stan" class="nav-link" data-scroll-target="#workshop-bayesian-survival-and-multistate-models-using-r-and-stan"><strong>WORKSHOP: Bayesian Survival and Multistate Models using R and Stan</strong></a></li>
  <li><a href="#workshop-from-data-to-insights-a-hands-on-workshop-with-teal-for-clinical-data-exploration" id="toc-workshop-from-data-to-insights-a-hands-on-workshop-with-teal-for-clinical-data-exploration" class="nav-link" data-scroll-target="#workshop-from-data-to-insights-a-hands-on-workshop-with-teal-for-clinical-data-exploration"><strong>WORKSHOP: From Data to Insights: A Hands-On Workshop with {teal} for Clinical Data Exploration</strong></a></li>
  </ul></li>
  <li><a href="#presentations" id="toc-presentations" class="nav-link" data-scroll-target="#presentations">Presentations</a>
  <ul class="collapse">
  <li><a href="#open-source-culture-and-data-strategy-in-shionogi-a-new-value-creation-model-for-pharma" id="toc-open-source-culture-and-data-strategy-in-shionogi-a-new-value-creation-model-for-pharma" class="nav-link" data-scroll-target="#open-source-culture-and-data-strategy-in-shionogi-a-new-value-creation-model-for-pharma">[<strong>Open-Source Culture and Data Strategy in SHIONOGI: A New Value-Creation Model for Pharma</strong>]</a></li>
  <li><a href="#strategically-assisting-statistical-programmers-to-succeed-in-r-sas2r" id="toc-strategically-assisting-statistical-programmers-to-succeed-in-r-sas2r" class="nav-link" data-scroll-target="#strategically-assisting-statistical-programmers-to-succeed-in-r-sas2r">[<strong>Strategically Assisting Statistical programmers To succeed in R (SAS2R)</strong>]</a></li>
  <li><a href="#side-by-side-by-design-pharma-data-handling-with-merge-join-match-and-hash-in-r" id="toc-side-by-side-by-design-pharma-data-handling-with-merge-join-match-and-hash-in-r" class="nav-link" data-scroll-target="#side-by-side-by-design-pharma-data-handling-with-merge-join-match-and-hash-in-r">[<strong>Side-by-side by Design: Pharma Data Handling with Merge, Join, Match, and Hash in R</strong>]</a></li>
  <li><a href="#risk-assessment-deep-dive" id="toc-risk-assessment-deep-dive" class="nav-link" data-scroll-target="#risk-assessment-deep-dive">[<strong>Risk Assessment Deep Dive</strong>]</a></li>
  <li><a href="#leverage-template-based-automated-reporting-on-dmc-materials-preparation" id="toc-leverage-template-based-automated-reporting-on-dmc-materials-preparation" class="nav-link" data-scroll-target="#leverage-template-based-automated-reporting-on-dmc-materials-preparation">[<strong>Leverage template-based automated reporting on DMC materials preparation</strong>]</a></li>
  <li><a href="#dynamic-creation-of-kaplan-meier-plots-and-summary-measure-tables-for-survival-data-with-r-shiny" id="toc-dynamic-creation-of-kaplan-meier-plots-and-summary-measure-tables-for-survival-data-with-r-shiny" class="nav-link" data-scroll-target="#dynamic-creation-of-kaplan-meier-plots-and-summary-measure-tables-for-survival-data-with-r-shiny">[<strong>Dynamic Creation of Kaplan-Meier Plots and Summary Measure Tables for Survival Data with R Shiny</strong>]</a></li>
  <li><a href="#autoslider-streamlining-slide-deck-generation-for-clinical-reporting-events-1" id="toc-autoslider-streamlining-slide-deck-generation-for-clinical-reporting-events-1" class="nav-link" data-scroll-target="#autoslider-streamlining-slide-deck-generation-for-clinical-reporting-events-1">[<strong>autoslideR: Streamlining slide deck generation for clinical reporting events</strong>]</a></li>
  <li><a href="#from-harmony-to-hybrid-charting-a-practical-course-for-r-adoption-in-pharma" id="toc-from-harmony-to-hybrid-charting-a-practical-course-for-r-adoption-in-pharma" class="nav-link" data-scroll-target="#from-harmony-to-hybrid-charting-a-practical-course-for-r-adoption-in-pharma">[<strong>From Harmony to Hybrid: Charting a Practical Course for R Adoption in Pharma</strong>]</a></li>
  <li><a href="#emerging-trend-of-llm-development-in-r-and-implementation" id="toc-emerging-trend-of-llm-development-in-r-and-implementation" class="nav-link" data-scroll-target="#emerging-trend-of-llm-development-in-r-and-implementation">[<strong>Emerging trend of LLM development in R and implementation</strong>]</a></li>
  <li><a href="#an-r-package-to-consolidate-pretest-probability-models-and-guidelines-for-cad" id="toc-an-r-package-to-consolidate-pretest-probability-models-and-guidelines-for-cad" class="nav-link" data-scroll-target="#an-r-package-to-consolidate-pretest-probability-models-and-guidelines-for-cad">[<strong>An R package to consolidate pretest probability models and guidelines for CAD</strong>]</a></li>
  <li><a href="#enhancing-efficiency-in-e-crt-creation-for-pmda-through-r-shiny-app-development-using-vibe-coding" id="toc-enhancing-efficiency-in-e-crt-creation-for-pmda-through-r-shiny-app-development-using-vibe-coding" class="nav-link" data-scroll-target="#enhancing-efficiency-in-e-crt-creation-for-pmda-through-r-shiny-app-development-using-vibe-coding">[<strong>Enhancing Efficiency in e-CRT Creation for PMDA Through R Shiny App Development Using Vibe Coding</strong>]</a></li>
  <li><a href="#merlin---context-aware-ai-assistant-for-clinical-programming" id="toc-merlin---context-aware-ai-assistant-for-clinical-programming" class="nav-link" data-scroll-target="#merlin---context-aware-ai-assistant-for-clinical-programming">[<strong>{meRlin} - context-aware AI assistant for clinical programming</strong>]</a></li>
  <li><a href="#improving-precision-healthcare-for-under-represented-and-genetically-diverse-global-populations" id="toc-improving-precision-healthcare-for-under-represented-and-genetically-diverse-global-populations" class="nav-link" data-scroll-target="#improving-precision-healthcare-for-under-represented-and-genetically-diverse-global-populations">[<strong>Improving precision healthcare for under-represented and genetically diverse global populations</strong>]</a></li>
  <li><a href="#exploring-ai-tools-in-clinical-trial-data-analysis" id="toc-exploring-ai-tools-in-clinical-trial-data-analysis" class="nav-link" data-scroll-target="#exploring-ai-tools-in-clinical-trial-data-analysis">[<strong>Exploring AI tools in clinical trial data analysis</strong>]</a></li>
  <li><a href="#an-r-package-cgmguru-for-automated-glycemic-event-detection-from-continuous-glucose-monitoring-data" id="toc-an-r-package-cgmguru-for-automated-glycemic-event-detection-from-continuous-glucose-monitoring-data" class="nav-link" data-scroll-target="#an-r-package-cgmguru-for-automated-glycemic-event-detection-from-continuous-glucose-monitoring-data">[<strong>An R Package cgmguru for Automated Glycemic Event Detection From Continuous Glucose Monitoring Data</strong>]</a></li>
  <li><a href="#interactive-and-reproducible-reports-with-quarto" id="toc-interactive-and-reproducible-reports-with-quarto" class="nav-link" data-scroll-target="#interactive-and-reproducible-reports-with-quarto">[<strong>Interactive and Reproducible Reports with Quarto</strong>]</a></li>
  <li><a href="#using-analysis-results-data-using-cards-for-pmda-oncology-inqueries" id="toc-using-analysis-results-data-using-cards-for-pmda-oncology-inqueries" class="nav-link" data-scroll-target="#using-analysis-results-data-using-cards-for-pmda-oncology-inqueries">[<strong>Using Analysis Results Data using {cards} for PMDA Oncology inqueries</strong>]</a></li>
  <li><a href="#reach-for-r-low-hanging-fruit-for-faster-results" id="toc-reach-for-r-low-hanging-fruit-for-faster-results" class="nav-link" data-scroll-target="#reach-for-r-low-hanging-fruit-for-faster-results">[<strong>Reach for R Low Hanging Fruit for Faster Results</strong>]</a></li>
  <li><a href="#medxr-package---bridging-regulatory-drug-data-from-the-fda-and-health-canada-into-r" id="toc-medxr-package---bridging-regulatory-drug-data-from-the-fda-and-health-canada-into-r" class="nav-link" data-scroll-target="#medxr-package---bridging-regulatory-drug-data-from-the-fda-and-health-canada-into-r">[<strong>MedxR Package - Bridging Regulatory Drug Data from the FDA and Health Canada into R</strong>]</a></li>
  <li><a href="#risk.assessr-extending-its-use-in-the-package-validation-process" id="toc-risk.assessr-extending-its-use-in-the-package-validation-process" class="nav-link" data-scroll-target="#risk.assessr-extending-its-use-in-the-package-validation-process">[<strong>risk.assessr: extending its use in the package validation process</strong>]</a></li>
  <li><a href="#code-review-for-compliance-best-practices-for-validated-r-workflows-in-pharma" id="toc-code-review-for-compliance-best-practices-for-validated-r-workflows-in-pharma" class="nav-link" data-scroll-target="#code-review-for-compliance-best-practices-for-validated-r-workflows-in-pharma">[<strong>Code Review for Compliance: Best Practices for Validated R Workflows in Pharma</strong>]</a></li>
  <li><a href="#a-web-based-r-application-for-forecasting-patient-enrollment-in-clinical-trials" id="toc-a-web-based-r-application-for-forecasting-patient-enrollment-in-clinical-trials" class="nav-link" data-scroll-target="#a-web-based-r-application-for-forecasting-patient-enrollment-in-clinical-trials">[<strong>A Web-Based R Application for Forecasting Patient Enrollment in Clinical Trials</strong>]</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"><h1 class="title display-7"></h1></header><div class="quarto-title-block"><div class="quarto-title-tools-only"><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>




<section id="r-pharma-2025-workshops" class="level1">
<h1>R-Pharma-2025-Workshops</h1>
<section id="workshop-flexible-clinical-trial-design-simulation-and-analysis-with-the-r-package-rpact" class="level3">
<h3 class="anchored" data-anchor-id="workshop-flexible-clinical-trial-design-simulation-and-analysis-with-the-r-package-rpact"><strong>WORKSHOP: Flexible Clinical Trial Design, Simulation, and Analysis with the R Package rpact</strong></h3>
<p><strong>Daniel Sabanes Bove</strong> Entrepreneur in Biostatistics Consulting and Engineering, RCONIS</p>
<p><strong>Friedrich Pahlke</strong> Tech Entrepreneur | Driving Innovation in R/Shiny</p>
<p>In this workshop we will explore the capabilities of the validated open-source R package ‘rpact’, which is available on CRAN and GitHub. rpact is a comprehensive validated, open source, free-of-charge R software package for clinical trial planning, design simulation, and data analysis. rpact is under continuous full-time development since 2017, and comprehensive documentation is available at&nbsp;<a href="http://www.rpact.org/">www.rpact.org</a>. We will provide an introduction to the package and illustrate the usage by several examples. The focus of the package is on group sequential and adaptive designs with p-value combination tests, but also fixed sample designs can be considered. The software can specifically be used to assess design characteristics of popular group sequential designs. However, going beyond those, adaptive designs are a strength of rpact: Adaptive multi-armed and population enrichment designs that are based on closed combination tests can be assessed by simulation. The application of the designs for simulation, real data, and estimation is possible for continuous, binary, survival, and count data. Furthermore, we introduce ‘RPACT Cloud’, a user-friendly platform designed to simplify and enhance the process of clinical trial design and simulations for researchers and practitioners. A free version of RPACT Cloud is available at&nbsp;<a href="https://cloud.rpact.com/" class="uri">https://cloud.rpact.com/</a>&nbsp;and workshop participants will be able to try out the software themselves following the workshop.</p>
<p>Link to the presentation: <a href="https://rpharma.presentation.2025.rpact.com/" class="uri">https://rpharma.presentation.2025.rpact.com/</a></p>
</section>
<section id="workshop-debugging-stan-programs" class="level3">
<h3 class="anchored" data-anchor-id="workshop-debugging-stan-programs"><strong>WORKSHOP: Debugging Stan Programs</strong></h3>
<p><strong>Daniel Lee</strong></p>
<p>Data Scientist, Bayesian statistician, Stan developer</p>
<p>Having trouble getting your Stan models to behave? This hands-on workshop will explore practical strategies for debugging Stan code, from identifying non-identifiable parameters to improving runtime performance. Participants will gain tools and intuition for building more robust models—skills that extend to a wide range of statistical and stochastic programming tasks.Prerequisite: Familiarity with Stan is recommended.</p>
<p>Workshop related link: <a href="https://github.com/bayesianops/stan-tutorials/tree/main/debugging-2025-11-03" class="uri">https://github.com/bayesianops/stan-tutorials/tree/main/debugging-2025-11-03</a></p>
</section>
<section id="workshop-introduction-to-building-better-r-packages" class="level3">
<h3 class="anchored" data-anchor-id="workshop-introduction-to-building-better-r-packages"><strong>WORKSHOP: Introduction to building (better) R packages</strong></h3>
<p><strong>Nicola Rennie</strong></p>
<p>Data Visualisation Specialist</p>
<p>There are many benefits to turning your R scripts or functions into a package, like making your code easier to re-use, easier to share with others, easier to document, and easier to test. But the process of writing a package can feel intimidating, especially if you haven’t done it before. But it doesn’t need to! In this interactive workshop, we’ll discuss:* What things you need to make a package and how to create them* How to write functions (in a package-friendly way) and add them to a package* How to write documentation and examples for functions* Best practices for package development* How to share your package with other people* Useful resources. By the end of this workshop, you will have made an R package! The session aims to be introductory, so you don’t need any previous experience of building R packages (or even writing functions!) but some basic knowledge of R will be useful. If you’re already a seasoned R package developer, you’re also welcome to attend and hopefully you’ll still pick up a few package development tips!</p>
<p>Workshop related link: <a href="https://nrennie.rbind.io/r-pharma-2025-r-packages/#/title-slide" class="uri">https://nrennie.rbind.io/r-pharma-2025-r-packages/#/title-slide</a></p>
</section>
<section id="workshop-getting-started-with-llm-apis-in-r" class="level3">
<h3 class="anchored" data-anchor-id="workshop-getting-started-with-llm-apis-in-r"><strong>WORKSHOP: Getting Started with LLM APIs in R</strong></h3>
<p><strong>Sara Altman</strong></p>
<p>Data Science Educator</p>
<p>Posit PBC</p>
<p>LLMs are transforming how we write code, build tools, and analyze data, but getting started with directly working with LLM APIs can feel daunting. This workshop will introduce participants to programming with LLM APIs in R using ellmer, an open-source package that makes it easy to work with LLMs from R. We’ll cover the basics of calling LLMs from R, as well as system prompt design, tool calling, and building basic chatbots.</p>
<p>No AI or machine learning background is required—just basic R familiarity. Participants will leave with example scripts they can adapt to their own projects.</p>
<p>Workshop related link: <a href="https://skaltman.github.io/r-pharma-llm/" class="uri">https://skaltman.github.io/r-pharma-llm/</a></p>
</section>
<section id="workshop-hands-on-with-cardinal-harmonizing-clinical-reporting-with-opensource-tlgs" class="level3">
<h3 class="anchored" data-anchor-id="workshop-hands-on-with-cardinal-harmonizing-clinical-reporting-with-opensource-tlgs"><strong>WORKSHOP: Hands on with Cardinal: Harmonizing Clinical Reporting with Open‑Source TLGs</strong></h3>
<p><strong>Abinaya Yogasekaram</strong></p>
<p>Bioinformatics | Software Development | Data Science</p>
<p>Amaris Consulting</p>
<p><strong>Emily De La Rua</strong></p>
<p>Data Scientist at Roche</p>
<p>Cardinal is an open-source collection of standardized table, listing, and graph (TLG) templates designed to streamline the process of clinical output review, comparison, and meta-analysis—promoting efficient communication to stakeholders while aligning with CDISC’s ARD/ARM efforts.</p>
<p>In this workshop, we’ll introduce the {gtsummary} package for table creation and walk through Cardinal’s growing catalog of TLGs. Participants will get hands-on experience generating key outputs—ideally working on examples that are directly relevant to your own work.</p>
<p>Whether you’re new to Cardinal, looking to integrate it into your own workflow, or interested in contributing to the project, this workshop will provide practical insights and real-world applications for modern clinical reporting.</p>
<p>Workshop related link: <a href="https://pharmaverse.github.io/cardinal/" class="uri">https://pharmaverse.github.io/cardinal/</a></p>
</section>
<section id="workshop-advanced-clinical-reporting-with-officer-and-flextable" class="level3">
<h3 class="anchored" data-anchor-id="workshop-advanced-clinical-reporting-with-officer-and-flextable"><strong>WORKSHOP: Advanced Clinical Reporting with officer and flextable</strong></h3>
<p><strong>David Gohel</strong></p>
<p><a href="https://rinpharma.com/docs/RPH2025/#"><strong>Advanced Clinical Reporting with officer and flextable</strong></a></p>
<p>In this workshop you will be working with the officer and flextable packages to create sophisticated clinical reports in Word format using R with a reproducible approach. Going from clinical data all the way through to complete pharmaceutical report generation. Specifically, we will walk through an end-to-end example focusing on advanced document structure management, complex table creation following pharmaceutical standards, and integration of ggplot2 visualizations. The workshop is divided into two parts: first, discovering the fundamentals of officer and flextable packages, then moving to advanced clinical reporting techniques including section management, headers and footers customization, and cross-reference handling for complete pharmaceutical report composition.</p>
<p>Workshop related links:</p>
<p><a href="https://ardata.fr/r-in-pharma-2025/" class="uri">https://ardata.fr/r-in-pharma-2025/</a></p>
<p><a href="https://github.com/ardata-fr/r-in-pharma-2025-codes" class="uri">https://github.com/ardata-fr/r-in-pharma-2025-codes</a></p>
<p><a href="https://github.com/ardata-fr/r-in-pharma-reporting-with-officer-flextable" class="uri">https://github.com/ardata-fr/r-in-pharma-reporting-with-officer-flextable</a></p>
</section>
<section id="workshop-creating-polished-branded-documents-with-quarto" class="level3">
<h3 class="anchored" data-anchor-id="workshop-creating-polished-branded-documents-with-quarto"><strong>WORKSHOP: Creating Polished, Branded Documents with Quarto</strong></h3>
<p><strong>Isabella Velásquez</strong></p>
<p>Sr.&nbsp;Product Marketing Manager</p>
<p>Posit PBC</p>
<p>Join us for a hands-on, one-day workshop at R/Phama, where we’ll explore the versatility of Quarto output formats. You will learn how to create dynamic websites, professional PDF documents, engaging presentations, and interactive dashboards using Quarto. This workshop highlights Quarto’s powerful theming capabilities, including the new support for brand.yml, which ensures that your work maintains a professional and cohesive style across all formats.</p>
<p>Workshop related links:</p>
<p><a href="https://019a4f2d-6b79-72c1-834b-c2a9488f9ec8.share.connect.posit.cloud/" class="uri">https://019a4f2d-6b79-72c1-834b-c2a9488f9ec8.share.connect.posit.cloud/</a></p>
<p><a href="https://github.com/ivelasq/2025-11-04_branded-quarto" class="uri">https://github.com/ivelasq/2025-11-04_branded-quarto</a></p>
</section>
<section id="workshop-polars-the-blazing-fast-python-framework-for-modern-clinical-trial-data-exploration" class="level3">
<h3 class="anchored" data-anchor-id="workshop-polars-the-blazing-fast-python-framework-for-modern-clinical-trial-data-exploration"><strong>WORKSHOP: Polars: The Blazing Fast Python Framework for Modern Clinical Trial Data Exploration</strong></h3>
<p><strong>Michael Chow</strong></p>
<p>Principal Software Engineer at Posit (Open Source)</p>
<p>Posit</p>
<p><strong>Jeroen Janssens</strong></p>
<p>Head of Developer Relations</p>
<p>Posit PBC</p>
<p>Clinical trials generate complex and standards driven datasets that can slow down traditional data processing tools. This workshop introduces Polars, a cutting-edge Python DataFrame library engineered with a high-performance backend and the Apache Arrow columnar format for blazingly fast data manipulation. Attendees will learn how Polars lays the foundation for the pharmaverse-py, streamlining the data clinical workflow from database querying and complex data wrangling to the potential task of prepping data for regulatory Tables, Figures, and Listings (TFLs). Discover the ‘delightful’ Polars API and how its speed dramatically accelerates both exploratory and regid data tasks in pharmaceutical drug development. The workshop is led by Michael Chow, a Python developer at Posit who is a key contributor to open-source data tools, notably helping to launch the data presentation library Great Tables, and focusing on bringing efficient data analysis patterns to Python.</p>
<p>Workshop related link:</p>
<p><a href="https://github.com/machow/examples-great-tables-pharma" class="uri">https://github.com/machow/examples-great-tables-pharma</a></p>
</section>
<section id="workshop-how-to-use-pointblank-to-understand-validate-and-document-your-data" class="level3">
<h3 class="anchored" data-anchor-id="workshop-how-to-use-pointblank-to-understand-validate-and-document-your-data"><strong>WORKSHOP: How to use pointblank to understand, validate, and document your data</strong></h3>
<p><strong>Rich Iannone</strong></p>
<p>Software Engineer at Posit PBC</p>
<p>This workshop will focus on the data quality and data documentation workflows that the pointblank package makes possible. We will use functions that allow us to:</p>
<p>(1) quickly understand a new dataset</p>
<p>(2) validate tabular data using rules that are based on our understanding of the data</p>
<p>(3) fully document a table by describing its variables and other important details. The pointblank package was created to scale from small validation problems (“Let’s make certain this table fits my expectations before moving on”) to very large (“Let’s validate these 35 database tables every day and ensure data quality is maintained”) and we’ll delve into all sorts of data quality scenarios so you’ll be comfortable using this package in your organization. Data documentation is seemingly and unfortunately less common in organizations (maybe even less than the practice of data validation). We’ll learn all about how this doesn’t have to be a tedious chore. The pointblank package allows you to create informative and beautiful data documentation that will help others understand what’s in all those tables that are so vital to an organization.</p>
<p>Workshop related link:</p>
<p><a href="https://github.com/rich-iannone/pointblank-workshop" class="uri">https://github.com/rich-iannone/pointblank-workshop</a></p>
<section id="europeus-session-1" class="level4">
<h4 class="anchored" data-anchor-id="europeus-session-1"><strong>Europe/US Session #1</strong></h4>
</section>
</section>
<section id="practical-ai-for-data-science" class="level3">
<h3 class="anchored" data-anchor-id="practical-ai-for-data-science"><strong>Practical AI for data science</strong></h3>
<p>Simon Couch (Posit). Practical AI for data science</p>
<p>While most discourse about AI focuses on glamorous, ungrounded applications, data scientists spend most of their days tackling unglamorous problems in sensitive data. Integrated thoughtfully, LLMs are quite useful in practice for all sorts of everyday data science tasks, even when restricted to secure deployments that protect proprietary information. At Posit, our work on ellmer and related R packages has focused on enabling these practical uses. This talk will outline three practical AI use-cases—structured data extraction, tool calling, and coding—and offer guidance on getting started with LLMs when your data and code is confidential.</p>
<p><a href="https://github.com/simonpcouch" class="uri">https://github.com/simonpcouch</a></p>
<section id="europeus-session-2" class="level4">
<h4 class="anchored" data-anchor-id="europeus-session-2"><strong>Europe/US Session #2</strong></h4>
</section>
</section>
<section id="duckplyr-analyze-large-data-with-duckdb-and-dplyr-compatibility" class="level3">
<h3 class="anchored" data-anchor-id="duckplyr-analyze-large-data-with-duckdb-and-dplyr-compatibility"><strong>duckplyr: Analyze large data with DuckDB and dplyr compatibility</strong></h3>
<p>Kirill Muller (Cynkra).</p>
<p>The duckplyr package is now stable; version 1.1.2 is on CRAN. It builds on top of DuckDB, a fast and flexible analytical engine that can work with larger-than-memory data from disk or cloud storage. All these features are available to duckplyr, with syntax and semantics much closer to R and the tidyverse. Use it to speed up existing code, to analyze Parquet or CSV files directly, or to access the plethora of exciting functionality provided by DuckDB.</p>
</section>
<section id="beyond-training-evolving-strategies-to-teach-and-support-r-adoption-in-pharma" class="level3">
<h3 class="anchored" data-anchor-id="beyond-training-evolving-strategies-to-teach-and-support-r-adoption-in-pharma"><strong>Beyond Training: Evolving Strategies to Teach and Support R Adoption in Pharma</strong></h3>
<p>Alanah Jonas (GSK).</p>
<p>Teaching R effectively is just the starting point for lasting adoption in pharma. At GSK, we began by developing two core R courses written in bookdown and delivered interactively, an approach that enabled high completion rates.</p>
<p>Recognizing that training alone isn’t enough, we expanded support through options like self-certification, intermediate courses, and a Resource Hub. We also launched AccelerateR to provide tailored support to early adopters during their transition.</p>
<p>Today, those efforts have scaled and evolved into Rburst, a cross-functional initiative designed not just to teach R, but to embed it into our ways of working across all of Biostatistics.</p>
<p>This talk will explore how our training strategy has matured into a broader support model, enabling wide-scale, integrated adoption of R in everyday work.</p>
</section>
<section id="validating-shiny-apps-in-regulated-environments" class="level3">
<h3 class="anchored" data-anchor-id="validating-shiny-apps-in-regulated-environments"><strong>Validating Shiny Apps in Regulated Environments</strong></h3>
<p>Pedro Silva (Jumping Rivers).</p>
<p>Shiny apps are increasingly used to deliver interactive tools in clinical and healthcare settings. But when these tools are used in regulated environments, validation becomes essential. How can we ensure that our Shiny apps are trustworthy, without stifling innovation?</p>
<p>In this talk we’ll explore practical approaches to validating Shiny applications in regulated contexts, drawing on principles from software engineering, quality assurance, and risk based validation. We’ll discuss key challenges like traceability, documentation, and versioning, as well as share techniques for building apps that are easier to validate from the start.</p>
<p>I’ll highlight some of the tools and packages used in Jumping Rivers that can support validation workflows that satisfies both internal reviewers and external regulators, including the Litmusverse, a suite of R packages designed to assess code quality and generate validation evidence.</p>
<p>By the end of the session, you’ll understand: - Why validation is critical for Shiny apps in regulated contexts; - What elements make a Shiny app more or less validatable; - How to incorporate validation strategies into your development process.</p>
<p>This session is ideal for R users in pharma, clinical research, and healthcare who want to build confidence in their dashboards, while maintaining flexibility in how they work.</p>
</section>
<section id="beyond-gtsummary-how-the-crane-package-extends-the-framework-for-pharmaceutical-reporting" class="level3">
<h3 class="anchored" data-anchor-id="beyond-gtsummary-how-the-crane-package-extends-the-framework-for-pharmaceutical-reporting"><strong>Beyond {gtsummary}: How the {crane} Package Extends the Framework for Pharmaceutical Reporting</strong></h3>
<p>Daniel Sjoberg (Genentech) and Davide Garolini (Genentech).</p>
<p>{gtsummary} has become the most-used R package for clinical tables in the R ecosystem, winning awards from the American Statistical Association and Posit. Building on this foundation, we created {crane}, an open-source extension that facilitates reporting requirements in the pharmaceutical space. Because {crane} and {gtsummary} are built upon Analysis Results Datasets (ARDs), study teams can take advantage of this foundation that streamlines the QC process and allows for simple re-use of calculated results in subsequent reporting.</p>
<p>In this session we show how: (1) a vanilla {gtsummary} script instantly upgrades when {crane} is loaded; (2) ARD-based outputs make QC a straightforward operation; (3) LLMs can summarise the language-agnostic ARD results for medical writers in seconds. You’ll leave with a blueprint of how to adapt {crane} for your reporting needs or (or roll your own) and shorten table turnaround on day one.</p>
<p><a href="https://www.danieldsjoberg.com/RinPharma-crane-2025/" class="uri">https://www.danieldsjoberg.com/RinPharma-crane-2025/</a></p>
<p><a href="https://github.com/ddsjoberg/RinPharma-crane-2025/tree/main" class="uri">https://github.com/ddsjoberg/RinPharma-crane-2025/tree/main</a></p>
<p><a href="https://github.com/cynkra/r-in-pharma-2025/" class="uri">https://github.com/cynkra/r-in-pharma-2025/</a></p>
<p><a href="https://docs.google.com/presentation/d/1atV5rBLQF2vcCg2lraiutg_Xx2BOEklZzf9LJt842ig/edit?usp=sharing" class="uri">https://docs.google.com/presentation/d/1atV5rBLQF2vcCg2lraiutg_Xx2BOEklZzf9LJt842ig/edit?usp=sharing</a></p>
<section id="europeus-session-3" class="level4">
<h4 class="anchored" data-anchor-id="europeus-session-3"><strong>Europe/US Session #3</strong></h4>
</section>
</section>
<section id="llumen-an-agentic-llm-framework-for-biomedical-documents-databases-foundation-models" class="level3">
<h3 class="anchored" data-anchor-id="llumen-an-agentic-llm-framework-for-biomedical-documents-databases-foundation-models"><strong>{llumen}: An agentic LLM framework for biomedical documents, databases &amp; foundation models</strong></h3>
<p>Sven-Eric Schelhorn (lumen).</p>
<p>We introduce {llumen}, an R package used at Merck KGaA, Darmstadt, Germany that implements an agentic framework bases on {ellmer} and enables pharmaceutical researchers to work with biomedical documents, large real-world evidence and biomarker databases, as well as with biological foundation models using large language models as orchestrators.</p>
<p>{llumen} currently supports the following functionalities:</p>
<ul>
<li><p><em>Large language models</em>*</p></li>
<li><p>Runs on standard company laptops (Windows, Linux, or macOS).</p></li>
<li><p>Allows using a wide range of private (Azure), public (OpenAI, Anthropic, Bedrock), and local (llama.cpp) LLMs.</p></li>
<li><p>Provides both programmatic and fully interactive (chatbot) ways to interact with the LLM.</p></li>
<li><p>Supports chain-of-thoughts, tree-of-thoughts, and ReAct reasoning strategies.</p></li>
<li><p>Supports context management to maintain conversation history and state.</p></li>
<li><p><em>Text analysis</em>*</p></li>
<li><p>Supports embeddings (Azure, public, or local) using a local, high-performance vector DB (based on {ragnar}).</p></li>
<li><p>Implements chunking office documents (Word, Excel, Powerpoint, RTF, PDF) into the vector DB.</p></li>
<li><p>While reading office documents, supports extracting tables with summary data.</p></li>
<li><p>Enables retrieval-augmented generation (RAG) using the vector DB, either explicitly or by using a RAG tool that the LLM calls.</p></li>
<li><p>Emulates the Future House’s PaperQA2 approach for summarizing and re-ranking parts of semantically related documents so that answer quality and comprehensiveness is significantly boosted.</p></li>
<li><p>Extracts text from documents to fill structured templates, such as the JSON-based {llumen} Analysis Results Schema (LARS). Extracted JSONs are directly validated by the LLM using an R tool.</p></li>
<li><p>Supports automatic diagram generation from texts, for instance to capture the main concepts of a paper in two or three flow charts.</p></li>
<li><p>Provides advanced text preprocessing and cleaning capabilities for various document types.</p></li>
<li><p>Offers customizable tokenization and text segmentation methods.</p></li>
<li><p><em>Agentic tool use and codegen</em>*</p></li>
<li><p>Allows the LLM to search the internet via Google and access the textual content of websites in a controlled manner. Also includes specialized query tools for Pubmed, Pubchem, and Wikipedia.</p></li>
<li><p>Enables the LLM agent to query Parquet files, Neo4j knowledge graphs, and GraphQL APIs using SQL, Cypher and GraphQL codegen in a secure context. The database agents are very capable and can answer complex, open-ended scientific questions using these data sources.</p></li>
<li><p>Enables the LLM agent to use local foundation models, such as Google’s TxGemma model for pharmaceutical applications, for instance for predicting solubility of small molecules.</p></li>
<li><p>Uses multimodal LLMs to accurately diagnose cancer histopathology images with very comprehensive pathology reports that investigate architectural and cytological Features of H&amp;E slides.</p></li>
<li><p>Makes it easy to give the LLM new R tool capabilities (basically all R functions), share tools via MCP (built-in pure R MCP server), or utilize tools of external MCP server as internal tools (via a MCP tool wrapper).</p></li>
<li><p>Supports dynamic tool creation and registration during runtime.</p></li>
<li><p>Provides a framework for defining custom tools and integrating them seamlessly with the LLM.</p></li>
</ul>
<p>We are internally using the package for the following usecases:</p>
<ul>
<li><em>Supported usecase</em>*</li>
</ul>
<ol type="1">
<li><p>Extracting results of statistical analyses from office documents: The vignettes show how to configure an agentic LLM to extract chunks oftext from documents and tables, semantically query a vector store (agent-based retrieval-augmented generation, RAG), load JSON definitions, extract JSON-structured data from documents, and validate these definitions against a user-defined JSON template. {llumen} can be utilized to extract results data from a large corpus of clinical trial results files. Templates for both CDISC Analysis Result Standard (ARS) and the {llumen} Analysis Result Schema (LARS) are provided.</p></li>
<li><p>Querying tabular databases and knowledge graphs: {llumen} excels at SQL codegen, allowing users to query very large Parquet files located on the user’s device and perform complex data analyses. It also supports querying Neo4j knowledge graphs and GraphQL APIs, enabling comprehensive data exploration and analysis.</p></li>
<li><p>Working with biological foundation models: {llumen}’s ability to use local foundation models specialized for particular biological or pharmaceutical applications, such as Google’s GemmaTX, enhances agentic LLMs with specialized capabilities for tasks like predicting molecular properties or analyzing biological pathways.</p></li>
<li><p>Automated literature review and summarization: {llumen} can be used to perform comprehensive literature reviews by searching multiple databases (e.g., PubMed, OpenAlex), extracting relevant information, and generating structured summaries of findings.</p></li>
<li><p>Histopathology image analysis: The package supports the use of multimodal LLMs for analyzing histopathology images, providing detailed reports on architectural and cytological features of H&amp;E slides, which can aid in cancer diagnosis and research.</p></li>
<li><p>Drug discovery and development support: By integrating various tools and databases (e.g., PubChem, TxGemma), {llumen} can assist in various stages of drug discovery, from initial compound screening to predicting drug properties and potential interactions.</p></li>
<li><p>Clinical trial data analysis and reporting: {llumen}’s capabilities in extracting and structuring data from various document types make it well-suited for analyzing and reporting on clinical trial data, potentially accelerating the process of deriving insights from trial results.</p></li>
<li><p>Biomedical knowledge graph exploration: The package’s ability to query knowledge graphs allows researchers to explore complex relationships in biomedical data, potentially uncovering new insights or research directions.</p></li>
<li><p>Automated scientific writing assistance: {llumen} can be used to assist in scientific writing tasks, such as generating literature summaries, creating structured abstracts, or even drafting sections of scientific papers based on analyzed data and literature.</p></li>
<li><p>Regulatory document preparation and analysis: The package’s capabilities in extracting and structuring information from various document types can be applied to preparing and analyzing regulatory documents in the pharmaceutical industry</p></li>
</ol>
<p>Presentation related link:</p>
<p><a href="https://drive.google.com/file/d/1g0_O_wSoeBHzeXl6DF3-NIY7gT2Bk62_/view" class="uri">https://drive.google.com/file/d/1g0_O_wSoeBHzeXl6DF3-NIY7gT2Bk62_/view</a></p>
</section>
<section id="build-model-context-protocol-servers-and-clients-in-r" class="level3">
<h3 class="anchored" data-anchor-id="build-model-context-protocol-servers-and-clients-in-r"><strong>Build Model Context Protocol servers and clients in R</strong></h3>
<p>John Coene (Opifex).</p>
<p>The mcpr package provides a comprehensive R implementation of the Model Context Protocol (MCP), a standardized JSON-RPC 2.0 interface that enables R applications to expose computational capabilities to AI models. This package bridges the gap between R’s statistical computing environment and modern AI assistants by allowing R developers to create MCP servers that expose tools, resources, and prompts as well as client functionality to interact with existing MCP servers.</p>
<p>Key features include schema-based tool definitions, multi-modal response support, and seamless integration with popular AI development environments including Claude Code, Cursor, and VS Code. This implementation democratizes AI-R integration by providing a standards-based approach to exposing R’s extensive ecosystem to conversational AI interfaces, opening new possibilities for interactive data analysis and statistical computing workflows.</p>
<section id="europeus-session-4" class="level4">
<h4 class="anchored" data-anchor-id="europeus-session-4"><strong>Europe/US Session #4</strong></h4>
</section>
</section>
<section id="mosaic-open-source-ars-driven-automation-of-standard-tfls" class="level3">
<h3 class="anchored" data-anchor-id="mosaic-open-source-ars-driven-automation-of-standard-tfls"><strong>Mosaic: Open-Source, ARS-Driven Automation of Standard TFLs</strong></h3>
<p>Conor Moloney (Novartis).</p>
<p>CDISC standards help streamline datasets (e.g.&nbsp;SDTM and ADaM), yet analysis results lack a common model. The emerging Analysis Results Standard (ARS) will help to fill this gap with machine-readable specifications. Mosaic couples ARS with an open-source stack to generate fully validated standard TFLs, fast and reproducibly.</p>
<p>How it works</p>
<p>Mosaic captures the Analysis Results Dataset (ARD) requirement in ARS-aligned YAML; updates and changes are made by editing this metadata, not code. After LinkML validation, a Python layer stores the YAML in a database via a SQL Alchemy ORM engine. The results-generation layer is intentionally language-agnostic . The rules that transform ADaM datasets into the ARD are expressed as metadata that can be rendered in any statistical language. Mosaic’s implementation uses R to derive the ARD.</p>
<p>A React UI reads the validated ARD. Here, users have controlled customisation options. Users can preview each TFL shell in real time and export regulator-ready RTF files suitable for submission packages.</p>
<p>Mosaic replaces ad-hoc programming with a transparent, standards-based pipeline, accelerating TFL delivery while safeguarding traceability and regulatory compliance. This reallocates programmer effort from repetitive coding to high-value scientific review</p>
</section>
<section id="integrating-collaborative-programming-with-automated-traceability-and-reproducibility-in-pharma" class="level3">
<h3 class="anchored" data-anchor-id="integrating-collaborative-programming-with-automated-traceability-and-reproducibility-in-pharma"><strong>Integrating Collaborative Programming with Automated Traceability and Reproducibility in Pharma</strong></h3>
<p>Jennifer Dusendang (Graticule Inc) and Sundeep Bath (Graticle Inc).</p>
<p>Integrating Collaborative Programming with Automated Traceability and Reproducibility in Pharma Studies and Real-World Data Projects by Adapting DevOps Best-Practices</p>
<p>To enhance integrity of research and study findings, data scientists should ensure that studies are traceable and reproducible, which involves meticulous management of datasets, tracking code changes, and robust storage of results.</p>
<p>Without infrastructure to support reproducibility efforts, documentation, dependency management, and version control processes can be manual, unreliable, and unclear. This creates problems with determining when analysis changes occurred, which version of study results were produced by which version of code, and whether all study steps are processed in proper order and appropriately documented.</p>
<p>Implementing procedures and technical infrastructure helps to maintain and automate reproducibility and traceability. To ensure that code can be executed consistently across multiple compute environments, we structure analysis scripts into parameterized pipelines within an isolated Docker container environment which specifies all versions and dependencies. We integrate Continuous Integration (CI) and Continuous Delivery (CD) into analysis pipelines to enable automatic rerunning of analyses following code modifications and storage of results in the cloud. Our process integrates and improves collaborative programming by providing code reviewers with the validated outputs that are produced by the code. By design, study close-out and compliance activities are incorporated within our infrastructure.</p>
<p>In this paper we will discuss how we implemented and adapted DevOps best-practices like CI/CD in a collaborative coding environment to work for epidemiological studies and real-world data projects. Although the concepts discussed are applicable to many tools, our implementation uses Git, GitHub Actions, SQL, Python, R, Docker, and AWS S3. This content is applicable for all skill levels.</p>
<p><a href="https://www.lexjansen.com/pharmasug/2025/OS/PharmaSUG-2025-OS-111.pdf" class="uri">https://www.lexjansen.com/pharmasug/2025/OS/PharmaSUG-2025-OS-111.pdf</a></p>
</section>
<section id="tabpfn-a-deep-learning-solution-for-tabular-data" class="level3">
<h3 class="anchored" data-anchor-id="tabpfn-a-deep-learning-solution-for-tabular-data"><strong>TabPFN: A Deep-Learning Solution for Tabular Data</strong></h3>
<p>Max Kuhn (Posit).</p>
<p>There have been numerous proposals for deep neural networks for tabular data, such as rectangular data sets (e.g., data frames). To date, none have really worked well and take far too long to train. TabPFN is a model that emulates a Bayesian approach and trains a deep learning model on a prior of simulated tabular datasets. Version 2 was released this year and offers several significant advantages, but also has one notable disadvantage. I’ll introduce this model and show an example.</p>
<p><a href="https://topepo.github.io/2025-r-pharma/#/title-slide" class="uri">https://topepo.github.io/2025-r-pharma/#/title-slide</a></p>
</section>
<section id="the-llm-lounge-live-coding-and-conversation-on-using-ai-for-data-science" class="level3">
<h3 class="anchored" data-anchor-id="the-llm-lounge-live-coding-and-conversation-on-using-ai-for-data-science"><strong>The LLM Lounge: Live-coding and conversation on using AI for data science</strong></h3>
<p><strong>Joe Cheng</strong></p>
<p>Posit</p>
<p><strong>Eric Nantz</strong></p>
<p>Eli Lilly</p>
<p>The number of workflows and tools leveraging large-language-models (LLMs) is growing exponentially across the world, and the life sciences industry is no exception. In this session, Eric Nantz takes the role of the curious and savvy data scientist as he is joined by Posit CTO Joe Cheng in a special live demonstration on using Databot to power an exploratory data science analysis. Throughout the demonstration, Joe will share the fascinating origin story of how Databot came to be, along with a deeper conversation on the recent trends and guiding principles of harnessing AI tools for data analyses and software engineering. This interactive, spontaneous format will allow the audience to submit questions and steer the direction of the session, making it a truly engaging, shared experience.</p>
<p><a href="https://github.com/posit-dev/querychat" class="uri">https://github.com/posit-dev/querychat</a></p>
</section>
<section id="llm-powered-gtsummary-qc-ready-clinical-tables-in-minutes" class="level3">
<h3 class="anchored" data-anchor-id="llm-powered-gtsummary-qc-ready-clinical-tables-in-minutes"><strong>LLM-Powered {gtsummary}: QC-Ready Clinical Tables in Minutes</strong></h3>
<p><strong>Davide Garolini</strong></p>
<p>Data Scientist, NEST, Roche</p>
<p>He significantly contributes to the NEST project by improving key tools like {gtsummary} and {rtables} for regulatory compliance.</p>
<p>Open-source R tooling has made table generation easy, yet interpreting the code and guaranteeing bullet-proof QC can still delay submissions. We present a workflow that fuses {gtsummary} for rapid table building with cards for “automatic” validation, topped by a fully offline, model-agnostic LLM helper. Starting on synthetic CDISC-like data, we create a standard summary table, validate it with {cards}, and ask the LLM-helper to explain each step and result and propose, if necessary, next steps—all without revealing trial data. A descriptive log is generated on the fly, combining code, QC results, and LLM explanations in one auditor-friendly document. When real data arrive, the same script reruns unchanged, delivering submission-ready tables in minutes while boosting clarity and compliance.</p>
</section>
<section id="post-approval-drug-exposure-estimation-using-an-r-shiny-app" class="level3">
<h3 class="anchored" data-anchor-id="post-approval-drug-exposure-estimation-using-an-r-shiny-app"><strong>Post-Approval Drug Exposure Estimation Using an R Shiny App</strong></h3>
<p><strong>Feifei Yang</strong></p>
<p>AstraZeneca</p>
<p><strong>Yu Zhang</strong></p>
<p>AstraZeneca</p>
<p><strong>Background</strong></p>
<p>Regulatory authorities require product post-marketing exposure estimates in aggregate safety reports for purposes of signal detection. The calculation of exposure estimates requires multiple data sources between sales data and aggregated de-identified patient data. Traditionally, the calculations were manually handled due to limited countries, products, and indications. With the growth of both markets and products, manual calculations are inefficient to handle the increasing volume of data and regional requests. An approach to automating the entire process has become essential.</p>
<p><strong>Method</strong></p>
<p>R Shiny App is a web application framework that allows us to create interactive web applications for data analysis, data visualization, and interactive reports, making it easier to share data insights with others. We converted monthly patient and sales report into an app-readable format and applied an exposure estimate algorithm to perform calculations by region, product, and indication.</p>
<p><strong>Results</strong></p>
<p>The time to generate a standard report of post-marketing exposure data for regulatory purposes has been reduced from a week to one day. The QC function of application helps check inconsistent numbers from month to month in sales and patient data. In addition to the exposure report, the visualization provided by the application shows trends in sales, patient utilization of products, and exposure by year and geographic regions. The sharing ability of the application enables other team members to generate customized report directly without any prerequisite training.</p>
<p><strong>Conclusion</strong></p>
<p>The application significantly improves the efficiency of delivering post-marketing exposure data and reduces time and resources needed for data management and QC. Accessibility to the application helps disseminate the information to a broader range of teams and functions.</p>
</section>
<section id="implementing-an-end-to-end-nca-software-using-shiny" class="level3">
<h3 class="anchored" data-anchor-id="implementing-an-end-to-end-nca-software-using-shiny"><strong>Implementing an end-to-end NCA software using Shiny</strong></h3>
<p><strong>Gerardo Jose Rodriguez</strong></p>
<p>Lucid Analytics</p>
<p><strong>Jana Spinner</strong></p>
<p>Lucid Analytics</p>
<p>Pharmacokinetic studies are essential yet demanding, typically relying on expensive proprietary software for Non-Compartmental Analysis (NCA). aNCA is an alternative developed collaboratively by Roche, Lucid Analytics, Appsilon, and Human Predictions. It is being developed within Pharmaverse, aiming to become a worldwide standard by utilizing open source development to make the process more efficient, economical, and transparent. The app performs an end-to-end approach, using interactive plots for data exploration, half life customization, TLGs, and report generation.aNCA is planned to be released on CRAN soon. It currently reaches 100% of testing coverage on its functions and has successfully passed internal package validations.</p>
<p>aNCA uses PKNCA, a widely used package that calculates over 200 PK parameters, has been tested against other industry-standard NCA software, showing differences within ±0.1% for most tested parameters.</p>
<p>We aim to present aNCA, highlight its innovative software concepts, discuss how we tackled key challenges, and showcase how open source and Shiny achieve industry-standard PK software. However, we welcome suggestions on focus areas for the R/Pharma audience.</p>
<p>If you want to know more about aNCA, feel free to follow the link to our GitHub: <a href="https://github.com/pharmaverse/aNCA" class="uri">https://github.com/pharmaverse/aNCA</a></p>
</section>
<section id="integrating-llm-using-r-shiny-for-clinical-data-review-by-ensuring-data-privacy-and-validity" class="level3">
<h3 class="anchored" data-anchor-id="integrating-llm-using-r-shiny-for-clinical-data-review-by-ensuring-data-privacy-and-validity"><strong>Integrating LLM using R Shiny for Clinical Data Review by Ensuring Data Privacy and Validity</strong></h3>
<p><strong>Zhen Wu</strong></p>
<p>CIMS Global</p>
<p><strong>Peng Zhang</strong></p>
<p>CIMS Global</p>
<p>The pharmaceutical industry is shifting from traditional SAS-based workflows toward the open-source R ecosystem. R Shiny applications have become a popular solution for visualizing tables, figures, and listings. However, these applications often require a strong understanding of data structures and familiarity with interface components such as dropdowns, which may not be intuitive for clinical reviewers. Recent advancements in artificial intelligence (AI), particularly large language models (LLMs), have opened new possibilities for how users interact with clinical data. In this session, we present an innovative R Shiny application, {DataChat}, that enables users to “chat with data” through a conversational interface. Powered by the {ellmer}, {shinychat}, and {ragnar} packages, along with internal statistical tools and utilities, the app integrates retrieval-augmented generation (RAG) capabilities tailored to the pharmaceutical domain. The solution emphasizes user-friendliness, enabling non-programmers and clinicians to explore datasets and derive insights while maintaining compliance with data privacy requirements and addressing concerns around statistical validity. This approach exemplifies the potential of AI-augmented tools to enhance clinical data review and exploration in a practical and accessible way</p>
</section>
<section id="r-we-there-yet-admirals-journey-transitioning-from-active-development-to-stability" class="level3">
<h3 class="anchored" data-anchor-id="r-we-there-yet-admirals-journey-transitioning-from-active-development-to-stability"><strong>R we there yet? {admiral}’s journey transitioning from active development to stability</strong></h3>
<p><strong>Edoardo Mancini</strong></p>
<p>Roche</p>
<p>If you are attending R/Pharma 2025, you probably enjoy actively contributing to open source R packages for the pharma industry. Fixing bugs, implementing new features and expanding the use-case is work that feels motivating and meaningful. However, what happens if/when your package reaches a point of stability and maturity, where the main use-case is answered and feature completeness is in sight? How can you sustain your development team’s momentum without chasing perfection, in a time where the active workload is naturally diminished? What should your new priorities be?</p>
<p>While there is no definitive answer to any of these questions, this talk will discuss the evolution of packages like {admiral} as they transition from active development to mature maintenance, drawing insights from the {admiral} team’s experiences in navigating this complex shift.</p>
</section>
<section id="workshop-r-classification-unleashing-predictive-power-with-tidymodels" class="level3">
<h3 class="anchored" data-anchor-id="workshop-r-classification-unleashing-predictive-power-with-tidymodels"><strong>Workshop: R-Classification: Unleashing Predictive Power with tidymodels</strong></h3>
<ul>
<li><strong>Harshavardhan Bajoria</strong></li>
</ul>
<p>Dive into the exciting world of classification with R and the elegant tidymodels framework! This hands-on workshop provides a comprehensive introduction to building, evaluating, and refining machine learning models that predict categorical outcomes. You’ll learn to preprocess your data effectively using recipes, split datasets for robust model training and testing with rsample, define and fit various classification algorithms using parsnip, and assess model performance using a suite of metrics from yardstick. Through practical exercises, including a wine classification challenge, you’ll gain the skills to tackle real-world predictive problems and make data-driven decisions using the consistent and intuitive tidymodels ecosystem.</p>
</section>
<section id="workshop-a-guided-tour-to-building-and-integrating-llm-based-tooling-with-r" class="level3">
<h3 class="anchored" data-anchor-id="workshop-a-guided-tour-to-building-and-integrating-llm-based-tooling-with-r"><strong>Workshop: A Guided Tour to Building and Integrating LLM Based Tooling with R</strong></h3>
<p><strong>Devin Pastoor</strong></p>
<p>Chief Technology and Product Officer, A2-AI</p>
<p><strong>Xu Fei</strong></p>
<p>Xu Fei is a Senior Solutions Engineer at A2-Ai, where he builds AI-powered tools and infrastructure for pharmaceutical research workflows. Working across R and Python stacks, he has developed LLM-enabled applications ranging from interactive chatbots to MCP server implementations, with a focus on making GenAI accessible and practical for scientific computing teams. His work bridges enterprise DevOps, cloud APIs (AWS Bedrock), and domain-specific R and Python packages to help scientists integrate AI capabilities into their existing workflows</p>
<p><strong>Aathira Anil Kumar</strong></p>
<p>A2-Ai</p>
<p>Join A2-AI engineers, Aathira Anil Kumar, Devin, and Xu Fei, for a practical, 2-hour workshop demonstrating how to integrate Generative AI (GenAI) into pharmaceutical workflows. This session focuses on bridging the R and Python ecosystems to deliver scalable, GxP-compliant solutions.</p>
<p>You will learn methodology for developing LLM-enabled applications—from interactive chatbots for clinical study reporting and SOP management, to more complex MCP server implementations for reproducible analytics. Drawing on their extensive experience with life-science organizations and tools like AWS Bedrock, the instructors will showcase how to navigate real-world IT constraints while making GenAI accessible and practical for scientific computing teams. This workshop is essential for analysts, developers, and project leaders aiming to stand up GxP-compliant statistical computing environments with integrated AI capabilities.</p>
<section id="europeus-session-5" class="level4">
<h4 class="anchored" data-anchor-id="europeus-session-5"><strong>Europe/US Session #5</strong></h4>
</section>
</section>
<section id="gsks-journey-to-clinical-study-reporting-using-open-source" class="level3">
<h3 class="anchored" data-anchor-id="gsks-journey-to-clinical-study-reporting-using-open-source"><strong>GSK’s journey to Clinical Study Reporting Using Open Source</strong></h3>
<p><strong>Sam Warden</strong></p>
<p>VP &amp; Global Head, Clinical Programming &amp; Business Excellence</p>
<p>GSK</p>
<p><strong>Tim Colman</strong></p>
<p>GSK</p>
<p>GSK’s Journey to Clinical Study Reporting Using Open Source chronicles the transformation of clinical reporting at GSK, the presentation marks pivotal moments in the pharmaceutical industry’s evolution—from the proprietary, SAS-dominated era of the 1980s and 90s, through the pain of rising R&amp;D costs and global health crises, to the emergence of collaborative models and open-source innovation.</p>
<p>The story highlights how industry challenges catalyzed a shift toward openness and collaboration. Key milestones include the FDA’s clarification on software neutrality, the rise of R and open-source platforms, and GSK’s commitment to writing at least 50% of code in open-source languages. The COVID-19 pandemic accelerated this transformation, driving rapid adoption of data science platforms and collaborative tools.</p>
<p>GSK’s multi-wave approach to change is shared and candidly addresses ongoing challenges: technical validation, regulatory uncertainty, cultural resistance, and the need for robust governance and training.</p>
<p>Ultimately, the journey demonstrates that embracing open-source technologies enables greater automation, and innovation in clinical study reporting. Success depends on a growth mindset, adaptability, and a vision for collaborative transformation—qualities that GSK continues to foster as it leads the industry into a new era of transparency and shared progress.</p>
<section id="europeus-session-6" class="level4">
<h4 class="anchored" data-anchor-id="europeus-session-6"><strong>Europe/US Session #6</strong></h4>
</section>
</section>
<section id="leveraging-ellmer-and-gpt-to-integrate-ai-agents-into-shiny-applications-for-accelerating-trials" class="level3">
<h3 class="anchored" data-anchor-id="leveraging-ellmer-and-gpt-to-integrate-ai-agents-into-shiny-applications-for-accelerating-trials"><strong>Leveraging ellmer and GPT to Integrate AI Agents into Shiny Applications for Accelerating Trials</strong></h3>
<p><strong>Xing Chen</strong></p>
<p>Moderna</p>
<p><strong>Xiaolin Chang</strong></p>
<p>Moderna</p>
<p>Background:</p>
<p>Artificial intelligence is transforming drug development, but its integration into biostatistics and clinical workflows remains limited. Clinical and biometrics teams often face barriers in exploring high-dimensional, multi-view trial datasets, requiring technical expertise to extract insights and generate visualizations.</p>
<p>Methods:</p>
<p>We developed an AI-enhanced R Shiny application that integrates ellmer with ChatGPTs. The app connects to Cellular-Mediated Immunogenicity (CMI) data across multiple mRNA infectious disease programs. Natural language queries are translated into structured R operations, through which users can interactively explore and visualize data, eliminating the need for manual coding.</p>
<p>Results:</p>
<p>The application successfully handled unstructured user queries, generated targeted outputs, and produced customizable visualizations. Pilot deployment across infectious disease programs demonstrated faster extraction of trial insights, reduced dependency on ad-hoc programming</p>
<p>support, and invigorates collaboration between statisticians, clinicians, and translational researchers.</p>
<p>Conclusions:</p>
<p>Embedding AI agents via ellmer within Shiny applications provides a scalable, user-friendly framework for accelerating exploratory analyses in vaccine development. This approach demonstrates how AI-assisted analytics can increase efficiency, strengthen cross-functional decision-making, and support broader adaptation of GenAI into clinical development workflows.</p>
</section>
<section id="autoslider-streamlining-slide-deck-generation-for-clinical-reporting-events" class="level3">
<h3 class="anchored" data-anchor-id="autoslider-streamlining-slide-deck-generation-for-clinical-reporting-events"><strong>autoslideR: Streamlining slide deck generation for clinical reporting events</strong></h3>
<p>Yolanda Zhou (Roche) and Joe Zhu (Roche).</p>
<p>The standard process of developing the slide deck for clinical reporting events includes manually populating numbers from static outputs and a separate QC. The process is time-consuming, resource-intensive, and error-prone. To address these issues, we created “autoslideR”, an R package to automate the slide deck generation for multiple clinical reporting events. autoslideR has successfully supported slide creation for several study endorsement meetings, IMC meetings, as well as dose escalation meetings for early development, saving teams 0.5 to 4 days for the slide deck preparation compared to the time it traditionally takes.</p>
<p>This talk explores the key features and technical advantages of autoslideR, such as supporting customized layout creations from existing templates, as well as adding placeholder slides to accelerate final slide preparation.</p>
<p><a href="https://pharmaverse.github.io/examples/digit_files/autoslider.html" class="uri">https://pharmaverse.github.io/examples/digit_files/autoslider.html</a></p>
</section>
<section id="putting-the-r-in-rwd" class="level3">
<h3 class="anchored" data-anchor-id="putting-the-r-in-rwd"><strong>Putting the ‘R’ in RWD</strong></h3>
<p>Sachin Heerah (Pfizer) and Darren Jeng (Pfizer).</p>
<p>The Pfizer Real World Data (RWD) programming team has leveraged R and Posit services to enhance the capabilities of its programmers. We have designed an R package, Shiny apps and even a Quarto website to support all programmers with varying backgrounds, including those with only SAS experience. Our R package is designed to simplify database queries, utilize both R and SAS variable syntax, and standardize deliverables. We have leveraged Posit’s RStudio features such as code snippets to make code templates readily accessible for all users within the IDE. Code guides are also presented as snippets to allow all users to load example data and explore standard RWD programming workflows. Overall, embracing and leveraging the features available to us in R and Posit is enhancing our workflow through integrated resources and documentation.</p>
</section>
<section id="generating-synthetic-data-with-synthpop-in-r" class="level3">
<h3 class="anchored" data-anchor-id="generating-synthetic-data-with-synthpop-in-r"><strong>Generating Synthetic Data with synthpop in R</strong></h3>
<p>Sophie Furlow (Abbot Diagnostics).</p>
<p>This talk will introduce synthetic data as an emerging tool for research and production. We will discuss the differences between synthetic, simulated, and resampled data and cover the current state of the art of synthetic data in healthcare, paying special attention to applications in pharma and diagnostics. We will walk through the basics of synthpop, an R package designed to generate synthetic and anonymous data at the individual level using various machine learning algorithms. Viewers will learn how to create entirely synthetic datasets with minimal statistical distortion their original data, making it suitable for software testing, data sharing, and model training. The talk will end with a demonstration of synthpop’s quality evaluation features and major caveats to consider during the generation process.</p>
<section id="europeus-session-7" class="level4">
<h4 class="anchored" data-anchor-id="europeus-session-7"><strong>Europe/US Session #7</strong></h4>
</section>
</section>
<section id="genai-in-production---moving-beyond-prototypes" class="level3">
<h3 class="anchored" data-anchor-id="genai-in-production---moving-beyond-prototypes"><strong>GenAI in Production - moving beyond prototypes</strong></h3>
<p><strong>Devin Pastoor</strong></p>
<p><strong>Chief Technology and Product Officer, A2-Ai</strong></p>
<p>Creation of AI applications has become increasingly commoditized through a rich ecosystem of R and python packages. However, there are significant hurdles to take a prototype application into “production” and keep it operating. Traditional testing and validation approaches do not always apply directly and the flexibility from which users can interact with the application can be much larger than a traditional application. This talk will discuss how to successfully (and unsuccessfully) develop, test, release, and maintain Generative AI based applications in GxP contexts.</p>
</section>
<section id="building-the-ultimate-r-ai-assistant" class="level3">
<h3 class="anchored" data-anchor-id="building-the-ultimate-r-ai-assistant"><strong>Building the Ultimate R AI Assistant</strong></h3>
<p><strong>Pawel Rucki</strong></p>
<p>Principal Data Scientist, Roche</p>
<p>Using R for clinical programming can be challenging, particularly with the specialized, often internal, packages used for reporting. To tackle these issues, we built our own AI assistant.</p>
<p>In this talk, I’ll share our story of building a multi-agent R co-pilot with the LangGraph framework, including the lessons we learned and a few tricks we picked up. A key decision was giving each R package its own AI agent. This was a game-changer for getting good help on our internal packages where general-purpose LLMs just can’t keep up.</p>
<p>I’ll discuss our agent network architecture and the practical techniques used to give agents the right context to write, debug, and explain complex R code for clinical trials. I’ll wrap up with a live demo showing how our design solves real-world programming problems, speeding up development and leading to better, more reliable code.</p>
<p>(agents, cursor via mcp, webR extenstion, admiralroche, air AI assistant for programming in R)</p>
<section id="europeus-session-8" class="level4">
<h4 class="anchored" data-anchor-id="europeus-session-8"><strong>Europe/US Session #8</strong></h4>
</section>
</section>
<section id="the-dependency-whisperer-ai-that-sees-what-you-might-miss" class="level3">
<h3 class="anchored" data-anchor-id="the-dependency-whisperer-ai-that-sees-what-you-might-miss"><strong>The Dependency Whisperer: AI That Sees What You Might Miss</strong></h3>
<p><strong>Ming Yan</strong></p>
<p>Eli Lilly</p>
<p><strong>Vina Ro</strong></p>
<p>Sr.&nbsp;Clinical Data Analyst, Eli Lilly</p>
<p>An ongoing challenge in clinical programming is ensuring that downstream analyses are accurately refreshed following updates to SDTM or ADaM datasets. Traditional tools like AstroGrep can locate references to specific datasets or variables, but they lack the ability to distinguish between active code and commented text. Moreover, identifying indirect dependencies often requires multiple searches and manual effort to document all affected areas, which is time-consuming and increases the risk of missing updates—potentially leading to incorrect outputs being shared with external parties.</p>
<p>This paper introduces an AI-powered tool designed to automatically identify and visualize all datasets and variables impacted by upstream changes. By parsing SDTM, ADaM, and TFL specifications or programs, the tool learns the structure of dependencies across the analysis pipeline. When a user specifies an updated variable and dataset, the tool generates a graphical report highlighting all affected elements. This capability streamlines the refresh process, reduces manual effort, and ensures the accuracy and completeness of deliverables.</p>
</section>
<section id="bayesertools-r-package-for-exposure-response-analysis-with-bayesian-approaches" class="level3">
<h3 class="anchored" data-anchor-id="bayesertools-r-package-for-exposure-response-analysis-with-bayesian-approaches"><strong>BayesERtools: R package for exposure-response analysis with Bayesian approaches</strong></h3>
<p><strong>Kenta Yoshida</strong></p>
<p>Clinical Pharmacology Modeling &amp; Simulation, Genentech</p>
<p>Exposure-response (ER) analysis is a critical component of clinical drug development for decisions such as dose selection. The new R package, BayesERtools (<a href="https://genentech.github.io/BayesERtools/" class="uri">https://genentech.github.io/BayesERtools/</a>), is designed to make Bayesian ER analysis more accessible. It provides a user-friendly interface for common tasks such as model development, simulation, and plotting, streamlining the entire workflow. The package currently supports linear and Emax models for continuous and binary endpoints. To further support users, we have also developed BayesERbook (<a href="https://genentech.github.io/BayesERbook/" class="uri">https://genentech.github.io/BayesERbook/</a>), a comprehensive online book that documents the workflow with typical examples. This open-source project, based on the Stan ecosystem, aims to expand the use of Bayesian methods in pharma, providing a powerful tool for quantitative decision-making in drug development.</p>
</section>
<section id="adapting-to-regulatory-guidance-covariate-adjustment-and-r-enabled-submissions" class="level3">
<h3 class="anchored" data-anchor-id="adapting-to-regulatory-guidance-covariate-adjustment-and-r-enabled-submissions"><strong>Adapting to Regulatory Guidance: Covariate Adjustment and R-enabled Submissions</strong></h3>
<p><strong>Alex Przybylski</strong></p>
<p><strong>Data scientist @ Novartis</strong></p>
<p>FDA guidance released in 2023 advocates for covariate adjustment as a non-controversial means to enhance the efficiency of statistical analyses. This includes specific recommendations featuring recently proposed methods from academic groups, providing an opportunity for sponsors to realize the practical benefits of innovative approaches. However, they also present challenges for trial teams regarding practical implementation. Bridging the gap between academia, regulation and industry adoption is essential.</p>
<p>This talk presents a case study from Novartis, where FDA feedback referencing the new guidance prompted a targeted and strategic response. We will discuss how we responded to this feedback, our preparation for future regulatory expectations, and the role of R in enabling change and impact.</p>
<p>The case study will highlight lightweight R package solutions ({beeca}) and the work of the ASA-BIOP Covariate Adjustment Working Group ({RobinCar2}). We will discuss the importance of software that is suited for integration with trial analysis workflows in regulated environments and the benefits of collaborating within the open-source community.</p>
</section>
<section id="r-library-validation-using-acceptance-test-driven-development" class="level3">
<h3 class="anchored" data-anchor-id="r-library-validation-using-acceptance-test-driven-development"><strong>R library validation using Acceptance-Test Driven Development</strong></h3>
<p><strong>Brian Repko</strong></p>
<p>Retired (ex-Novartis Biomedical Research Oncology Data Science), Retired (ex-Novartis)</p>
<p>Europe/US</p>
<p>While unit tests are a key component of a single R package’s quality, we need similar ways to test / validate a library of R packages or potentially Shiny applications. This session will walk through frameworks used for Acceptance-Test Driven Development (ATDD) and Behavior Driven Development (BDD) outside of R - cucumber, JBehave, etc. - how they work and their value-add to system quality. In short, tests are written in Quarto markdown, in a “given-when-then” format that is regex-matched against annotated functions that drive the testing and asserting of the system under test. The industry can write tests in plain-language and share those tests and feature code not only amongst themselves but also potentially as part of a validation effort with regulators. Feature code can also make use of packages like {chromote} to drive Shiny applications as well. This is bringing my experience as a contributor to JBehave to R and the pharmaverse.</p>
</section>
<section id="workshop-r-validation-discussion-metric-repos-for-open-quality-assessment" class="level3">
<h3 class="anchored" data-anchor-id="workshop-r-validation-discussion-metric-repos-for-open-quality-assessment"><strong>WORKSHOP: R Validation Discussion: Metric Repos for Open Quality Assessment</strong></h3>
<p><strong>Doug Kelkhoff</strong></p>
<p>Over the past year, the R Validation Hub has been hard at work to build out a Metric Repository - a pre-built database of metrics to support the software validation process. We’d like to invite you to discuss the industry outlook for this open validation database. How do we standardize our compute environments to make metrics useful? What do we do when a package isn’t living up to our standards? What can we do to ensure that you can supplement our database with the validation of in-house packages? We’d love to share our answers and hear your thoughts to help guide our work. Come join us and discuss the future of R package validation.</p>
<p>Workshop related packages:</p>
<p>riskmetric, riskassessment, riskscore</p>
<p>Workshop related links:</p>
<p><a href="https://github.com/pharmaR/regulatory-r-repo-wg" class="uri">https://github.com/pharmaR/regulatory-r-repo-wg</a></p>
<p><a href="https://github.com/pharmaR/val.meter" class="uri">https://github.com/pharmaR/val.meter</a></p>
<p><a href="https://github.com/pharmaR/val.criterion" class="uri">https://github.com/pharmaR/val.criterion</a></p>
</section>
<section id="workshop-datasetjson---read-and-write-cdisc-dataset-json-formatted-datasets-in-r-and-python" class="level3">
<h3 class="anchored" data-anchor-id="workshop-datasetjson---read-and-write-cdisc-dataset-json-formatted-datasets-in-r-and-python"><strong>WORKSHOP: datasetjson - Read and write CDISC Dataset JSON formatted datasets in R and Python</strong></h3>
<p>Michael Stackhouse Chief Innovation Officer, Atorus Sam Hume Research Data Engineer | Open Source | Data Exchange Standards, CDSIC Nick Masel Associate Director Innovation Team Lead, Johnson &amp; Johnson Eli Miller Senior Manager, Cloud Solutions, Atorus What? Join us for an engaging workshop designed to introduce Dataset-JSON, a powerful format for sharing datasets. We’ll start with an environment setup and explore the motivation behind choosing Dataset-JSON over other formats like Parquet. The session will include a detailed walkthrough of the Dataset-JSON specification, followed by hands-on demonstrations and exercises in both R and Python.</p>
<p>Discover how to implement Dataset-JSON in your workflows, learn about upcoming adoption plans, and explore future roadmap and API integrations. This workshop is perfect for data professionals interested in improving dataset interoperability and sharing standards.</p>
<p><a href="https://atorus-research.github.io/datasetjson/" class="uri">https://atorus-research.github.io/datasetjson/</a></p>
<p><a href="https://atorus-research.github.io/datasetjson_workshop/" class="uri">https://atorus-research.github.io/datasetjson_workshop/</a></p>
</section>
<section id="workshop-sdtm-programming-in-r-using-sdtm.oak-package" class="level3">
<h3 class="anchored" data-anchor-id="workshop-sdtm-programming-in-r-using-sdtm.oak-package"><strong>WORKSHOP: SDTM programming in R using {sdtm.oak} package</strong></h3>
<p><strong>Rammprasad Ganapathy</strong></p>
<p>Principal Data Scientist</p>
<p>The {sdtm.oak} package is an EDC (Electronic Data Capture) and data standard-agnostic solution designed to empower the pharmaceutical programming community to develop CDISC SDTM datasets using R. By leveraging reusable algorithms, {sdtm. oak} offers a modular programming framework that can potentially automate the creation of SDTM datasets based on standard SDTM specifications. In this workshop, we will cover the fundamentals of the V0.1 {sdtm.oak} package and provide detailed guidance for programmers to begin utilizing it effectively.</p>
<p>Users will be given access to an R environment for the session. Users do not need to install R or other tools/packages prior to the session.</p>
<p>Workshop related link:</p>
<p><a href="https://pharmaverse.github.io/rinpharma-SDTM-workshop/#/title-slide" class="uri">https://pharmaverse.github.io/rinpharma-SDTM-workshop/#/title-slide</a></p>
</section>
<section id="workshop-python-for-clinical-study-report-and-submission" class="level3">
<h3 class="anchored" data-anchor-id="workshop-python-for-clinical-study-report-and-submission"><strong>WORKSHOP: Python for Clinical Study Report and Submission</strong></h3>
<p><strong>Nan Xiao</strong></p>
<p>Statistician at Merck, Merck</p>
<p><strong>Yilong Zhang</strong></p>
<p>Biostatistician at Meta, Meta</p>
<p>Open-source programming languages are rapidly transforming drug discovery, research, and development, offering powerful capabilities for study design, data analysis, visualization, and clinical reporting. This workshop introduces practical strategies for using Python to prepare tables, listings, and figures (TLFs) in a clinical study report (CSR) and to assemble submission-ready electronic Common Technical Document (eCTD) packages that include both source code and deliverables.</p>
<p>This workshop is designed for clinical programmers, statisticians, and data scientists who are interested in exploring Python as an alternative approach for clinical trial analysis and reporting. Participants will gain hands-on experience with reproducible workflows, clinical data engineering, and end-to-end project management using the modern Python toolchain. By the end of the session, attendees will have a clear roadmap to start a Python project for clinical trial analysis and reporting.</p>
<p>The workshop is based on the open source book&nbsp;<em>Python for Clinical Study Reports and Submission</em>&nbsp;(<a href="https://pycsr.org/" class="uri">https://pycsr.org/</a>) and is organized into four modules:</p>
<ol type="1">
<li><p>Python environment setup: Use&nbsp;uv&nbsp;to create and manage reproducible Python projects. Develop and collaborate in GitHub Codespaces, Visual Studio Code, or Positron.</p></li>
<li><p>Python packages for clinical reporting: A guided tour of essential packages such as&nbsp;polars,&nbsp;plotnine, and&nbsp;rtflite, with demonstrations of creating TLFs commonly used in clinical trials.</p></li>
<li><p>Manage a clinical trial A&amp;R project: Practical project structure, conventions, and execution from data to deliverables.</p></li>
<li><p>Preparing eCTD submission packages: An example workflow for assembling submission-ready source code and outputs using&nbsp;py-pkglite, aligned with eCTD requirements.</p></li>
</ol>
<p><a href="https://pycsr.org/slides/workshop-slides.html#/datasets" class="uri">https://pycsr.org/slides/workshop-slides.html#/datasets</a></p>
<p>Publicly available CDISC pilot study data located at the CDISC GitHub repository.</p>
<p>The dataset structure follows the CDISC Analysis Data Model (ADAM).</p>
<p>Source data: <a href="https://github.com/elong0527/r4csr/tree/main/data-adam" class="uri">https://github.com/elong0527/r4csr/tree/main/data-adam</a></p>
<p>Converted parquet data: <a href="https://github.com/nanxstats/pycsr/tree/main/data" class="uri">https://github.com/nanxstats/pycsr/tree/main/data</a></p>
<p>Workshop Slides:</p>
<p><a href="https://pycsr.org/slides/workshop-slides.html#" class="uri">https://pycsr.org/slides/workshop-slides.html#</a></p>
<p><a href="https://github.com/nanxstats/pycsr" class="uri">https://github.com/nanxstats/pycsr</a></p>
</section>
<section id="workshop-supercharge-your-shiny-app-by-offloading-computations-to-a-hpc-cluster" class="level3">
<h3 class="anchored" data-anchor-id="workshop-supercharge-your-shiny-app-by-offloading-computations-to-a-hpc-cluster"><strong>WORKSHOP: Supercharge your shiny app by offloading computations to a HPC cluster</strong></h3>
<p><strong>Michael Mayer</strong></p>
<p>Principal Solution Engineer at Posit , Posit PBC</p>
<p>With ever increasing complexity of data and analysis, application developers are tempted to put in serious computations into their shiny applications. Given that those shiny applications typically run on infrastructure that has certain resource limitations or sometimes even shared with other shiny apps, more often than not this leads to crashes affecting the overall stability of the system. As a consequence, either other approaches are pursued, or the approach simplified to the point that good science is prevented from happening.&nbsp;in this workshop you will learn how to interact with a remote HPC cluster straight from your laptop. You will run a shiny app locally and remote submit pieces of code to the HPC cluster. By leveraging a multiple of your locally available compute power for a short period of time, you will reduce&nbsp; time-to-result considerably keeping the app fairly interactive. This approach also can be used to connect applications hosted on a Shiny Hosting platform such as Posit Connect to a HPC cluster.&nbsp;In the second part of the workshop you will be able to discuss with the workshop instructor(s) your own use cases and get insights on how to address those.</p>
</section>
<section id="workshop-bayesian-survival-and-multistate-models-using-r-and-stan" class="level3">
<h3 class="anchored" data-anchor-id="workshop-bayesian-survival-and-multistate-models-using-r-and-stan"><strong>WORKSHOP: Bayesian Survival and Multistate Models using R and Stan</strong></h3>
<p><strong>Eric Novik</strong></p>
<p>Founder &amp; CEO @ Generable, Generable</p>
<p><strong>Jacqueline Buros-Novik</strong></p>
<p>Generable</p>
<p><strong>Juho Timonen</strong></p>
<p>Computational Scientist, Generable</p>
<p>Bayesian inference and Stan offer many advantages for analyzing time-to-event data, including incorporating prior knowledge into the model, propagating all sources of uncertainty to produce well-calibrated predictions, and integrating arbitrary utility functions for optimal decision-making, such as patients’ preferences for different types of risks. The latter point is particularly relevant in multistate models where people may differ in their preferences towards multiple competing <a href="http://events.In">events.In</a> this workshop, we will briefly introduce Bayesian workflow – the typical steps in Bayesian analysis and basic (single-event) survival models in the Bayesian context. We will then proceed to introduce multistate models where we are tracking multiple event types, such as bleeding and stroke in cardiovascular trials, or stable disease, progressive disease, and death in oncology trials. Time permitting, we will demonstrate how to incorporate the patient’s utility function into a decision analysis.</p>
<p>Workshop related link:</p>
<p><a href="https://github.com/generable/bmstate" class="uri">https://github.com/generable/bmstate</a></p>
</section>
<section id="workshop-from-data-to-insights-a-hands-on-workshop-with-teal-for-clinical-data-exploration" class="level3">
<h3 class="anchored" data-anchor-id="workshop-from-data-to-insights-a-hands-on-workshop-with-teal-for-clinical-data-exploration"><strong>WORKSHOP: From Data to Insights: A Hands-On Workshop with {teal} for Clinical Data Exploration</strong></h3>
<p><strong>Nina Qi</strong></p>
<p>Principal Data Scientist at Genentech, Roche/Genentech</p>
<p><strong>Dony Unardi</strong></p>
<p>Data Scientist at Genentech, Roche/Genentech</p>
<p>{teal} is an innovative open-source R-Shiny framework that has transformed how clinical trial data is analyzed and visualized in recent years. By streamlining the creation of interactive web applications, it enables R programmers and data scientists to deliver insights faster while promoting efficiency, transparency, and reproducibility in data exploration.&nbsp;This hands-on workshop, built on the latest {teal} 1.0 release, will start from the basics and progressively cover practical topics for building {teal} applications. Together, we will explore key features of {teal} and work through step-by-step exercises designed to build confidence and proficiency in {teal} programming. No prior experience with {teal} or attendance at previous workshops is required - all R users are welcome.&nbsp;Designed to deepen participants’ understanding of the {teal} framework, this session will equip attendees with the skills to leverage the {teal} ecosystem to create scalable, reproducible applications that accelerate insight generation in clinical research.</p>
<p>Workshop related link:</p>
<p><a href="https://github.com/pharmaverse/tealworkshop-rinpharma2025/tree/main" class="uri">https://github.com/pharmaverse/tealworkshop-rinpharma2025/tree/main</a></p>
</section>
</section>
<section id="presentations" class="level1">
<h1>Presentations</h1>
<section id="open-source-culture-and-data-strategy-in-shionogi-a-new-value-creation-model-for-pharma" class="level3">
<h3 class="anchored" data-anchor-id="open-source-culture-and-data-strategy-in-shionogi-a-new-value-creation-model-for-pharma">[<strong>Open-Source Culture and Data Strategy in SHIONOGI: A New Value-Creation Model for Pharma</strong>]</h3>
<ul>
<li>[<strong>Yoshitake Kitanishi</strong>]</li>
</ul>
</section>
<section id="strategically-assisting-statistical-programmers-to-succeed-in-r-sas2r" class="level3">
<h3 class="anchored" data-anchor-id="strategically-assisting-statistical-programmers-to-succeed-in-r-sas2r">[<strong>Strategically Assisting Statistical programmers To succeed in R (SAS2R)</strong>]</h3>
<ul>
<li>[<strong>KuenHung Lin</strong>]</li>
</ul>
</section>
<section id="side-by-side-by-design-pharma-data-handling-with-merge-join-match-and-hash-in-r" class="level3">
<h3 class="anchored" data-anchor-id="side-by-side-by-design-pharma-data-handling-with-merge-join-match-and-hash-in-r">[<strong>Side-by-side by Design: Pharma Data Handling with Merge, Join, Match, and Hash in R</strong>]</h3>
<ul>
<li><p>[<strong>Yutaka Morioka</strong>]</p></li>
<li><p>[<strong>Yuki Nakagawa</strong>]</p></li>
</ul>
</section>
<section id="risk-assessment-deep-dive" class="level3">
<h3 class="anchored" data-anchor-id="risk-assessment-deep-dive">[<strong>Risk Assessment Deep Dive</strong>]</h3>
<ul>
<li>[<strong>Ryo Nakaya</strong>]</li>
</ul>
</section>
<section id="leverage-template-based-automated-reporting-on-dmc-materials-preparation" class="level3">
<h3 class="anchored" data-anchor-id="leverage-template-based-automated-reporting-on-dmc-materials-preparation">[<strong>Leverage template-based automated reporting on DMC materials preparation</strong>]</h3>
<ul>
<li><p>[<strong>Nina Han</strong>]</p></li>
<li><p>[<strong>Peng Zhang</strong>]</p></li>
</ul>
</section>
<section id="dynamic-creation-of-kaplan-meier-plots-and-summary-measure-tables-for-survival-data-with-r-shiny" class="level3">
<h3 class="anchored" data-anchor-id="dynamic-creation-of-kaplan-meier-plots-and-summary-measure-tables-for-survival-data-with-r-shiny">[<strong>Dynamic Creation of Kaplan-Meier Plots and Summary Measure Tables for Survival Data with R Shiny</strong>]</h3>
<ul>
<li><p>[<strong>Takumi Imamura</strong>]</p></li>
<li><p>[<strong>Takahiro Hasegawa</strong>]</p></li>
</ul>
</section>
<section id="autoslider-streamlining-slide-deck-generation-for-clinical-reporting-events-1" class="level3">
<h3 class="anchored" data-anchor-id="autoslider-streamlining-slide-deck-generation-for-clinical-reporting-events-1">[<strong>autoslideR: Streamlining slide deck generation for clinical reporting events</strong>]</h3>
<ul>
<li><p>[<strong>Yolanda Zhou</strong>]</p></li>
<li><p>[<strong>Joe Zhu</strong>]</p></li>
</ul>
</section>
<section id="from-harmony-to-hybrid-charting-a-practical-course-for-r-adoption-in-pharma" class="level3">
<h3 class="anchored" data-anchor-id="from-harmony-to-hybrid-charting-a-practical-course-for-r-adoption-in-pharma">[<strong>From Harmony to Hybrid: Charting a Practical Course for R Adoption in Pharma</strong>]</h3>
<ul>
<li>[<strong>Joe Zhu</strong>]</li>
</ul>
</section>
<section id="emerging-trend-of-llm-development-in-r-and-implementation" class="level3">
<h3 class="anchored" data-anchor-id="emerging-trend-of-llm-development-in-r-and-implementation">[<strong>Emerging trend of LLM development in R and implementation</strong>]</h3>
<ul>
<li><p>[<strong>Mia Chen</strong>]</p></li>
<li><p>[<strong>Peng Zhang</strong>]</p></li>
</ul>
</section>
<section id="an-r-package-to-consolidate-pretest-probability-models-and-guidelines-for-cad" class="level3">
<h3 class="anchored" data-anchor-id="an-r-package-to-consolidate-pretest-probability-models-and-guidelines-for-cad">[<strong>An R package to consolidate pretest probability models and guidelines for CAD</strong>]</h3>
<ul>
<li>[<strong>Jeremy Selva</strong>]</li>
</ul>
</section>
<section id="enhancing-efficiency-in-e-crt-creation-for-pmda-through-r-shiny-app-development-using-vibe-coding" class="level3">
<h3 class="anchored" data-anchor-id="enhancing-efficiency-in-e-crt-creation-for-pmda-through-r-shiny-app-development-using-vibe-coding">[<strong>Enhancing Efficiency in e-CRT Creation for PMDA Through R Shiny App Development Using Vibe Coding</strong>]</h3>
<ul>
<li>[<strong>Naoki Yoshida</strong>]</li>
</ul>
</section>
<section id="merlin---context-aware-ai-assistant-for-clinical-programming" class="level3">
<h3 class="anchored" data-anchor-id="merlin---context-aware-ai-assistant-for-clinical-programming">[<strong>{meRlin} - context-aware AI assistant for clinical programming</strong>]</h3>
<ul>
<li><p>[<strong>Steven Brooks</strong>]</p></li>
<li><p>[<strong>Pietro Mascheroni</strong>]</p></li>
<li><p>[<strong>Xiecheng Gu</strong>]</p></li>
</ul>
</section>
<section id="improving-precision-healthcare-for-under-represented-and-genetically-diverse-global-populations" class="level3">
<h3 class="anchored" data-anchor-id="improving-precision-healthcare-for-under-represented-and-genetically-diverse-global-populations">[<strong>Improving precision healthcare for under-represented and genetically diverse global populations</strong>]</h3>
<ul>
<li>[<strong>Jimmy Breen</strong>]</li>
</ul>
</section>
<section id="exploring-ai-tools-in-clinical-trial-data-analysis" class="level3">
<h3 class="anchored" data-anchor-id="exploring-ai-tools-in-clinical-trial-data-analysis">[<strong>Exploring AI tools in clinical trial data analysis</strong>]</h3>
<ul>
<li>[<strong>Terry Zhang</strong>]</li>
</ul>
</section>
<section id="an-r-package-cgmguru-for-automated-glycemic-event-detection-from-continuous-glucose-monitoring-data" class="level3">
<h3 class="anchored" data-anchor-id="an-r-package-cgmguru-for-automated-glycemic-event-detection-from-continuous-glucose-monitoring-data">[<strong>An R Package cgmguru for Automated Glycemic Event Detection From Continuous Glucose Monitoring Data</strong>]</h3>
<ul>
<li>[<strong>Sang Ho Park</strong>]</li>
</ul>
</section>
<section id="interactive-and-reproducible-reports-with-quarto" class="level3">
<h3 class="anchored" data-anchor-id="interactive-and-reproducible-reports-with-quarto">[<strong>Interactive and Reproducible Reports with Quarto</strong>]</h3>
<ul>
<li>[<strong>Jaspreet Pabla</strong>]</li>
</ul>
</section>
<section id="using-analysis-results-data-using-cards-for-pmda-oncology-inqueries" class="level3">
<h3 class="anchored" data-anchor-id="using-analysis-results-data-using-cards-for-pmda-oncology-inqueries">[<strong>Using Analysis Results Data using {cards} for PMDA Oncology inqueries</strong>]</h3>
<ul>
<li>[<strong>Shunsuke Goto</strong>]</li>
</ul>
</section>
<section id="reach-for-r-low-hanging-fruit-for-faster-results" class="level3">
<h3 class="anchored" data-anchor-id="reach-for-r-low-hanging-fruit-for-faster-results">[<strong>Reach for R Low Hanging Fruit for Faster Results</strong>]</h3>
<ul>
<li>[<strong>Sunil Gupta</strong>]</li>
</ul>
</section>
<section id="medxr-package---bridging-regulatory-drug-data-from-the-fda-and-health-canada-into-r" class="level3">
<h3 class="anchored" data-anchor-id="medxr-package---bridging-regulatory-drug-data-from-the-fda-and-health-canada-into-r">[<strong>MedxR Package - Bridging Regulatory Drug Data from the FDA and Health Canada into R</strong>]</h3>
<ul>
<li>[<strong>Renzo Cáceres Rossi</strong>]</li>
</ul>
</section>
<section id="risk.assessr-extending-its-use-in-the-package-validation-process" class="level3">
<h3 class="anchored" data-anchor-id="risk.assessr-extending-its-use-in-the-package-validation-process">[<strong>risk.assessr: extending its use in the package validation process</strong>]</h3>
<ul>
<li>[<strong>Hugo Bottois</strong>]</li>
</ul>
</section>
<section id="code-review-for-compliance-best-practices-for-validated-r-workflows-in-pharma" class="level3">
<h3 class="anchored" data-anchor-id="code-review-for-compliance-best-practices-for-validated-r-workflows-in-pharma">[<strong>Code Review for Compliance: Best Practices for Validated R Workflows in Pharma</strong>]</h3>
<ul>
<li>[<strong>Alexandros Kouretsis</strong>]</li>
</ul>
</section>
<section id="a-web-based-r-application-for-forecasting-patient-enrollment-in-clinical-trials" class="level3">
<h3 class="anchored" data-anchor-id="a-web-based-r-application-for-forecasting-patient-enrollment-in-clinical-trials">[<strong>A Web-Based R Application for Forecasting Patient Enrollment in Clinical Trials</strong>]</h3>
<ul>
<li><p>[<strong>Akifumi Okayama</strong>]</p></li>
<li><p>[<strong>Motoki Oe</strong>]</p></li>
<li><p>[<strong>Nobushige Matsuoka</strong>]</p></li>
</ul>


<!-- -->

</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
            // default icon
            link.classList.add("external");
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># R-Pharma-2025-Workshops</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">### **WORKSHOP: Flexible Clinical Trial Design, Simulation, and Analysis with the R Package rpact**</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>**Daniel Sabanes Bove** Entrepreneur in Biostatistics Consulting and Engineering, RCONIS</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>**Friedrich Pahlke** Tech Entrepreneur <span class="sc">\|</span> Driving Innovation in R/Shiny</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>In this workshop we will explore the capabilities of the validated open-source R package 'rpact', which is available on CRAN and GitHub. rpact is a comprehensive validated, open source, free-of-charge R software package for clinical trial planning, design simulation, and data analysis. rpact is under continuous full-time development since 2017, and comprehensive documentation is available at&nbsp;<span class="co">[</span><span class="ot">www.rpact.org</span><span class="co">](http://www.rpact.org/)</span>. We will provide an introduction to the package and illustrate the usage by several examples. The focus of the package is on group sequential and adaptive designs with p-value combination tests, but also fixed sample designs can be considered. The software can specifically be used to assess design characteristics of popular group sequential designs. However, going beyond those, adaptive designs are a strength of rpact: Adaptive multi-armed and population enrichment designs that are based on closed combination tests can be assessed by simulation. The application of the designs for simulation, real data, and estimation is possible for continuous, binary, survival, and count data. Furthermore, we introduce 'RPACT Cloud', a user-friendly platform designed to simplify and enhance the process of clinical trial design and simulations for researchers and practitioners. A free version of RPACT Cloud is available at&nbsp;<span class="ot">&lt;https://cloud.rpact.com/&gt;</span>&nbsp;and workshop participants will be able to try out the software themselves following the workshop.</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>Link to the presentation: <span class="ot">&lt;https://rpharma.presentation.2025.rpact.com/&gt;</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="fu">### **WORKSHOP: Debugging Stan Programs**</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>**Daniel Lee**</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>Data Scientist, Bayesian statistician, Stan developer</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>Having trouble getting your Stan models to behave? This hands-on workshop will explore practical strategies for debugging Stan code, from identifying non-identifiable parameters to improving runtime performance. Participants will gain tools and intuition for building more robust models—skills that extend to a wide range of statistical and stochastic programming tasks.Prerequisite: Familiarity with Stan is recommended.</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>Workshop related link: <span class="ot">&lt;https://github.com/bayesianops/stan-tutorials/tree/main/debugging-2025-11-03&gt;</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="fu">### **WORKSHOP: Introduction to building (better) R packages**</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>**Nicola Rennie**</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>Data Visualisation Specialist</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>There are many benefits to turning your R scripts or functions into a package, like making your code easier to re-use, easier to share with others, easier to document, and easier to test. But the process of writing a package can feel intimidating, especially if you haven't done it before. But it doesn't need to! In this interactive workshop, we'll discuss:<span class="sc">\*</span> What things you need to make a package and how to create them<span class="sc">\*</span> How to write functions (in a package-friendly way) and add them to a package<span class="sc">\*</span> How to write documentation and examples for functions<span class="sc">\*</span> Best practices for package development<span class="sc">\*</span> How to share your package with other people<span class="sc">\*</span> Useful resources. By the end of this workshop, you will have made an R package! The session aims to be introductory, so you don't need any previous experience of building R packages (or even writing functions!) but some basic knowledge of R will be useful. If you're already a seasoned R package developer, you're also welcome to attend and hopefully you'll still pick up a few package development tips!</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>Workshop related link: <span class="ot">&lt;https://nrennie.rbind.io/r-pharma-2025-r-packages/#/title-slide&gt;</span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="fu">### **WORKSHOP: Getting Started with LLM APIs in R**</span></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>**Sara Altman**</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>Data Science Educator</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>Posit PBC</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>LLMs are transforming how we write code, build tools, and analyze data, but getting started with directly working with LLM APIs can feel daunting. This workshop will introduce participants to programming with LLM APIs in R using ellmer, an open-source package that makes it easy to work with LLMs from R. We’ll cover the basics of calling LLMs from R, as well as system prompt design, tool calling, and building basic chatbots.</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>No AI or machine learning background is required—just basic R familiarity. Participants will leave with example scripts they can adapt to their own projects.</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>Workshop related link: <span class="ot">&lt;https://skaltman.github.io/r-pharma-llm/&gt;</span></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a><span class="fu">### **WORKSHOP: Hands on with Cardinal: Harmonizing Clinical Reporting with Open‑Source TLGs**</span></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>**Abinaya Yogasekaram**</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>Bioinformatics <span class="sc">\|</span> Software Development <span class="sc">\|</span> Data Science</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>Amaris Consulting</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>**Emily De La Rua**</span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>Data Scientist at Roche</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>Cardinal is an open-source collection of standardized table, listing, and graph (TLG) templates designed to streamline the process of clinical output review, comparison, and meta-analysis—promoting efficient communication to stakeholders while aligning with CDISC’s ARD/ARM efforts.</span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a>In this workshop, we’ll introduce the {gtsummary} package for table creation and walk through Cardinal’s growing catalog of TLGs. Participants will get hands-on experience generating key outputs—ideally working on examples that are directly relevant to your own work.</span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a>Whether you're new to Cardinal, looking to integrate it into your own workflow, or interested in contributing to the project, this workshop will provide practical insights and real-world applications for modern clinical reporting.</span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a>Workshop related link: <span class="ot">&lt;https://pharmaverse.github.io/cardinal/&gt;</span></span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a><span class="fu">### **WORKSHOP: Advanced Clinical Reporting with officer and flextable**</span></span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a>**David Gohel**</span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">**Advanced Clinical Reporting with officer and flextable**</span><span class="co">](https://rinpharma.com/docs/RPH2025/#)</span></span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a>In this workshop you will be working with the officer and flextable packages to create sophisticated clinical reports in Word format using R with a reproducible approach. Going from clinical data all the way through to complete pharmaceutical report generation. Specifically, we will walk through an end-to-end example focusing on advanced document structure management, complex table creation following pharmaceutical standards, and integration of ggplot2 visualizations. The workshop is divided into two parts: first, discovering the fundamentals of officer and flextable packages, then moving to advanced clinical reporting techniques including section management, headers and footers customization, and cross-reference handling for complete pharmaceutical report composition.</span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a>Workshop related links:</span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a><span class="ot">&lt;https://ardata.fr/r-in-pharma-2025/&gt;</span></span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a><span class="ot">&lt;https://github.com/ardata-fr/r-in-pharma-2025-codes&gt;</span></span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a><span class="ot">&lt;https://github.com/ardata-fr/r-in-pharma-reporting-with-officer-flextable&gt;</span></span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a><span class="fu">### **WORKSHOP: Creating Polished, Branded Documents with Quarto**</span></span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a>**Isabella Velásquez**</span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a>Sr. Product Marketing Manager</span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a>Posit PBC</span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a>Join us for a hands-on, one-day workshop at R/Phama, where we’ll explore the versatility of Quarto output formats. You will learn how to create dynamic websites, professional PDF documents, engaging presentations, and interactive dashboards using Quarto. This workshop highlights Quarto's powerful theming capabilities, including the new support for brand.yml, which ensures that your work maintains a professional and cohesive style across all formats.</span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a>Workshop related links:</span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a><span class="ot">&lt;https://019a4f2d-6b79-72c1-834b-c2a9488f9ec8.share.connect.posit.cloud/&gt;</span></span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a><span class="ot">&lt;https://github.com/ivelasq/2025-11-04_branded-quarto&gt;</span></span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a><span class="fu">### **WORKSHOP: Polars: The Blazing Fast Python Framework for Modern Clinical Trial Data Exploration**</span></span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a>**Michael Chow**</span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a>Principal Software Engineer at Posit (Open Source)</span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a>Posit</span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a>**Jeroen Janssens**</span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a>Head of Developer Relations</span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a>Posit PBC</span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-113"><a href="#cb1-113" aria-hidden="true" tabindex="-1"></a>Clinical trials generate complex and standards driven datasets that can slow down traditional data processing tools. This workshop introduces Polars, a cutting-edge Python DataFrame library engineered with a high-performance backend and the Apache Arrow columnar format for blazingly fast data manipulation. Attendees will learn how Polars lays the foundation for the pharmaverse-py, streamlining the data clinical workflow from database querying and complex data wrangling to the potential task of prepping data for regulatory Tables, Figures, and Listings (TFLs). Discover the 'delightful' Polars API and how its speed dramatically accelerates both exploratory and regid data tasks in pharmaceutical drug development. The workshop is led by Michael Chow, a Python developer at Posit who is a key contributor to open-source data tools, notably helping to launch the data presentation library Great Tables, and focusing on bringing efficient data analysis patterns to Python.</span>
<span id="cb1-114"><a href="#cb1-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-115"><a href="#cb1-115" aria-hidden="true" tabindex="-1"></a>Workshop related link:</span>
<span id="cb1-116"><a href="#cb1-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-117"><a href="#cb1-117" aria-hidden="true" tabindex="-1"></a><span class="ot">&lt;https://github.com/machow/examples-great-tables-pharma&gt;</span></span>
<span id="cb1-118"><a href="#cb1-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-119"><a href="#cb1-119" aria-hidden="true" tabindex="-1"></a><span class="fu">### **WORKSHOP: How to use pointblank to understand, validate, and document your data**</span></span>
<span id="cb1-120"><a href="#cb1-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-121"><a href="#cb1-121" aria-hidden="true" tabindex="-1"></a>**Rich Iannone**</span>
<span id="cb1-122"><a href="#cb1-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-123"><a href="#cb1-123" aria-hidden="true" tabindex="-1"></a>Software Engineer at Posit PBC</span>
<span id="cb1-124"><a href="#cb1-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-125"><a href="#cb1-125" aria-hidden="true" tabindex="-1"></a>This workshop will focus on the data quality and data documentation workflows that the pointblank package makes possible. We will use functions that allow us to:</span>
<span id="cb1-126"><a href="#cb1-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-127"><a href="#cb1-127" aria-hidden="true" tabindex="-1"></a><span class="sc">\(</span>1<span class="sc">\)</span> quickly understand a new dataset</span>
<span id="cb1-128"><a href="#cb1-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-129"><a href="#cb1-129" aria-hidden="true" tabindex="-1"></a><span class="sc">\(</span>2<span class="sc">\)</span> validate tabular data using rules that are based on our understanding of the data</span>
<span id="cb1-130"><a href="#cb1-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-131"><a href="#cb1-131" aria-hidden="true" tabindex="-1"></a><span class="sc">\(</span>3<span class="sc">\)</span> fully document a table by describing its variables and other important details. The pointblank package was created to scale from small validation problems (“Let’s make certain this table fits my expectations before moving on”) to very large (“Let’s validate these 35 database tables every day and ensure data quality is maintained”) and we’ll delve into all sorts of data quality scenarios so you’ll be comfortable using this package in your organization. Data documentation is seemingly and unfortunately less common in organizations (maybe even less than the practice of data validation). We’ll learn all about how this doesn’t have to be a tedious chore. The pointblank package allows you to create informative and beautiful data documentation that will help others understand what’s in all those tables that are so vital to an organization.</span>
<span id="cb1-132"><a href="#cb1-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-133"><a href="#cb1-133" aria-hidden="true" tabindex="-1"></a>Workshop related link:</span>
<span id="cb1-134"><a href="#cb1-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-135"><a href="#cb1-135" aria-hidden="true" tabindex="-1"></a><span class="ot">&lt;https://github.com/rich-iannone/pointblank-workshop&gt;</span></span>
<span id="cb1-136"><a href="#cb1-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-137"><a href="#cb1-137" aria-hidden="true" tabindex="-1"></a><span class="fu">#### **Europe/US Session #1**</span></span>
<span id="cb1-138"><a href="#cb1-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-139"><a href="#cb1-139" aria-hidden="true" tabindex="-1"></a><span class="fu">### **Practical AI for data science**</span></span>
<span id="cb1-140"><a href="#cb1-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-141"><a href="#cb1-141" aria-hidden="true" tabindex="-1"></a>Simon Couch (Posit). Practical AI for data science</span>
<span id="cb1-142"><a href="#cb1-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-143"><a href="#cb1-143" aria-hidden="true" tabindex="-1"></a>While most discourse about AI focuses on glamorous, ungrounded applications, data scientists spend most of their days tackling unglamorous problems in sensitive data. Integrated thoughtfully, LLMs are quite useful in practice for all sorts of everyday data science tasks, even when restricted to secure deployments that protect proprietary information. At Posit, our work on ellmer and related R packages has focused on enabling these practical uses. This talk will outline three practical AI use-cases—structured data extraction, tool calling, and coding—and offer guidance on getting started with LLMs when your data and code is confidential.</span>
<span id="cb1-144"><a href="#cb1-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-145"><a href="#cb1-145" aria-hidden="true" tabindex="-1"></a><span class="ot">&lt;https://github.com/simonpcouch&gt;</span></span>
<span id="cb1-146"><a href="#cb1-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-147"><a href="#cb1-147" aria-hidden="true" tabindex="-1"></a><span class="fu">#### **Europe/US Session #2**</span></span>
<span id="cb1-148"><a href="#cb1-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-149"><a href="#cb1-149" aria-hidden="true" tabindex="-1"></a><span class="fu">### **duckplyr: Analyze large data with DuckDB and dplyr compatibility**</span></span>
<span id="cb1-150"><a href="#cb1-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-151"><a href="#cb1-151" aria-hidden="true" tabindex="-1"></a>Kirill Muller (Cynkra).</span>
<span id="cb1-152"><a href="#cb1-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-153"><a href="#cb1-153" aria-hidden="true" tabindex="-1"></a>The duckplyr package is now stable; version 1.1.2 is on CRAN. It builds on top of DuckDB, a fast and flexible analytical engine that can work with larger-than-memory data from disk or cloud storage. All these features are available to duckplyr, with syntax and semantics much closer to R and the tidyverse. Use it to speed up existing code, to analyze Parquet or CSV files directly, or to access the plethora of exciting functionality provided by DuckDB.</span>
<span id="cb1-154"><a href="#cb1-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-155"><a href="#cb1-155" aria-hidden="true" tabindex="-1"></a><span class="fu">### **Beyond Training: Evolving Strategies to Teach and Support R Adoption in Pharma**</span></span>
<span id="cb1-156"><a href="#cb1-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-157"><a href="#cb1-157" aria-hidden="true" tabindex="-1"></a>Alanah Jonas (GSK).</span>
<span id="cb1-158"><a href="#cb1-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-159"><a href="#cb1-159" aria-hidden="true" tabindex="-1"></a>Teaching R effectively is just the starting point for lasting adoption in pharma. At GSK, we began by developing two core R courses written in bookdown and delivered interactively, an approach that enabled high completion rates.</span>
<span id="cb1-160"><a href="#cb1-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-161"><a href="#cb1-161" aria-hidden="true" tabindex="-1"></a>Recognizing that training alone isn't enough, we expanded support through options like self-certification, intermediate courses, and a Resource Hub. We also launched AccelerateR to provide tailored support to early adopters during their transition.</span>
<span id="cb1-162"><a href="#cb1-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-163"><a href="#cb1-163" aria-hidden="true" tabindex="-1"></a>Today, those efforts have scaled and evolved into Rburst, a cross-functional initiative designed not just to teach R, but to embed it into our ways of working across all of Biostatistics.</span>
<span id="cb1-164"><a href="#cb1-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-165"><a href="#cb1-165" aria-hidden="true" tabindex="-1"></a>This talk will explore how our training strategy has matured into a broader support model, enabling wide-scale, integrated adoption of R in everyday work.</span>
<span id="cb1-166"><a href="#cb1-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-167"><a href="#cb1-167" aria-hidden="true" tabindex="-1"></a><span class="fu">### **Validating Shiny Apps in Regulated Environments**</span></span>
<span id="cb1-168"><a href="#cb1-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-169"><a href="#cb1-169" aria-hidden="true" tabindex="-1"></a>Pedro Silva (Jumping Rivers).</span>
<span id="cb1-170"><a href="#cb1-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-171"><a href="#cb1-171" aria-hidden="true" tabindex="-1"></a>Shiny apps are increasingly used to deliver interactive tools in clinical and healthcare settings. But when these tools are used in regulated environments, validation becomes essential. How can we ensure that our Shiny apps are trustworthy, without stifling innovation?</span>
<span id="cb1-172"><a href="#cb1-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-173"><a href="#cb1-173" aria-hidden="true" tabindex="-1"></a>In this talk we’ll explore practical approaches to validating Shiny applications in regulated contexts, drawing on principles from software engineering, quality assurance, and risk based validation. We’ll discuss key challenges like traceability, documentation, and versioning, as well as share techniques for building apps that are easier to validate from the start.</span>
<span id="cb1-174"><a href="#cb1-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-175"><a href="#cb1-175" aria-hidden="true" tabindex="-1"></a>I’ll highlight some of the tools and packages used in Jumping Rivers that can support validation workflows that satisfies both internal reviewers and external regulators, including the Litmusverse, a suite of R packages designed to assess code quality and generate validation evidence.</span>
<span id="cb1-176"><a href="#cb1-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-177"><a href="#cb1-177" aria-hidden="true" tabindex="-1"></a>By the end of the session, you’ll understand: - Why validation is critical for Shiny apps in regulated contexts; - What elements make a Shiny app more or less validatable; - How to incorporate validation strategies into your development process.</span>
<span id="cb1-178"><a href="#cb1-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-179"><a href="#cb1-179" aria-hidden="true" tabindex="-1"></a>This session is ideal for R users in pharma, clinical research, and healthcare who want to build confidence in their dashboards, while maintaining flexibility in how they work.</span>
<span id="cb1-180"><a href="#cb1-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-181"><a href="#cb1-181" aria-hidden="true" tabindex="-1"></a><span class="fu">### **Beyond {gtsummary}: How the {crane} Package Extends the Framework for Pharmaceutical Reporting**</span></span>
<span id="cb1-182"><a href="#cb1-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-183"><a href="#cb1-183" aria-hidden="true" tabindex="-1"></a>Daniel Sjoberg (Genentech) and Davide Garolini (Genentech).</span>
<span id="cb1-184"><a href="#cb1-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-185"><a href="#cb1-185" aria-hidden="true" tabindex="-1"></a>{gtsummary} has become the most-used R package for clinical tables in the R ecosystem, winning awards from the American Statistical Association and Posit. Building on this foundation, we created {crane}, an open-source extension that facilitates reporting requirements in the pharmaceutical space. Because {crane} and {gtsummary} are built upon Analysis Results Datasets (ARDs), study teams can take advantage of this foundation that streamlines the QC process and allows for simple re-use of calculated results in subsequent reporting.</span>
<span id="cb1-186"><a href="#cb1-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-187"><a href="#cb1-187" aria-hidden="true" tabindex="-1"></a>In this session we show how: (1) a vanilla {gtsummary} script instantly upgrades when {crane} is loaded; (2) ARD-based outputs make QC a straightforward operation; (3) LLMs can summarise the language-agnostic ARD results for medical writers in seconds. You’ll leave with a blueprint of how to adapt {crane} for your reporting needs or (or roll your own) and shorten table turnaround on day one.</span>
<span id="cb1-188"><a href="#cb1-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-189"><a href="#cb1-189" aria-hidden="true" tabindex="-1"></a><span class="ot">&lt;https://www.danieldsjoberg.com/RinPharma-crane-2025/&gt;</span></span>
<span id="cb1-190"><a href="#cb1-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-191"><a href="#cb1-191" aria-hidden="true" tabindex="-1"></a><span class="ot">&lt;https://github.com/ddsjoberg/RinPharma-crane-2025/tree/main&gt;</span></span>
<span id="cb1-192"><a href="#cb1-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-193"><a href="#cb1-193" aria-hidden="true" tabindex="-1"></a><span class="ot">&lt;https://github.com/cynkra/r-in-pharma-2025/&gt;</span></span>
<span id="cb1-194"><a href="#cb1-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-195"><a href="#cb1-195" aria-hidden="true" tabindex="-1"></a><span class="ot">&lt;https://docs.google.com/presentation/d/1atV5rBLQF2vcCg2lraiutg_Xx2BOEklZzf9LJt842ig/edit?usp=sharing&gt;</span></span>
<span id="cb1-196"><a href="#cb1-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-197"><a href="#cb1-197" aria-hidden="true" tabindex="-1"></a><span class="fu">#### **Europe/US Session #3**</span></span>
<span id="cb1-198"><a href="#cb1-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-199"><a href="#cb1-199" aria-hidden="true" tabindex="-1"></a><span class="fu">### **{llumen}: An agentic LLM framework for biomedical documents, databases &amp; foundation models**</span></span>
<span id="cb1-200"><a href="#cb1-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-201"><a href="#cb1-201" aria-hidden="true" tabindex="-1"></a>Sven-Eric Schelhorn (lumen).</span>
<span id="cb1-202"><a href="#cb1-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-203"><a href="#cb1-203" aria-hidden="true" tabindex="-1"></a>We introduce {llumen}, an R package used at Merck KGaA, Darmstadt, Germany that implements an agentic framework bases on {ellmer} and enables pharmaceutical researchers to work with biomedical documents, large real-world evidence and biomarker databases, as well as with biological foundation models using large language models as orchestrators.</span>
<span id="cb1-204"><a href="#cb1-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-205"><a href="#cb1-205" aria-hidden="true" tabindex="-1"></a>{llumen} currently supports the following functionalities:</span>
<span id="cb1-206"><a href="#cb1-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-207"><a href="#cb1-207" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>*Large language models*<span class="sc">\*</span></span>
<span id="cb1-208"><a href="#cb1-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-209"><a href="#cb1-209" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Runs on standard company laptops (Windows, Linux, or macOS).</span>
<span id="cb1-210"><a href="#cb1-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-211"><a href="#cb1-211" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Allows using a wide range of private (Azure), public (OpenAI, Anthropic, Bedrock), and local (llama.cpp) LLMs.</span>
<span id="cb1-212"><a href="#cb1-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-213"><a href="#cb1-213" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Provides both programmatic and fully interactive (chatbot) ways to interact with the LLM.</span>
<span id="cb1-214"><a href="#cb1-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-215"><a href="#cb1-215" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Supports chain-of-thoughts, tree-of-thoughts, and ReAct reasoning strategies.</span>
<span id="cb1-216"><a href="#cb1-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-217"><a href="#cb1-217" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Supports context management to maintain conversation history and state.</span>
<span id="cb1-218"><a href="#cb1-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-219"><a href="#cb1-219" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>*Text analysis*<span class="sc">\*</span></span>
<span id="cb1-220"><a href="#cb1-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-221"><a href="#cb1-221" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Supports embeddings (Azure, public, or local) using a local, high-performance vector DB (based on {ragnar}).</span>
<span id="cb1-222"><a href="#cb1-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-223"><a href="#cb1-223" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Implements chunking office documents (Word, Excel, Powerpoint, RTF, PDF) into the vector DB.</span>
<span id="cb1-224"><a href="#cb1-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-225"><a href="#cb1-225" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>While reading office documents, supports extracting tables with summary data.</span>
<span id="cb1-226"><a href="#cb1-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-227"><a href="#cb1-227" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Enables retrieval-augmented generation (RAG) using the vector DB, either explicitly or by using a RAG tool that the LLM calls.</span>
<span id="cb1-228"><a href="#cb1-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-229"><a href="#cb1-229" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Emulates the Future House's PaperQA2 approach for summarizing and re-ranking parts of semantically related documents so that answer quality and comprehensiveness is significantly boosted.</span>
<span id="cb1-230"><a href="#cb1-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-231"><a href="#cb1-231" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Extracts text from documents to fill structured templates, such as the JSON-based {llumen} Analysis Results Schema (LARS). Extracted JSONs are directly validated by the LLM using an R tool.</span>
<span id="cb1-232"><a href="#cb1-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-233"><a href="#cb1-233" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Supports automatic diagram generation from texts, for instance to capture the main concepts of a paper in two or three flow charts.</span>
<span id="cb1-234"><a href="#cb1-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-235"><a href="#cb1-235" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Provides advanced text preprocessing and cleaning capabilities for various document types.</span>
<span id="cb1-236"><a href="#cb1-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-237"><a href="#cb1-237" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Offers customizable tokenization and text segmentation methods.</span>
<span id="cb1-238"><a href="#cb1-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-239"><a href="#cb1-239" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>*Agentic tool use and codegen*<span class="sc">\*</span></span>
<span id="cb1-240"><a href="#cb1-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-241"><a href="#cb1-241" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Allows the LLM to search the internet via Google and access the textual content of websites in a controlled manner. Also includes specialized query tools for Pubmed, Pubchem, and Wikipedia.</span>
<span id="cb1-242"><a href="#cb1-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-243"><a href="#cb1-243" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Enables the LLM agent to query Parquet files, Neo4j knowledge graphs, and GraphQL APIs using SQL, Cypher and GraphQL codegen in a secure context. The database agents are very capable and can answer complex, open-ended scientific questions using these data sources.</span>
<span id="cb1-244"><a href="#cb1-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-245"><a href="#cb1-245" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Enables the LLM agent to use local foundation models, such as Google's TxGemma model for pharmaceutical applications, for instance for predicting solubility of small molecules.</span>
<span id="cb1-246"><a href="#cb1-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-247"><a href="#cb1-247" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Uses multimodal LLMs to accurately diagnose cancer histopathology images with very comprehensive pathology reports that investigate architectural and cytological Features of H&amp;E slides.</span>
<span id="cb1-248"><a href="#cb1-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-249"><a href="#cb1-249" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Makes it easy to give the LLM new R tool capabilities (basically all R functions), share tools via MCP (built-in pure R MCP server), or utilize tools of external MCP server as internal tools (via a MCP tool wrapper).</span>
<span id="cb1-250"><a href="#cb1-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-251"><a href="#cb1-251" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Supports dynamic tool creation and registration during runtime.</span>
<span id="cb1-252"><a href="#cb1-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-253"><a href="#cb1-253" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Provides a framework for defining custom tools and integrating them seamlessly with the LLM.</span>
<span id="cb1-254"><a href="#cb1-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-255"><a href="#cb1-255" aria-hidden="true" tabindex="-1"></a>We are internally using the package for the following usecases:</span>
<span id="cb1-256"><a href="#cb1-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-257"><a href="#cb1-257" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>*Supported usecase*<span class="sc">\*</span></span>
<span id="cb1-258"><a href="#cb1-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-259"><a href="#cb1-259" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>Extracting results of statistical analyses from office documents: The vignettes show how to configure an agentic LLM to extract chunks oftext from documents and tables, semantically query a vector store (agent-based retrieval-augmented generation, RAG), load JSON definitions, extract JSON-structured data from documents, and validate these definitions against a user-defined JSON template. {llumen} can be utilized to extract results data from a large corpus of clinical trial results files. Templates for both CDISC Analysis Result Standard (ARS) and the {llumen} Analysis Result Schema (LARS) are provided.</span>
<span id="cb1-260"><a href="#cb1-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-261"><a href="#cb1-261" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>Querying tabular databases and knowledge graphs: {llumen} excels at SQL codegen, allowing users to query very large Parquet files located on the user's device and perform complex data analyses. It also supports querying Neo4j knowledge graphs and GraphQL APIs, enabling comprehensive data exploration and analysis.</span>
<span id="cb1-262"><a href="#cb1-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-263"><a href="#cb1-263" aria-hidden="true" tabindex="-1"></a><span class="ss">3.  </span>Working with biological foundation models: {llumen}'s ability to use local foundation models specialized for particular biological or pharmaceutical applications, such as Google's GemmaTX, enhances agentic LLMs with specialized capabilities for tasks like predicting molecular properties or analyzing biological pathways.</span>
<span id="cb1-264"><a href="#cb1-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-265"><a href="#cb1-265" aria-hidden="true" tabindex="-1"></a><span class="ss">4.  </span>Automated literature review and summarization: {llumen} can be used to perform comprehensive literature reviews by searching multiple databases (e.g., PubMed, OpenAlex), extracting relevant information, and generating structured summaries of findings.</span>
<span id="cb1-266"><a href="#cb1-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-267"><a href="#cb1-267" aria-hidden="true" tabindex="-1"></a><span class="ss">5.  </span>Histopathology image analysis: The package supports the use of multimodal LLMs for analyzing histopathology images, providing detailed reports on architectural and cytological features of H&amp;E slides, which can aid in cancer diagnosis and research.</span>
<span id="cb1-268"><a href="#cb1-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-269"><a href="#cb1-269" aria-hidden="true" tabindex="-1"></a><span class="ss">6.  </span>Drug discovery and development support: By integrating various tools and databases (e.g., PubChem, TxGemma), {llumen} can assist in various stages of drug discovery, from initial compound screening to predicting drug properties and potential interactions.</span>
<span id="cb1-270"><a href="#cb1-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-271"><a href="#cb1-271" aria-hidden="true" tabindex="-1"></a><span class="ss">7.  </span>Clinical trial data analysis and reporting: {llumen}'s capabilities in extracting and structuring data from various document types make it well-suited for analyzing and reporting on clinical trial data, potentially accelerating the process of deriving insights from trial results.</span>
<span id="cb1-272"><a href="#cb1-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-273"><a href="#cb1-273" aria-hidden="true" tabindex="-1"></a><span class="ss">8.  </span>Biomedical knowledge graph exploration: The package's ability to query knowledge graphs allows researchers to explore complex relationships in biomedical data, potentially uncovering new insights or research directions.</span>
<span id="cb1-274"><a href="#cb1-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-275"><a href="#cb1-275" aria-hidden="true" tabindex="-1"></a><span class="ss">9.  </span>Automated scientific writing assistance: {llumen} can be used to assist in scientific writing tasks, such as generating literature summaries, creating structured abstracts, or even drafting sections of scientific papers based on analyzed data and literature.</span>
<span id="cb1-276"><a href="#cb1-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-277"><a href="#cb1-277" aria-hidden="true" tabindex="-1"></a><span class="ss">10. </span>Regulatory document preparation and analysis: The package's capabilities in extracting and structuring information from various document types can be applied to preparing and analyzing regulatory documents in the pharmaceutical industry</span>
<span id="cb1-278"><a href="#cb1-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-279"><a href="#cb1-279" aria-hidden="true" tabindex="-1"></a>Presentation related link:</span>
<span id="cb1-280"><a href="#cb1-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-281"><a href="#cb1-281" aria-hidden="true" tabindex="-1"></a><span class="ot">&lt;https://drive.google.com/file/d/1g0_O_wSoeBHzeXl6DF3-NIY7gT2Bk62_/view&gt;</span></span>
<span id="cb1-282"><a href="#cb1-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-283"><a href="#cb1-283" aria-hidden="true" tabindex="-1"></a><span class="fu">### **Build Model Context Protocol servers and clients in R**</span></span>
<span id="cb1-284"><a href="#cb1-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-285"><a href="#cb1-285" aria-hidden="true" tabindex="-1"></a>John Coene (Opifex).</span>
<span id="cb1-286"><a href="#cb1-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-287"><a href="#cb1-287" aria-hidden="true" tabindex="-1"></a>The mcpr package provides a comprehensive R implementation of the Model Context Protocol (MCP), a standardized JSON-RPC 2.0 interface that enables R applications to expose computational capabilities to AI models. This package bridges the gap between R's statistical computing environment and modern AI assistants by allowing R developers to create MCP servers that expose tools, resources, and prompts as well as client functionality to interact with existing MCP servers.</span>
<span id="cb1-288"><a href="#cb1-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-289"><a href="#cb1-289" aria-hidden="true" tabindex="-1"></a>Key features include schema-based tool definitions, multi-modal response support, and seamless integration with popular AI development environments including Claude Code, Cursor, and VS Code. This implementation democratizes AI-R integration by providing a standards-based approach to exposing R's extensive ecosystem to conversational AI interfaces, opening new possibilities for interactive data analysis and statistical computing workflows.</span>
<span id="cb1-290"><a href="#cb1-290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-291"><a href="#cb1-291" aria-hidden="true" tabindex="-1"></a><span class="fu">#### **Europe/US Session #4**</span></span>
<span id="cb1-292"><a href="#cb1-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-293"><a href="#cb1-293" aria-hidden="true" tabindex="-1"></a><span class="fu">### **Mosaic: Open-Source, ARS-Driven Automation of Standard TFLs**</span></span>
<span id="cb1-294"><a href="#cb1-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-295"><a href="#cb1-295" aria-hidden="true" tabindex="-1"></a>Conor Moloney (Novartis).</span>
<span id="cb1-296"><a href="#cb1-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-297"><a href="#cb1-297" aria-hidden="true" tabindex="-1"></a>CDISC standards help streamline datasets (e.g. SDTM and ADaM), yet analysis results lack a common model. The emerging Analysis Results Standard (ARS) will help to fill this gap with machine-readable specifications. Mosaic couples ARS with an open-source stack to generate fully validated standard TFLs, fast and reproducibly.</span>
<span id="cb1-298"><a href="#cb1-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-299"><a href="#cb1-299" aria-hidden="true" tabindex="-1"></a>How it works</span>
<span id="cb1-300"><a href="#cb1-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-301"><a href="#cb1-301" aria-hidden="true" tabindex="-1"></a>Mosaic captures the Analysis Results Dataset (ARD) requirement in ARS-aligned YAML; updates and changes are made by editing this metadata, not code. After LinkML validation, a Python layer stores the YAML in a database via a SQL Alchemy ORM engine. The results-generation layer is intentionally language-agnostic . The rules that transform ADaM datasets into the ARD are expressed as metadata that can be rendered in any statistical language. Mosaic’s implementation uses R to derive the ARD.</span>
<span id="cb1-302"><a href="#cb1-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-303"><a href="#cb1-303" aria-hidden="true" tabindex="-1"></a>A React UI reads the validated ARD. Here, users have controlled customisation options. Users can preview each TFL shell in real time and export regulator-ready RTF files suitable for submission packages.</span>
<span id="cb1-304"><a href="#cb1-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-305"><a href="#cb1-305" aria-hidden="true" tabindex="-1"></a>Mosaic replaces ad-hoc programming with a transparent, standards-based pipeline, accelerating TFL delivery while safeguarding traceability and regulatory compliance. This reallocates programmer effort from repetitive coding to high-value scientific review</span>
<span id="cb1-306"><a href="#cb1-306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-307"><a href="#cb1-307" aria-hidden="true" tabindex="-1"></a><span class="fu">### **Integrating Collaborative Programming with Automated Traceability and Reproducibility in Pharma**</span></span>
<span id="cb1-308"><a href="#cb1-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-309"><a href="#cb1-309" aria-hidden="true" tabindex="-1"></a>Jennifer Dusendang (Graticule Inc) and Sundeep Bath (Graticle Inc).</span>
<span id="cb1-310"><a href="#cb1-310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-311"><a href="#cb1-311" aria-hidden="true" tabindex="-1"></a>Integrating Collaborative Programming with Automated Traceability and Reproducibility in Pharma Studies and Real-World Data Projects by Adapting DevOps Best-Practices</span>
<span id="cb1-312"><a href="#cb1-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-313"><a href="#cb1-313" aria-hidden="true" tabindex="-1"></a>To enhance integrity of research and study findings, data scientists should ensure that studies are traceable and reproducible, which involves meticulous management of datasets, tracking code changes, and robust storage of results.</span>
<span id="cb1-314"><a href="#cb1-314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-315"><a href="#cb1-315" aria-hidden="true" tabindex="-1"></a>Without infrastructure to support reproducibility efforts, documentation, dependency management, and version control processes can be manual, unreliable, and unclear. This creates problems with determining when analysis changes occurred, which version of study results were produced by which version of code, and whether all study steps are processed in proper order and appropriately documented.</span>
<span id="cb1-316"><a href="#cb1-316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-317"><a href="#cb1-317" aria-hidden="true" tabindex="-1"></a>Implementing procedures and technical infrastructure helps to maintain and automate reproducibility and traceability. To ensure that code can be executed consistently across multiple compute environments, we structure analysis scripts into parameterized pipelines within an isolated Docker container environment which specifies all versions and dependencies. We integrate Continuous Integration (CI) and Continuous Delivery (CD) into analysis pipelines to enable automatic rerunning of analyses following code modifications and storage of results in the cloud. Our process integrates and improves collaborative programming by providing code reviewers with the validated outputs that are produced by the code. By design, study close-out and compliance activities are incorporated within our infrastructure.</span>
<span id="cb1-318"><a href="#cb1-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-319"><a href="#cb1-319" aria-hidden="true" tabindex="-1"></a>In this paper we will discuss how we implemented and adapted DevOps best-practices like CI/CD in a collaborative coding environment to work for epidemiological studies and real-world data projects. Although the concepts discussed are applicable to many tools, our implementation uses Git, GitHub Actions, SQL, Python, R, Docker, and AWS S3. This content is applicable for all skill levels.</span>
<span id="cb1-320"><a href="#cb1-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-321"><a href="#cb1-321" aria-hidden="true" tabindex="-1"></a><span class="ot">&lt;https://www.lexjansen.com/pharmasug/2025/OS/PharmaSUG-2025-OS-111.pdf&gt;</span></span>
<span id="cb1-322"><a href="#cb1-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-323"><a href="#cb1-323" aria-hidden="true" tabindex="-1"></a><span class="fu">### **TabPFN: A Deep-Learning Solution for Tabular Data**</span></span>
<span id="cb1-324"><a href="#cb1-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-325"><a href="#cb1-325" aria-hidden="true" tabindex="-1"></a>Max Kuhn (Posit).</span>
<span id="cb1-326"><a href="#cb1-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-327"><a href="#cb1-327" aria-hidden="true" tabindex="-1"></a>There have been numerous proposals for deep neural networks for tabular data, such as rectangular data sets (e.g., data frames). To date, none have really worked well and take far too long to train. TabPFN is a model that emulates a Bayesian approach and trains a deep learning model on a prior of simulated tabular datasets. Version 2 was released this year and offers several significant advantages, but also has one notable disadvantage. I'll introduce this model and show an example.</span>
<span id="cb1-328"><a href="#cb1-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-329"><a href="#cb1-329" aria-hidden="true" tabindex="-1"></a><span class="ot">&lt;https://topepo.github.io/2025-r-pharma/#/title-slide&gt;</span></span>
<span id="cb1-330"><a href="#cb1-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-331"><a href="#cb1-331" aria-hidden="true" tabindex="-1"></a><span class="fu">### **The LLM Lounge: Live-coding and conversation on using AI for data science**</span></span>
<span id="cb1-332"><a href="#cb1-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-333"><a href="#cb1-333" aria-hidden="true" tabindex="-1"></a>**Joe Cheng**</span>
<span id="cb1-334"><a href="#cb1-334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-335"><a href="#cb1-335" aria-hidden="true" tabindex="-1"></a>Posit</span>
<span id="cb1-336"><a href="#cb1-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-337"><a href="#cb1-337" aria-hidden="true" tabindex="-1"></a>**Eric Nantz**</span>
<span id="cb1-338"><a href="#cb1-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-339"><a href="#cb1-339" aria-hidden="true" tabindex="-1"></a>Eli Lilly</span>
<span id="cb1-340"><a href="#cb1-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-341"><a href="#cb1-341" aria-hidden="true" tabindex="-1"></a>The number of workflows and tools leveraging large-language-models (LLMs) is growing exponentially across the world, and the life sciences industry is no exception. In this session, Eric Nantz takes the role of the curious and savvy data scientist as he is joined by Posit CTO Joe Cheng in a special live demonstration on using Databot to power an exploratory data science analysis. Throughout the demonstration, Joe will share the fascinating origin story of how Databot came to be, along with a deeper conversation on the recent trends and guiding principles of harnessing AI tools for data analyses and software engineering. This interactive, spontaneous format will allow the audience to submit questions and steer the direction of the session, making it a truly engaging, shared experience.</span>
<span id="cb1-342"><a href="#cb1-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-343"><a href="#cb1-343" aria-hidden="true" tabindex="-1"></a><span class="ot">&lt;https://github.com/posit-dev/querychat&gt;</span></span>
<span id="cb1-344"><a href="#cb1-344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-345"><a href="#cb1-345" aria-hidden="true" tabindex="-1"></a><span class="fu">### **LLM-Powered {gtsummary}: QC-Ready Clinical Tables in Minutes**</span></span>
<span id="cb1-346"><a href="#cb1-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-347"><a href="#cb1-347" aria-hidden="true" tabindex="-1"></a>**Davide Garolini**</span>
<span id="cb1-348"><a href="#cb1-348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-349"><a href="#cb1-349" aria-hidden="true" tabindex="-1"></a>Data Scientist, NEST, Roche</span>
<span id="cb1-350"><a href="#cb1-350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-351"><a href="#cb1-351" aria-hidden="true" tabindex="-1"></a>He significantly contributes to the NEST project by improving key tools like {gtsummary} and {rtables} for regulatory compliance.</span>
<span id="cb1-352"><a href="#cb1-352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-353"><a href="#cb1-353" aria-hidden="true" tabindex="-1"></a>Open-source R tooling has made table generation easy, yet interpreting the code and guaranteeing bullet-proof QC can still delay submissions. We present a workflow that fuses {gtsummary} for rapid table building with cards for "automatic" validation, topped by a fully offline, model-agnostic LLM helper. Starting on synthetic CDISC-like data, we create a standard summary table, validate it with {cards}, and ask the LLM-helper to explain each step and result and propose, if necessary, next steps—all without revealing trial data. A descriptive log is generated on the fly, combining code, QC results, and LLM explanations in one auditor-friendly document. When real data arrive, the same script reruns unchanged, delivering submission-ready tables in minutes while boosting clarity and compliance.</span>
<span id="cb1-354"><a href="#cb1-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-355"><a href="#cb1-355" aria-hidden="true" tabindex="-1"></a><span class="fu">### **Post-Approval Drug Exposure Estimation Using an R Shiny App**</span></span>
<span id="cb1-356"><a href="#cb1-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-357"><a href="#cb1-357" aria-hidden="true" tabindex="-1"></a>**Feifei Yang**</span>
<span id="cb1-358"><a href="#cb1-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-359"><a href="#cb1-359" aria-hidden="true" tabindex="-1"></a>AstraZeneca</span>
<span id="cb1-360"><a href="#cb1-360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-361"><a href="#cb1-361" aria-hidden="true" tabindex="-1"></a>**Yu Zhang**</span>
<span id="cb1-362"><a href="#cb1-362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-363"><a href="#cb1-363" aria-hidden="true" tabindex="-1"></a>AstraZeneca</span>
<span id="cb1-364"><a href="#cb1-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-365"><a href="#cb1-365" aria-hidden="true" tabindex="-1"></a>**Background**</span>
<span id="cb1-366"><a href="#cb1-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-367"><a href="#cb1-367" aria-hidden="true" tabindex="-1"></a>Regulatory authorities require product post-marketing exposure estimates in aggregate safety reports for purposes of signal detection. The calculation of exposure estimates requires multiple data sources between sales data and aggregated de-identified patient data. Traditionally, the calculations were manually handled due to limited countries, products, and indications. With the growth of both markets and products, manual calculations are inefficient to handle the increasing volume of data and regional requests. An approach to automating the entire process has become essential.</span>
<span id="cb1-368"><a href="#cb1-368" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-369"><a href="#cb1-369" aria-hidden="true" tabindex="-1"></a>**Method**</span>
<span id="cb1-370"><a href="#cb1-370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-371"><a href="#cb1-371" aria-hidden="true" tabindex="-1"></a>R Shiny App is a web application framework that allows us to create interactive web applications for data analysis, data visualization, and interactive reports, making it easier to share data insights with others. We converted monthly patient and sales report into an app-readable format and applied an exposure estimate algorithm to perform calculations by region, product, and indication.</span>
<span id="cb1-372"><a href="#cb1-372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-373"><a href="#cb1-373" aria-hidden="true" tabindex="-1"></a>**Results**</span>
<span id="cb1-374"><a href="#cb1-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-375"><a href="#cb1-375" aria-hidden="true" tabindex="-1"></a>The time to generate a standard report of post-marketing exposure data for regulatory purposes has been reduced from a week to one day. The QC function of application helps check inconsistent numbers from month to month in sales and patient data. In addition to the exposure report, the visualization provided by the application shows trends in sales, patient utilization of products, and exposure by year and geographic regions. The sharing ability of the application enables other team members to generate customized report directly without any prerequisite training.</span>
<span id="cb1-376"><a href="#cb1-376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-377"><a href="#cb1-377" aria-hidden="true" tabindex="-1"></a>**Conclusion**</span>
<span id="cb1-378"><a href="#cb1-378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-379"><a href="#cb1-379" aria-hidden="true" tabindex="-1"></a>The application significantly improves the efficiency of delivering post-marketing exposure data and reduces time and resources needed for data management and QC. Accessibility to the application helps disseminate the information to a broader range of teams and functions.</span>
<span id="cb1-380"><a href="#cb1-380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-381"><a href="#cb1-381" aria-hidden="true" tabindex="-1"></a><span class="fu">### **Implementing an end-to-end NCA software using Shiny**</span></span>
<span id="cb1-382"><a href="#cb1-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-383"><a href="#cb1-383" aria-hidden="true" tabindex="-1"></a>**Gerardo Jose Rodriguez**</span>
<span id="cb1-384"><a href="#cb1-384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-385"><a href="#cb1-385" aria-hidden="true" tabindex="-1"></a>Lucid Analytics</span>
<span id="cb1-386"><a href="#cb1-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-387"><a href="#cb1-387" aria-hidden="true" tabindex="-1"></a>**Jana Spinner**</span>
<span id="cb1-388"><a href="#cb1-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-389"><a href="#cb1-389" aria-hidden="true" tabindex="-1"></a>Lucid Analytics</span>
<span id="cb1-390"><a href="#cb1-390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-391"><a href="#cb1-391" aria-hidden="true" tabindex="-1"></a>Pharmacokinetic studies are essential yet demanding, typically relying on expensive proprietary software for Non-Compartmental Analysis (NCA). aNCA is an alternative developed collaboratively by Roche, Lucid Analytics, Appsilon, and Human Predictions. It is being developed within Pharmaverse, aiming to become a worldwide standard by utilizing open source development to make the process more efficient, economical, and transparent. The app performs an end-to-end approach, using interactive plots for data exploration, half life customization, TLGs, and report generation.aNCA is planned to be released on CRAN soon. It currently reaches 100% of testing coverage on its functions and has successfully passed internal package validations.</span>
<span id="cb1-392"><a href="#cb1-392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-393"><a href="#cb1-393" aria-hidden="true" tabindex="-1"></a>aNCA uses PKNCA, a widely used package that calculates over 200 PK parameters, has been tested against other industry-standard NCA software, showing differences within ±0.1% for most tested parameters.</span>
<span id="cb1-394"><a href="#cb1-394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-395"><a href="#cb1-395" aria-hidden="true" tabindex="-1"></a>We aim to present aNCA, highlight its innovative software concepts, discuss how we tackled key challenges, and showcase how open source and Shiny achieve industry-standard PK software. However, we welcome suggestions on focus areas for the R/Pharma audience.</span>
<span id="cb1-396"><a href="#cb1-396" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-397"><a href="#cb1-397" aria-hidden="true" tabindex="-1"></a>If you want to know more about aNCA, feel free to follow the link to our GitHub: <span class="ot">&lt;https://github.com/pharmaverse/aNCA&gt;</span></span>
<span id="cb1-398"><a href="#cb1-398" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-399"><a href="#cb1-399" aria-hidden="true" tabindex="-1"></a><span class="fu">### **Integrating LLM using R Shiny for Clinical Data Review by Ensuring Data Privacy and Validity**</span></span>
<span id="cb1-400"><a href="#cb1-400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-401"><a href="#cb1-401" aria-hidden="true" tabindex="-1"></a>**Zhen Wu**</span>
<span id="cb1-402"><a href="#cb1-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-403"><a href="#cb1-403" aria-hidden="true" tabindex="-1"></a>CIMS Global</span>
<span id="cb1-404"><a href="#cb1-404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-405"><a href="#cb1-405" aria-hidden="true" tabindex="-1"></a>**Peng Zhang**</span>
<span id="cb1-406"><a href="#cb1-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-407"><a href="#cb1-407" aria-hidden="true" tabindex="-1"></a>CIMS Global</span>
<span id="cb1-408"><a href="#cb1-408" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-409"><a href="#cb1-409" aria-hidden="true" tabindex="-1"></a>The pharmaceutical industry is shifting from traditional SAS-based workflows toward the open-source R ecosystem. R Shiny applications have become a popular solution for visualizing tables, figures, and listings. However, these applications often require a strong understanding of data structures and familiarity with interface components such as dropdowns, which may not be intuitive for clinical reviewers. Recent advancements in artificial intelligence (AI), particularly large language models (LLMs), have opened new possibilities for how users interact with clinical data. In this session, we present an innovative R Shiny application, {DataChat}, that enables users to "chat with data" through a conversational interface. Powered by the {ellmer}, {shinychat}, and {ragnar} packages, along with internal statistical tools and utilities, the app integrates retrieval-augmented generation (RAG) capabilities tailored to the pharmaceutical domain. The solution emphasizes user-friendliness, enabling non-programmers and clinicians to explore datasets and derive insights while maintaining compliance with data privacy requirements and addressing concerns around statistical validity. This approach exemplifies the potential of AI-augmented tools to enhance clinical data review and exploration in a practical and accessible way</span>
<span id="cb1-410"><a href="#cb1-410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-411"><a href="#cb1-411" aria-hidden="true" tabindex="-1"></a><span class="fu">### **R we there yet? {admiral}’s journey transitioning from active development to stability**</span></span>
<span id="cb1-412"><a href="#cb1-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-413"><a href="#cb1-413" aria-hidden="true" tabindex="-1"></a>**Edoardo Mancini**</span>
<span id="cb1-414"><a href="#cb1-414" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-415"><a href="#cb1-415" aria-hidden="true" tabindex="-1"></a>Roche</span>
<span id="cb1-416"><a href="#cb1-416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-417"><a href="#cb1-417" aria-hidden="true" tabindex="-1"></a>If you are attending R/Pharma 2025, you probably enjoy actively contributing to open source R packages for the pharma industry. Fixing bugs, implementing new features and expanding the use-case is work that feels motivating and meaningful. However, what happens if/when your package reaches a point of stability and maturity, where the main use-case is answered and feature completeness is in sight? How can you sustain your development team's momentum without chasing perfection, in a time where the active workload is naturally diminished? What should your new priorities be?</span>
<span id="cb1-418"><a href="#cb1-418" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-419"><a href="#cb1-419" aria-hidden="true" tabindex="-1"></a>While there is no definitive answer to any of these questions, this talk will discuss the evolution of packages like {admiral} as they transition from active development to mature maintenance, drawing insights from the {admiral} team's experiences in navigating this complex shift.</span>
<span id="cb1-420"><a href="#cb1-420" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-421"><a href="#cb1-421" aria-hidden="true" tabindex="-1"></a><span class="fu">### **Workshop: R-Classification: Unleashing Predictive Power with tidymodels**</span></span>
<span id="cb1-422"><a href="#cb1-422" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-423"><a href="#cb1-423" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Harshavardhan Bajoria**</span>
<span id="cb1-424"><a href="#cb1-424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-425"><a href="#cb1-425" aria-hidden="true" tabindex="-1"></a>Dive into the exciting world of classification with R and the elegant tidymodels framework! This hands-on workshop provides a comprehensive introduction to building, evaluating, and refining machine learning models that predict categorical outcomes. You'll learn to preprocess your data effectively using recipes, split datasets for robust model training and testing with rsample, define and fit various classification algorithms using parsnip, and assess model performance using a suite of metrics from yardstick. Through practical exercises, including a wine classification challenge, you'll gain the skills to tackle real-world predictive problems and make data-driven decisions using the consistent and intuitive tidymodels ecosystem.</span>
<span id="cb1-426"><a href="#cb1-426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-427"><a href="#cb1-427" aria-hidden="true" tabindex="-1"></a><span class="fu">### **Workshop: A Guided Tour to Building and Integrating LLM Based Tooling with R**</span></span>
<span id="cb1-428"><a href="#cb1-428" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-429"><a href="#cb1-429" aria-hidden="true" tabindex="-1"></a>**Devin Pastoor**</span>
<span id="cb1-430"><a href="#cb1-430" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-431"><a href="#cb1-431" aria-hidden="true" tabindex="-1"></a>Chief Technology and Product Officer, A2-AI</span>
<span id="cb1-432"><a href="#cb1-432" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-433"><a href="#cb1-433" aria-hidden="true" tabindex="-1"></a>**Xu Fei**</span>
<span id="cb1-434"><a href="#cb1-434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-435"><a href="#cb1-435" aria-hidden="true" tabindex="-1"></a>Xu Fei is a Senior Solutions Engineer at A2-Ai, where he builds AI-powered tools and infrastructure for pharmaceutical research workflows. Working across R and Python stacks, he has developed LLM-enabled applications ranging from interactive chatbots to MCP server implementations, with a focus on making GenAI accessible and practical for scientific computing teams. His work bridges enterprise DevOps, cloud APIs (AWS Bedrock), and domain-specific R and Python packages to help scientists integrate AI capabilities into their existing workflows</span>
<span id="cb1-436"><a href="#cb1-436" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-437"><a href="#cb1-437" aria-hidden="true" tabindex="-1"></a>**Aathira Anil Kumar**</span>
<span id="cb1-438"><a href="#cb1-438" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-439"><a href="#cb1-439" aria-hidden="true" tabindex="-1"></a>A2-Ai</span>
<span id="cb1-440"><a href="#cb1-440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-441"><a href="#cb1-441" aria-hidden="true" tabindex="-1"></a>Join A2-AI engineers, Aathira Anil Kumar, Devin, and Xu Fei, for a practical, 2-hour workshop demonstrating how to integrate Generative AI (GenAI) into pharmaceutical workflows. This session focuses on bridging the R and Python ecosystems to deliver scalable, GxP-compliant solutions.</span>
<span id="cb1-442"><a href="#cb1-442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-443"><a href="#cb1-443" aria-hidden="true" tabindex="-1"></a>You will learn methodology for developing LLM-enabled applications—from interactive chatbots for clinical study reporting and SOP management, to more complex MCP server implementations for reproducible analytics. Drawing on their extensive experience with life-science organizations and tools like AWS Bedrock, the instructors will showcase how to navigate real-world IT constraints while making GenAI accessible and practical for scientific computing teams. This workshop is essential for analysts, developers, and project leaders aiming to stand up GxP-compliant statistical computing environments with integrated AI capabilities.</span>
<span id="cb1-444"><a href="#cb1-444" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-445"><a href="#cb1-445" aria-hidden="true" tabindex="-1"></a><span class="fu">#### **Europe/US Session #5**</span></span>
<span id="cb1-446"><a href="#cb1-446" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-447"><a href="#cb1-447" aria-hidden="true" tabindex="-1"></a><span class="fu">### **GSK’s journey to Clinical Study Reporting Using Open Source**</span></span>
<span id="cb1-448"><a href="#cb1-448" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-449"><a href="#cb1-449" aria-hidden="true" tabindex="-1"></a>**Sam Warden**</span>
<span id="cb1-450"><a href="#cb1-450" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-451"><a href="#cb1-451" aria-hidden="true" tabindex="-1"></a>VP &amp; Global Head, Clinical Programming &amp; Business Excellence</span>
<span id="cb1-452"><a href="#cb1-452" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-453"><a href="#cb1-453" aria-hidden="true" tabindex="-1"></a>GSK</span>
<span id="cb1-454"><a href="#cb1-454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-455"><a href="#cb1-455" aria-hidden="true" tabindex="-1"></a>**Tim Colman**</span>
<span id="cb1-456"><a href="#cb1-456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-457"><a href="#cb1-457" aria-hidden="true" tabindex="-1"></a>GSK</span>
<span id="cb1-458"><a href="#cb1-458" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-459"><a href="#cb1-459" aria-hidden="true" tabindex="-1"></a>GSK’s Journey to Clinical Study Reporting Using Open Source chronicles the transformation of clinical reporting at GSK, the presentation marks pivotal moments in the pharmaceutical industry’s evolution—from the proprietary, SAS-dominated era of the 1980s and 90s, through the pain of rising R&amp;D costs and global health crises, to the emergence of collaborative models and open-source innovation.</span>
<span id="cb1-460"><a href="#cb1-460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-461"><a href="#cb1-461" aria-hidden="true" tabindex="-1"></a>The story highlights how industry challenges catalyzed a shift toward openness and collaboration. Key milestones include the FDA’s clarification on software neutrality, the rise of R and open-source platforms, and GSK’s commitment to writing at least 50% of code in open-source languages. The COVID-19 pandemic accelerated this transformation, driving rapid adoption of data science platforms and collaborative tools.</span>
<span id="cb1-462"><a href="#cb1-462" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-463"><a href="#cb1-463" aria-hidden="true" tabindex="-1"></a>GSK’s multi-wave approach to change is shared and candidly addresses ongoing challenges: technical validation, regulatory uncertainty, cultural resistance, and the need for robust governance and training.</span>
<span id="cb1-464"><a href="#cb1-464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-465"><a href="#cb1-465" aria-hidden="true" tabindex="-1"></a>Ultimately, the journey demonstrates that embracing open-source technologies enables greater automation, and innovation in clinical study reporting. Success depends on a growth mindset, adaptability, and a vision for collaborative transformation—qualities that GSK continues to foster as it leads the industry into a new era of transparency and shared progress.</span>
<span id="cb1-466"><a href="#cb1-466" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-467"><a href="#cb1-467" aria-hidden="true" tabindex="-1"></a><span class="fu">#### **Europe/US Session #6**</span></span>
<span id="cb1-468"><a href="#cb1-468" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-469"><a href="#cb1-469" aria-hidden="true" tabindex="-1"></a><span class="fu">### **Leveraging ellmer and GPT to Integrate AI Agents into Shiny Applications for Accelerating Trials**</span></span>
<span id="cb1-470"><a href="#cb1-470" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-471"><a href="#cb1-471" aria-hidden="true" tabindex="-1"></a>**Xing Chen**</span>
<span id="cb1-472"><a href="#cb1-472" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-473"><a href="#cb1-473" aria-hidden="true" tabindex="-1"></a>Moderna</span>
<span id="cb1-474"><a href="#cb1-474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-475"><a href="#cb1-475" aria-hidden="true" tabindex="-1"></a>**Xiaolin Chang**</span>
<span id="cb1-476"><a href="#cb1-476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-477"><a href="#cb1-477" aria-hidden="true" tabindex="-1"></a>Moderna</span>
<span id="cb1-478"><a href="#cb1-478" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-479"><a href="#cb1-479" aria-hidden="true" tabindex="-1"></a>Background:</span>
<span id="cb1-480"><a href="#cb1-480" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-481"><a href="#cb1-481" aria-hidden="true" tabindex="-1"></a>Artificial intelligence is transforming drug development, but its integration into biostatistics and clinical workflows remains limited. Clinical and biometrics teams often face barriers in exploring high-dimensional, multi-view trial datasets, requiring technical expertise to extract insights and generate visualizations.</span>
<span id="cb1-482"><a href="#cb1-482" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-483"><a href="#cb1-483" aria-hidden="true" tabindex="-1"></a>Methods:</span>
<span id="cb1-484"><a href="#cb1-484" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-485"><a href="#cb1-485" aria-hidden="true" tabindex="-1"></a>We developed an AI-enhanced R Shiny application that integrates ellmer with ChatGPTs. The app connects to Cellular-Mediated Immunogenicity (CMI) data across multiple mRNA infectious disease programs. Natural language queries are translated into structured R operations, through which users can interactively explore and visualize data, eliminating the need for manual coding.</span>
<span id="cb1-486"><a href="#cb1-486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-487"><a href="#cb1-487" aria-hidden="true" tabindex="-1"></a>Results:</span>
<span id="cb1-488"><a href="#cb1-488" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-489"><a href="#cb1-489" aria-hidden="true" tabindex="-1"></a>The application successfully handled unstructured user queries, generated targeted outputs, and produced customizable visualizations. Pilot deployment across infectious disease programs demonstrated faster extraction of trial insights, reduced dependency on ad-hoc programming</span>
<span id="cb1-490"><a href="#cb1-490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-491"><a href="#cb1-491" aria-hidden="true" tabindex="-1"></a>support, and invigorates collaboration between statisticians, clinicians, and translational researchers.</span>
<span id="cb1-492"><a href="#cb1-492" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-493"><a href="#cb1-493" aria-hidden="true" tabindex="-1"></a>Conclusions:</span>
<span id="cb1-494"><a href="#cb1-494" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-495"><a href="#cb1-495" aria-hidden="true" tabindex="-1"></a>Embedding AI agents via ellmer within Shiny applications provides a scalable, user-friendly framework for accelerating exploratory analyses in vaccine development. This approach demonstrates how AI-assisted analytics can increase efficiency, strengthen cross-functional decision-making, and support broader adaptation of GenAI into clinical development workflows.</span>
<span id="cb1-496"><a href="#cb1-496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-497"><a href="#cb1-497" aria-hidden="true" tabindex="-1"></a><span class="fu">### **autoslideR: Streamlining slide deck generation for clinical reporting events**</span></span>
<span id="cb1-498"><a href="#cb1-498" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-499"><a href="#cb1-499" aria-hidden="true" tabindex="-1"></a>Yolanda Zhou (Roche) and Joe Zhu (Roche).</span>
<span id="cb1-500"><a href="#cb1-500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-501"><a href="#cb1-501" aria-hidden="true" tabindex="-1"></a>The standard process of developing the slide deck for clinical reporting events includes manually populating numbers from static outputs and a separate QC. The process is time-consuming, resource-intensive, and error-prone. To address these issues, we created “autoslideR”, an R package to automate the slide deck generation for multiple clinical reporting events. autoslideR has successfully supported slide creation for several study endorsement meetings, IMC meetings, as well as dose escalation meetings for early development, saving teams 0.5 to 4 days for the slide deck preparation compared to the time it traditionally takes.</span>
<span id="cb1-502"><a href="#cb1-502" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-503"><a href="#cb1-503" aria-hidden="true" tabindex="-1"></a>This talk explores the key features and technical advantages of autoslideR, such as supporting customized layout creations from existing templates, as well as adding placeholder slides to accelerate final slide preparation.</span>
<span id="cb1-504"><a href="#cb1-504" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-505"><a href="#cb1-505" aria-hidden="true" tabindex="-1"></a><span class="ot">&lt;https://pharmaverse.github.io/examples/digit_files/autoslider.html&gt;</span></span>
<span id="cb1-506"><a href="#cb1-506" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-507"><a href="#cb1-507" aria-hidden="true" tabindex="-1"></a><span class="fu">### **Putting the 'R' in RWD**</span></span>
<span id="cb1-508"><a href="#cb1-508" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-509"><a href="#cb1-509" aria-hidden="true" tabindex="-1"></a>Sachin Heerah (Pfizer) and Darren Jeng (Pfizer).</span>
<span id="cb1-510"><a href="#cb1-510" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-511"><a href="#cb1-511" aria-hidden="true" tabindex="-1"></a>The Pfizer Real World Data (RWD) programming team has leveraged R and Posit services to enhance the capabilities of its programmers. We have designed an R package, Shiny apps and even a Quarto website to support all programmers with varying backgrounds, including those with only SAS experience. Our R package is designed to simplify database queries, utilize both R and SAS variable syntax, and standardize deliverables. We have leveraged Posit’s RStudio features such as code snippets to make code templates readily accessible for all users within the IDE. Code guides are also presented as snippets to allow all users to load example data and explore standard RWD programming workflows. Overall, embracing and leveraging the features available to us in R and Posit is enhancing our workflow through integrated resources and documentation.</span>
<span id="cb1-512"><a href="#cb1-512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-513"><a href="#cb1-513" aria-hidden="true" tabindex="-1"></a><span class="fu">### **Generating Synthetic Data with synthpop in R**</span></span>
<span id="cb1-514"><a href="#cb1-514" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-515"><a href="#cb1-515" aria-hidden="true" tabindex="-1"></a>Sophie Furlow (Abbot Diagnostics).</span>
<span id="cb1-516"><a href="#cb1-516" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-517"><a href="#cb1-517" aria-hidden="true" tabindex="-1"></a>This talk will introduce synthetic data as an emerging tool for research and production. We will discuss the differences between synthetic, simulated, and resampled data and cover the current state of the art of synthetic data in healthcare, paying special attention to applications in pharma and diagnostics. We will walk through the basics of synthpop, an R package designed to generate synthetic and anonymous data at the individual level using various machine learning algorithms. Viewers will learn how to create entirely synthetic datasets with minimal statistical distortion their original data, making it suitable for software testing, data sharing, and model training. The talk will end with a demonstration of synthpop's quality evaluation features and major caveats to consider during the generation process.</span>
<span id="cb1-518"><a href="#cb1-518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-519"><a href="#cb1-519" aria-hidden="true" tabindex="-1"></a><span class="fu">#### **Europe/US Session #7**</span></span>
<span id="cb1-520"><a href="#cb1-520" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-521"><a href="#cb1-521" aria-hidden="true" tabindex="-1"></a><span class="fu">### **GenAI in Production - moving beyond prototypes**</span></span>
<span id="cb1-522"><a href="#cb1-522" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-523"><a href="#cb1-523" aria-hidden="true" tabindex="-1"></a>**Devin Pastoor**</span>
<span id="cb1-524"><a href="#cb1-524" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-525"><a href="#cb1-525" aria-hidden="true" tabindex="-1"></a>**Chief Technology and Product Officer, A2-Ai**</span>
<span id="cb1-526"><a href="#cb1-526" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-527"><a href="#cb1-527" aria-hidden="true" tabindex="-1"></a>Creation of AI applications has become increasingly commoditized through a rich ecosystem of R and python packages. However, there are significant hurdles to take a prototype application into "production" and keep it operating. Traditional testing and validation approaches do not always apply directly and the flexibility from which users can interact with the application can be much larger than a traditional application. This talk will discuss how to successfully (and unsuccessfully) develop, test, release, and maintain Generative AI based applications in GxP contexts.</span>
<span id="cb1-528"><a href="#cb1-528" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-529"><a href="#cb1-529" aria-hidden="true" tabindex="-1"></a><span class="fu">### **Building the Ultimate R AI Assistant**</span></span>
<span id="cb1-530"><a href="#cb1-530" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-531"><a href="#cb1-531" aria-hidden="true" tabindex="-1"></a>**Pawel Rucki**</span>
<span id="cb1-532"><a href="#cb1-532" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-533"><a href="#cb1-533" aria-hidden="true" tabindex="-1"></a>Principal Data Scientist, Roche</span>
<span id="cb1-534"><a href="#cb1-534" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-535"><a href="#cb1-535" aria-hidden="true" tabindex="-1"></a>Using R for clinical programming can be challenging, particularly with the specialized, often internal, packages used for reporting. To tackle these issues, we built our own AI assistant.</span>
<span id="cb1-536"><a href="#cb1-536" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-537"><a href="#cb1-537" aria-hidden="true" tabindex="-1"></a>In this talk, I'll share our story of building a multi-agent R co-pilot with the LangGraph framework, including the lessons we learned and a few tricks we picked up. A key decision was giving each R package its own AI agent. This was a game-changer for getting good help on our internal packages where general-purpose LLMs just can't keep up.</span>
<span id="cb1-538"><a href="#cb1-538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-539"><a href="#cb1-539" aria-hidden="true" tabindex="-1"></a>I'll discuss our agent network architecture and the practical techniques used to give agents the right context to write, debug, and explain complex R code for clinical trials. I’ll wrap up with a live demo showing how our design solves real-world programming problems, speeding up development and leading to better, more reliable code.</span>
<span id="cb1-540"><a href="#cb1-540" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-541"><a href="#cb1-541" aria-hidden="true" tabindex="-1"></a>(agents, cursor via mcp, webR extenstion, admiralroche, air AI assistant for programming in R)</span>
<span id="cb1-542"><a href="#cb1-542" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-543"><a href="#cb1-543" aria-hidden="true" tabindex="-1"></a><span class="fu">#### **Europe/US Session #8**</span></span>
<span id="cb1-544"><a href="#cb1-544" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-545"><a href="#cb1-545" aria-hidden="true" tabindex="-1"></a><span class="fu">### **The Dependency Whisperer: AI That Sees What You Might Miss**</span></span>
<span id="cb1-546"><a href="#cb1-546" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-547"><a href="#cb1-547" aria-hidden="true" tabindex="-1"></a>**Ming Yan**</span>
<span id="cb1-548"><a href="#cb1-548" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-549"><a href="#cb1-549" aria-hidden="true" tabindex="-1"></a>Eli Lilly</span>
<span id="cb1-550"><a href="#cb1-550" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-551"><a href="#cb1-551" aria-hidden="true" tabindex="-1"></a>**Vina Ro**</span>
<span id="cb1-552"><a href="#cb1-552" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-553"><a href="#cb1-553" aria-hidden="true" tabindex="-1"></a>Sr. Clinical Data Analyst, Eli Lilly</span>
<span id="cb1-554"><a href="#cb1-554" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-555"><a href="#cb1-555" aria-hidden="true" tabindex="-1"></a>An ongoing challenge in clinical programming is ensuring that downstream analyses are accurately refreshed following updates to SDTM or ADaM datasets. Traditional tools like AstroGrep can locate references to specific datasets or variables, but they lack the ability to distinguish between active code and commented text. Moreover, identifying indirect dependencies often requires multiple searches and manual effort to document all affected areas, which is time-consuming and increases the risk of missing updates—potentially leading to incorrect outputs being shared with external parties.</span>
<span id="cb1-556"><a href="#cb1-556" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-557"><a href="#cb1-557" aria-hidden="true" tabindex="-1"></a>This paper introduces an AI-powered tool designed to automatically identify and visualize all datasets and variables impacted by upstream changes. By parsing SDTM, ADaM, and TFL specifications or programs, the tool learns the structure of dependencies across the analysis pipeline. When a user specifies an updated variable and dataset, the tool generates a graphical report highlighting all affected elements. This capability streamlines the refresh process, reduces manual effort, and ensures the accuracy and completeness of deliverables.</span>
<span id="cb1-558"><a href="#cb1-558" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-559"><a href="#cb1-559" aria-hidden="true" tabindex="-1"></a><span class="fu">### **BayesERtools: R package for exposure-response analysis with Bayesian approaches**</span></span>
<span id="cb1-560"><a href="#cb1-560" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-561"><a href="#cb1-561" aria-hidden="true" tabindex="-1"></a>**Kenta Yoshida**</span>
<span id="cb1-562"><a href="#cb1-562" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-563"><a href="#cb1-563" aria-hidden="true" tabindex="-1"></a>Clinical Pharmacology Modeling &amp; Simulation, Genentech</span>
<span id="cb1-564"><a href="#cb1-564" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-565"><a href="#cb1-565" aria-hidden="true" tabindex="-1"></a>Exposure-response (ER) analysis is a critical component of clinical drug development for decisions such as dose selection. The new R package, BayesERtools (<span class="ot">&lt;https://genentech.github.io/BayesERtools/&gt;</span>), is designed to make Bayesian ER analysis more accessible. It provides a user-friendly interface for common tasks such as model development, simulation, and plotting, streamlining the entire workflow. The package currently supports linear and Emax models for continuous and binary endpoints. To further support users, we have also developed BayesERbook (<span class="ot">&lt;https://genentech.github.io/BayesERbook/&gt;</span>), a comprehensive online book that documents the workflow with typical examples. This open-source project, based on the Stan ecosystem, aims to expand the use of Bayesian methods in pharma, providing a powerful tool for quantitative decision-making in drug development.</span>
<span id="cb1-566"><a href="#cb1-566" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-567"><a href="#cb1-567" aria-hidden="true" tabindex="-1"></a><span class="fu">### **Adapting to Regulatory Guidance: Covariate Adjustment and R-enabled Submissions**</span></span>
<span id="cb1-568"><a href="#cb1-568" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-569"><a href="#cb1-569" aria-hidden="true" tabindex="-1"></a>**Alex Przybylski**</span>
<span id="cb1-570"><a href="#cb1-570" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-571"><a href="#cb1-571" aria-hidden="true" tabindex="-1"></a>**Data scientist \@ Novartis**</span>
<span id="cb1-572"><a href="#cb1-572" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-573"><a href="#cb1-573" aria-hidden="true" tabindex="-1"></a>FDA guidance released in 2023 advocates for covariate adjustment as a non-controversial means to enhance the efficiency of statistical analyses. This includes specific recommendations featuring recently proposed methods from academic groups, providing an opportunity for sponsors to realize the practical benefits of innovative approaches. However, they also present challenges for trial teams regarding practical implementation. Bridging the gap between academia, regulation and industry adoption is essential.</span>
<span id="cb1-574"><a href="#cb1-574" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-575"><a href="#cb1-575" aria-hidden="true" tabindex="-1"></a>This talk presents a case study from Novartis, where FDA feedback referencing the new guidance prompted a targeted and strategic response. We will discuss how we responded to this feedback, our preparation for future regulatory expectations, and the role of R in enabling change and impact.</span>
<span id="cb1-576"><a href="#cb1-576" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-577"><a href="#cb1-577" aria-hidden="true" tabindex="-1"></a>The case study will highlight lightweight R package solutions ({beeca}) and the work of the ASA-BIOP Covariate Adjustment Working Group ({RobinCar2}). We will discuss the importance of software that is suited for integration with trial analysis workflows in regulated environments and the benefits of collaborating within the open-source community.</span>
<span id="cb1-578"><a href="#cb1-578" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-579"><a href="#cb1-579" aria-hidden="true" tabindex="-1"></a><span class="fu">### **R library validation using Acceptance-Test Driven Development**</span></span>
<span id="cb1-580"><a href="#cb1-580" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-581"><a href="#cb1-581" aria-hidden="true" tabindex="-1"></a>**Brian Repko**</span>
<span id="cb1-582"><a href="#cb1-582" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-583"><a href="#cb1-583" aria-hidden="true" tabindex="-1"></a>Retired (ex-Novartis Biomedical Research Oncology Data Science), Retired (ex-Novartis)</span>
<span id="cb1-584"><a href="#cb1-584" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-585"><a href="#cb1-585" aria-hidden="true" tabindex="-1"></a>Europe/US</span>
<span id="cb1-586"><a href="#cb1-586" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-587"><a href="#cb1-587" aria-hidden="true" tabindex="-1"></a>While unit tests are a key component of a single R package's quality, we need similar ways to test / validate a library of R packages or potentially Shiny applications. This session will walk through frameworks used for Acceptance-Test Driven Development (ATDD) and Behavior Driven Development (BDD) outside of R - cucumber, JBehave, etc. - how they work and their value-add to system quality. In short, tests are written in Quarto markdown, in a "given-when-then" format that is regex-matched against annotated functions that drive the testing and asserting of the system under test. The industry can write tests in plain-language and share those tests and feature code not only amongst themselves but also potentially as part of a validation effort with regulators. Feature code can also make use of packages like {chromote} to drive Shiny applications as well. This is bringing my experience as a contributor to JBehave to R and the pharmaverse.</span>
<span id="cb1-588"><a href="#cb1-588" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-589"><a href="#cb1-589" aria-hidden="true" tabindex="-1"></a><span class="fu">### **WORKSHOP: R Validation Discussion: Metric Repos for Open Quality Assessment**</span></span>
<span id="cb1-590"><a href="#cb1-590" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-591"><a href="#cb1-591" aria-hidden="true" tabindex="-1"></a>**Doug Kelkhoff**</span>
<span id="cb1-592"><a href="#cb1-592" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-593"><a href="#cb1-593" aria-hidden="true" tabindex="-1"></a>Over the past year, the R Validation Hub has been hard at work to build out a Metric Repository - a pre-built database of metrics to support the software validation process. We'd like to invite you to discuss the industry outlook for this open validation database. How do we standardize our compute environments to make metrics useful? What do we do when a package isn't living up to our standards? What can we do to ensure that you can supplement our database with the validation of in-house packages? We'd love to share our answers and hear your thoughts to help guide our work. Come join us and discuss the future of R package validation.</span>
<span id="cb1-594"><a href="#cb1-594" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-595"><a href="#cb1-595" aria-hidden="true" tabindex="-1"></a>Workshop related packages:</span>
<span id="cb1-596"><a href="#cb1-596" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-597"><a href="#cb1-597" aria-hidden="true" tabindex="-1"></a>riskmetric, riskassessment, riskscore</span>
<span id="cb1-598"><a href="#cb1-598" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-599"><a href="#cb1-599" aria-hidden="true" tabindex="-1"></a>Workshop related links:</span>
<span id="cb1-600"><a href="#cb1-600" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-601"><a href="#cb1-601" aria-hidden="true" tabindex="-1"></a><span class="ot">&lt;https://github.com/pharmaR/regulatory-r-repo-wg&gt;</span></span>
<span id="cb1-602"><a href="#cb1-602" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-603"><a href="#cb1-603" aria-hidden="true" tabindex="-1"></a><span class="ot">&lt;https://github.com/pharmaR/val.meter&gt;</span></span>
<span id="cb1-604"><a href="#cb1-604" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-605"><a href="#cb1-605" aria-hidden="true" tabindex="-1"></a><span class="ot">&lt;https://github.com/pharmaR/val.criterion&gt;</span></span>
<span id="cb1-606"><a href="#cb1-606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-607"><a href="#cb1-607" aria-hidden="true" tabindex="-1"></a><span class="fu">### **WORKSHOP: datasetjson - Read and write CDISC Dataset JSON formatted datasets in R and Python**</span></span>
<span id="cb1-608"><a href="#cb1-608" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-609"><a href="#cb1-609" aria-hidden="true" tabindex="-1"></a>Michael Stackhouse Chief Innovation Officer, Atorus Sam Hume Research Data Engineer <span class="sc">\|</span> Open Source <span class="sc">\|</span> Data Exchange Standards, CDSIC Nick Masel Associate Director Innovation Team Lead, Johnson &amp; Johnson Eli Miller Senior Manager, Cloud Solutions, Atorus What? Join us for an engaging workshop designed to introduce Dataset-JSON, a powerful format for sharing datasets. We'll start with an environment setup and explore the motivation behind choosing Dataset-JSON over other formats like Parquet. The session will include a detailed walkthrough of the Dataset-JSON specification, followed by hands-on demonstrations and exercises in both R and Python.</span>
<span id="cb1-610"><a href="#cb1-610" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-611"><a href="#cb1-611" aria-hidden="true" tabindex="-1"></a>Discover how to implement Dataset-JSON in your workflows, learn about upcoming adoption plans, and explore future roadmap and API integrations. This workshop is perfect for data professionals interested in improving dataset interoperability and sharing standards.</span>
<span id="cb1-612"><a href="#cb1-612" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-613"><a href="#cb1-613" aria-hidden="true" tabindex="-1"></a><span class="ot">&lt;https://atorus-research.github.io/datasetjson/&gt;</span></span>
<span id="cb1-614"><a href="#cb1-614" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-615"><a href="#cb1-615" aria-hidden="true" tabindex="-1"></a><span class="ot">&lt;https://atorus-research.github.io/datasetjson_workshop/&gt;</span></span>
<span id="cb1-616"><a href="#cb1-616" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-617"><a href="#cb1-617" aria-hidden="true" tabindex="-1"></a><span class="fu">### **WORKSHOP: SDTM programming in R using {sdtm.oak} package**</span></span>
<span id="cb1-618"><a href="#cb1-618" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-619"><a href="#cb1-619" aria-hidden="true" tabindex="-1"></a>**Rammprasad Ganapathy**</span>
<span id="cb1-620"><a href="#cb1-620" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-621"><a href="#cb1-621" aria-hidden="true" tabindex="-1"></a>Principal Data Scientist</span>
<span id="cb1-622"><a href="#cb1-622" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-623"><a href="#cb1-623" aria-hidden="true" tabindex="-1"></a>The {sdtm.oak} package is an EDC (Electronic Data Capture) and data standard-agnostic solution designed to empower the pharmaceutical programming community to develop CDISC SDTM datasets using R. By leveraging reusable algorithms, {sdtm. oak} offers a modular programming framework that can potentially automate the creation of SDTM datasets based on standard SDTM specifications. In this workshop, we will cover the fundamentals of the V0.1 {sdtm.oak} package and provide detailed guidance for programmers to begin utilizing it effectively.</span>
<span id="cb1-624"><a href="#cb1-624" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-625"><a href="#cb1-625" aria-hidden="true" tabindex="-1"></a>Users will be given access to an R environment for the session. Users do not need to install R or other tools/packages prior to the session.</span>
<span id="cb1-626"><a href="#cb1-626" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-627"><a href="#cb1-627" aria-hidden="true" tabindex="-1"></a>Workshop related link:</span>
<span id="cb1-628"><a href="#cb1-628" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-629"><a href="#cb1-629" aria-hidden="true" tabindex="-1"></a><span class="ot">&lt;https://pharmaverse.github.io/rinpharma-SDTM-workshop/#/title-slide&gt;</span></span>
<span id="cb1-630"><a href="#cb1-630" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-631"><a href="#cb1-631" aria-hidden="true" tabindex="-1"></a><span class="fu">### **WORKSHOP: Python for Clinical Study Report and Submission**</span></span>
<span id="cb1-632"><a href="#cb1-632" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-633"><a href="#cb1-633" aria-hidden="true" tabindex="-1"></a>**Nan Xiao**</span>
<span id="cb1-634"><a href="#cb1-634" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-635"><a href="#cb1-635" aria-hidden="true" tabindex="-1"></a>Statistician at Merck, Merck</span>
<span id="cb1-636"><a href="#cb1-636" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-637"><a href="#cb1-637" aria-hidden="true" tabindex="-1"></a>**Yilong Zhang**</span>
<span id="cb1-638"><a href="#cb1-638" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-639"><a href="#cb1-639" aria-hidden="true" tabindex="-1"></a>Biostatistician at Meta, Meta</span>
<span id="cb1-640"><a href="#cb1-640" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-641"><a href="#cb1-641" aria-hidden="true" tabindex="-1"></a>Open-source programming languages are rapidly transforming drug discovery, research, and development, offering powerful capabilities for study design, data analysis, visualization, and clinical reporting. This workshop introduces practical strategies for using Python to prepare tables, listings, and figures (TLFs) in a clinical study report (CSR) and to assemble submission-ready electronic Common Technical Document (eCTD) packages that include both source code and deliverables.</span>
<span id="cb1-642"><a href="#cb1-642" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-643"><a href="#cb1-643" aria-hidden="true" tabindex="-1"></a>This workshop is designed for clinical programmers, statisticians, and data scientists who are interested in exploring Python as an alternative approach for clinical trial analysis and reporting. Participants will gain hands-on experience with reproducible workflows, clinical data engineering, and end-to-end project management using the modern Python toolchain. By the end of the session, attendees will have a clear roadmap to start a Python project for clinical trial analysis and reporting.</span>
<span id="cb1-644"><a href="#cb1-644" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-645"><a href="#cb1-645" aria-hidden="true" tabindex="-1"></a>The workshop is based on the open source book&nbsp;*Python for Clinical Study Reports and Submission*&nbsp;(<span class="ot">&lt;https://pycsr.org/&gt;</span>) and is organized into four modules:</span>
<span id="cb1-646"><a href="#cb1-646" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-647"><a href="#cb1-647" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>Python environment setup: Use&nbsp;uv&nbsp;to create and manage reproducible Python projects. Develop and collaborate in GitHub Codespaces, Visual Studio Code, or Positron.</span>
<span id="cb1-648"><a href="#cb1-648" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-649"><a href="#cb1-649" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>Python packages for clinical reporting: A guided tour of essential packages such as&nbsp;polars,&nbsp;plotnine, and&nbsp;rtflite, with demonstrations of creating TLFs commonly used in clinical trials.</span>
<span id="cb1-650"><a href="#cb1-650" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-651"><a href="#cb1-651" aria-hidden="true" tabindex="-1"></a><span class="ss">3.  </span>Manage a clinical trial A&amp;R project: Practical project structure, conventions, and execution from data to deliverables.</span>
<span id="cb1-652"><a href="#cb1-652" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-653"><a href="#cb1-653" aria-hidden="true" tabindex="-1"></a><span class="ss">4.  </span>Preparing eCTD submission packages: An example workflow for assembling submission-ready source code and outputs using&nbsp;py-pkglite, aligned with eCTD requirements.</span>
<span id="cb1-654"><a href="#cb1-654" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-655"><a href="#cb1-655" aria-hidden="true" tabindex="-1"></a><span class="ot">&lt;https://pycsr.org/slides/workshop-slides.html#/datasets&gt;</span></span>
<span id="cb1-656"><a href="#cb1-656" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-657"><a href="#cb1-657" aria-hidden="true" tabindex="-1"></a>Publicly available CDISC pilot study data located at the CDISC GitHub repository.</span>
<span id="cb1-658"><a href="#cb1-658" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-659"><a href="#cb1-659" aria-hidden="true" tabindex="-1"></a>The dataset structure follows the CDISC Analysis Data Model (ADAM).</span>
<span id="cb1-660"><a href="#cb1-660" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-661"><a href="#cb1-661" aria-hidden="true" tabindex="-1"></a>Source data: <span class="ot">&lt;https://github.com/elong0527/r4csr/tree/main/data-adam&gt;</span></span>
<span id="cb1-662"><a href="#cb1-662" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-663"><a href="#cb1-663" aria-hidden="true" tabindex="-1"></a>Converted parquet data: <span class="ot">&lt;https://github.com/nanxstats/pycsr/tree/main/data&gt;</span></span>
<span id="cb1-664"><a href="#cb1-664" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-665"><a href="#cb1-665" aria-hidden="true" tabindex="-1"></a>Workshop Slides:</span>
<span id="cb1-666"><a href="#cb1-666" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-667"><a href="#cb1-667" aria-hidden="true" tabindex="-1"></a><span class="ot">&lt;https://pycsr.org/slides/workshop-slides.html#&gt;</span></span>
<span id="cb1-668"><a href="#cb1-668" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-669"><a href="#cb1-669" aria-hidden="true" tabindex="-1"></a><span class="ot">&lt;https://github.com/nanxstats/pycsr&gt;</span></span>
<span id="cb1-670"><a href="#cb1-670" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-671"><a href="#cb1-671" aria-hidden="true" tabindex="-1"></a><span class="fu">### **WORKSHOP: Supercharge your shiny app by offloading computations to a HPC cluster**</span></span>
<span id="cb1-672"><a href="#cb1-672" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-673"><a href="#cb1-673" aria-hidden="true" tabindex="-1"></a>**Michael Mayer**</span>
<span id="cb1-674"><a href="#cb1-674" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-675"><a href="#cb1-675" aria-hidden="true" tabindex="-1"></a>Principal Solution Engineer at Posit , Posit PBC</span>
<span id="cb1-676"><a href="#cb1-676" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-677"><a href="#cb1-677" aria-hidden="true" tabindex="-1"></a>With ever increasing complexity of data and analysis, application developers are tempted to put in serious computations into their shiny applications. Given that those shiny applications typically run on infrastructure that has certain resource limitations or sometimes even shared with other shiny apps, more often than not this leads to crashes affecting the overall stability of the system. As a consequence, either other approaches are pursued, or the approach simplified to the point that good science is prevented from happening.&nbsp;in this workshop you will learn how to interact with a remote HPC cluster straight from your laptop. You will run a shiny app locally and remote submit pieces of code to the HPC cluster. By leveraging a multiple of your locally available compute power for a short period of time, you will reduce&nbsp; time-to-result considerably keeping the app fairly interactive. This approach also can be used to connect applications hosted on a Shiny Hosting platform such as Posit Connect to a HPC cluster.&nbsp;In the second part of the workshop you will be able to discuss with the workshop instructor(s) your own use cases and get insights on how to address those.</span>
<span id="cb1-678"><a href="#cb1-678" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-679"><a href="#cb1-679" aria-hidden="true" tabindex="-1"></a><span class="fu">### **WORKSHOP: Bayesian Survival and Multistate Models using R and Stan**</span></span>
<span id="cb1-680"><a href="#cb1-680" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-681"><a href="#cb1-681" aria-hidden="true" tabindex="-1"></a>**Eric Novik**</span>
<span id="cb1-682"><a href="#cb1-682" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-683"><a href="#cb1-683" aria-hidden="true" tabindex="-1"></a>Founder &amp; CEO \@ Generable, Generable</span>
<span id="cb1-684"><a href="#cb1-684" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-685"><a href="#cb1-685" aria-hidden="true" tabindex="-1"></a>**Jacqueline Buros-Novik**</span>
<span id="cb1-686"><a href="#cb1-686" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-687"><a href="#cb1-687" aria-hidden="true" tabindex="-1"></a>Generable</span>
<span id="cb1-688"><a href="#cb1-688" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-689"><a href="#cb1-689" aria-hidden="true" tabindex="-1"></a>**Juho Timonen**</span>
<span id="cb1-690"><a href="#cb1-690" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-691"><a href="#cb1-691" aria-hidden="true" tabindex="-1"></a>Computational Scientist, Generable</span>
<span id="cb1-692"><a href="#cb1-692" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-693"><a href="#cb1-693" aria-hidden="true" tabindex="-1"></a>Bayesian inference and Stan offer many advantages for analyzing time-to-event data, including incorporating prior knowledge into the model, propagating all sources of uncertainty to produce well-calibrated predictions, and integrating arbitrary utility functions for optimal decision-making, such as patients' preferences for different types of risks. The latter point is particularly relevant in multistate models where people may differ in their preferences towards multiple competing <span class="co">[</span><span class="ot">events.In</span><span class="co">](http://events.In)</span> this workshop, we will briefly introduce Bayesian workflow – the typical steps in Bayesian analysis and basic (single-event) survival models in the Bayesian context. We will then proceed to introduce multistate models where we are tracking multiple event types, such as bleeding and stroke in cardiovascular trials, or stable disease, progressive disease, and death in oncology trials. Time permitting, we will demonstrate how to incorporate the patient’s utility function into a decision analysis.</span>
<span id="cb1-694"><a href="#cb1-694" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-695"><a href="#cb1-695" aria-hidden="true" tabindex="-1"></a>Workshop related link:</span>
<span id="cb1-696"><a href="#cb1-696" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-697"><a href="#cb1-697" aria-hidden="true" tabindex="-1"></a><span class="ot">&lt;https://github.com/generable/bmstate&gt;</span></span>
<span id="cb1-698"><a href="#cb1-698" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-699"><a href="#cb1-699" aria-hidden="true" tabindex="-1"></a><span class="fu">### **WORKSHOP: From Data to Insights: A Hands-On Workshop with {teal} for Clinical Data Exploration**</span></span>
<span id="cb1-700"><a href="#cb1-700" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-701"><a href="#cb1-701" aria-hidden="true" tabindex="-1"></a>**Nina Qi**</span>
<span id="cb1-702"><a href="#cb1-702" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-703"><a href="#cb1-703" aria-hidden="true" tabindex="-1"></a>Principal Data Scientist at Genentech, Roche/Genentech</span>
<span id="cb1-704"><a href="#cb1-704" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-705"><a href="#cb1-705" aria-hidden="true" tabindex="-1"></a>**Dony Unardi**</span>
<span id="cb1-706"><a href="#cb1-706" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-707"><a href="#cb1-707" aria-hidden="true" tabindex="-1"></a>Data Scientist at Genentech, Roche/Genentech</span>
<span id="cb1-708"><a href="#cb1-708" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-709"><a href="#cb1-709" aria-hidden="true" tabindex="-1"></a>{teal} is an innovative open-source R-Shiny framework that has transformed how clinical trial data is analyzed and visualized in recent years. By streamlining the creation of interactive web applications, it enables R programmers and data scientists to deliver insights faster while promoting efficiency, transparency, and reproducibility in data exploration.&nbsp;This hands-on workshop, built on the latest {teal} 1.0 release, will start from the basics and progressively cover practical topics for building {teal} applications. Together, we will explore key features of {teal} and work through step-by-step exercises designed to build confidence and proficiency in {teal} programming. No prior experience with {teal} or attendance at previous workshops is required - all R users are welcome.&nbsp;Designed to deepen participants’ understanding of the {teal} framework, this session will equip attendees with the skills to leverage the {teal} ecosystem to create scalable, reproducible applications that accelerate insight generation in clinical research.</span>
<span id="cb1-710"><a href="#cb1-710" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-711"><a href="#cb1-711" aria-hidden="true" tabindex="-1"></a>Workshop related link:</span>
<span id="cb1-712"><a href="#cb1-712" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-713"><a href="#cb1-713" aria-hidden="true" tabindex="-1"></a><span class="ot">&lt;https://github.com/pharmaverse/tealworkshop-rinpharma2025/tree/main&gt;</span></span>
<span id="cb1-714"><a href="#cb1-714" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-715"><a href="#cb1-715" aria-hidden="true" tabindex="-1"></a><span class="fu"># Presentations</span></span>
<span id="cb1-716"><a href="#cb1-716" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-717"><a href="#cb1-717" aria-hidden="true" tabindex="-1"></a><span class="fu">### \[**Open-Source Culture and Data Strategy in SHIONOGI: A New Value-Creation Model for Pharma**\]</span></span>
<span id="cb1-718"><a href="#cb1-718" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-719"><a href="#cb1-719" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="sc">\[</span>**Yoshitake Kitanishi**<span class="sc">\]</span></span>
<span id="cb1-720"><a href="#cb1-720" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-721"><a href="#cb1-721" aria-hidden="true" tabindex="-1"></a><span class="fu">### \[**Strategically Assisting Statistical programmers To succeed in R (SAS2R)**\]</span></span>
<span id="cb1-722"><a href="#cb1-722" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-723"><a href="#cb1-723" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="sc">\[</span>**KuenHung Lin**<span class="sc">\]</span></span>
<span id="cb1-724"><a href="#cb1-724" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-725"><a href="#cb1-725" aria-hidden="true" tabindex="-1"></a><span class="fu">### \[**Side-by-side by Design: Pharma Data Handling with Merge, Join, Match, and Hash in R**\]</span></span>
<span id="cb1-726"><a href="#cb1-726" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-727"><a href="#cb1-727" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="sc">\[</span>**Yutaka Morioka**<span class="sc">\]</span></span>
<span id="cb1-728"><a href="#cb1-728" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-729"><a href="#cb1-729" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="sc">\[</span>**Yuki Nakagawa**<span class="sc">\]</span></span>
<span id="cb1-730"><a href="#cb1-730" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-731"><a href="#cb1-731" aria-hidden="true" tabindex="-1"></a><span class="fu">### \[**Risk Assessment Deep Dive**\]</span></span>
<span id="cb1-732"><a href="#cb1-732" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-733"><a href="#cb1-733" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="sc">\[</span>**Ryo Nakaya**<span class="sc">\]</span></span>
<span id="cb1-734"><a href="#cb1-734" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-735"><a href="#cb1-735" aria-hidden="true" tabindex="-1"></a><span class="fu">### \[**Leverage template-based automated reporting on DMC materials preparation**\]</span></span>
<span id="cb1-736"><a href="#cb1-736" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-737"><a href="#cb1-737" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="sc">\[</span>**Nina Han**<span class="sc">\]</span></span>
<span id="cb1-738"><a href="#cb1-738" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-739"><a href="#cb1-739" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="sc">\[</span>**Peng Zhang**<span class="sc">\]</span></span>
<span id="cb1-740"><a href="#cb1-740" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-741"><a href="#cb1-741" aria-hidden="true" tabindex="-1"></a><span class="fu">### \[**Dynamic Creation of Kaplan-Meier Plots and Summary Measure Tables for Survival Data with R Shiny**\]</span></span>
<span id="cb1-742"><a href="#cb1-742" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-743"><a href="#cb1-743" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="sc">\[</span>**Takumi Imamura**<span class="sc">\]</span></span>
<span id="cb1-744"><a href="#cb1-744" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-745"><a href="#cb1-745" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="sc">\[</span>**Takahiro Hasegawa**<span class="sc">\]</span></span>
<span id="cb1-746"><a href="#cb1-746" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-747"><a href="#cb1-747" aria-hidden="true" tabindex="-1"></a><span class="fu">### \[**autoslideR: Streamlining slide deck generation for clinical reporting events**\]</span></span>
<span id="cb1-748"><a href="#cb1-748" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-749"><a href="#cb1-749" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="sc">\[</span>**Yolanda Zhou**<span class="sc">\]</span></span>
<span id="cb1-750"><a href="#cb1-750" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-751"><a href="#cb1-751" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="sc">\[</span>**Joe Zhu**<span class="sc">\]</span></span>
<span id="cb1-752"><a href="#cb1-752" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-753"><a href="#cb1-753" aria-hidden="true" tabindex="-1"></a><span class="fu">### \[**From Harmony to Hybrid: Charting a Practical Course for R Adoption in Pharma**\]</span></span>
<span id="cb1-754"><a href="#cb1-754" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-755"><a href="#cb1-755" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="sc">\[</span>**Joe Zhu**<span class="sc">\]</span></span>
<span id="cb1-756"><a href="#cb1-756" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-757"><a href="#cb1-757" aria-hidden="true" tabindex="-1"></a><span class="fu">### \[**Emerging trend of LLM development in R and implementation**\]</span></span>
<span id="cb1-758"><a href="#cb1-758" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-759"><a href="#cb1-759" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="sc">\[</span>**Mia Chen**<span class="sc">\]</span></span>
<span id="cb1-760"><a href="#cb1-760" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-761"><a href="#cb1-761" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="sc">\[</span>**Peng Zhang**<span class="sc">\]</span></span>
<span id="cb1-762"><a href="#cb1-762" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-763"><a href="#cb1-763" aria-hidden="true" tabindex="-1"></a><span class="fu">### \[**An R package to consolidate pretest probability models and guidelines for CAD**\]</span></span>
<span id="cb1-764"><a href="#cb1-764" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-765"><a href="#cb1-765" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="sc">\[</span>**Jeremy Selva**<span class="sc">\]</span></span>
<span id="cb1-766"><a href="#cb1-766" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-767"><a href="#cb1-767" aria-hidden="true" tabindex="-1"></a><span class="fu">### \[**Enhancing Efficiency in e-CRT Creation for PMDA Through R Shiny App Development Using Vibe Coding**\]</span></span>
<span id="cb1-768"><a href="#cb1-768" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-769"><a href="#cb1-769" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="sc">\[</span>**Naoki Yoshida**<span class="sc">\]</span></span>
<span id="cb1-770"><a href="#cb1-770" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-771"><a href="#cb1-771" aria-hidden="true" tabindex="-1"></a><span class="fu">### \[**{meRlin} - context-aware AI assistant for clinical programming**\]</span></span>
<span id="cb1-772"><a href="#cb1-772" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-773"><a href="#cb1-773" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="sc">\[</span>**Steven Brooks**<span class="sc">\]</span></span>
<span id="cb1-774"><a href="#cb1-774" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-775"><a href="#cb1-775" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="sc">\[</span>**Pietro Mascheroni**<span class="sc">\]</span></span>
<span id="cb1-776"><a href="#cb1-776" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-777"><a href="#cb1-777" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="sc">\[</span>**Xiecheng Gu**<span class="sc">\]</span></span>
<span id="cb1-778"><a href="#cb1-778" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-779"><a href="#cb1-779" aria-hidden="true" tabindex="-1"></a><span class="fu">### \[**Improving precision healthcare for under-represented and genetically diverse global populations**\]</span></span>
<span id="cb1-780"><a href="#cb1-780" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-781"><a href="#cb1-781" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="sc">\[</span>**Jimmy Breen**<span class="sc">\]</span></span>
<span id="cb1-782"><a href="#cb1-782" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-783"><a href="#cb1-783" aria-hidden="true" tabindex="-1"></a><span class="fu">### \[**Exploring AI tools in clinical trial data analysis**\]</span></span>
<span id="cb1-784"><a href="#cb1-784" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-785"><a href="#cb1-785" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="sc">\[</span>**Terry Zhang**<span class="sc">\]</span></span>
<span id="cb1-786"><a href="#cb1-786" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-787"><a href="#cb1-787" aria-hidden="true" tabindex="-1"></a><span class="fu">### \[**An R Package cgmguru for Automated Glycemic Event Detection From Continuous Glucose Monitoring Data**\]</span></span>
<span id="cb1-788"><a href="#cb1-788" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-789"><a href="#cb1-789" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="sc">\[</span>**Sang Ho Park**<span class="sc">\]</span></span>
<span id="cb1-790"><a href="#cb1-790" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-791"><a href="#cb1-791" aria-hidden="true" tabindex="-1"></a><span class="fu">### \[**Interactive and Reproducible Reports with Quarto**\]</span></span>
<span id="cb1-792"><a href="#cb1-792" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-793"><a href="#cb1-793" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="sc">\[</span>**Jaspreet Pabla**<span class="sc">\]</span></span>
<span id="cb1-794"><a href="#cb1-794" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-795"><a href="#cb1-795" aria-hidden="true" tabindex="-1"></a><span class="fu">### \[**Using Analysis Results Data using {cards} for PMDA Oncology inqueries**\]</span></span>
<span id="cb1-796"><a href="#cb1-796" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-797"><a href="#cb1-797" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="sc">\[</span>**Shunsuke Goto**<span class="sc">\]</span></span>
<span id="cb1-798"><a href="#cb1-798" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-799"><a href="#cb1-799" aria-hidden="true" tabindex="-1"></a><span class="fu">### \[**Reach for R Low Hanging Fruit for Faster Results**\]</span></span>
<span id="cb1-800"><a href="#cb1-800" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-801"><a href="#cb1-801" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="sc">\[</span>**Sunil Gupta**<span class="sc">\]</span></span>
<span id="cb1-802"><a href="#cb1-802" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-803"><a href="#cb1-803" aria-hidden="true" tabindex="-1"></a><span class="fu">### \[**MedxR Package - Bridging Regulatory Drug Data from the FDA and Health Canada into R**\]</span></span>
<span id="cb1-804"><a href="#cb1-804" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-805"><a href="#cb1-805" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="sc">\[</span>**Renzo Cáceres Rossi**<span class="sc">\]</span></span>
<span id="cb1-806"><a href="#cb1-806" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-807"><a href="#cb1-807" aria-hidden="true" tabindex="-1"></a><span class="fu">### \[**risk.assessr: extending its use in the package validation process**\]</span></span>
<span id="cb1-808"><a href="#cb1-808" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-809"><a href="#cb1-809" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="sc">\[</span>**Hugo Bottois**<span class="sc">\]</span></span>
<span id="cb1-810"><a href="#cb1-810" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-811"><a href="#cb1-811" aria-hidden="true" tabindex="-1"></a><span class="fu">### \[**Code Review for Compliance: Best Practices for Validated R Workflows in Pharma**\]</span></span>
<span id="cb1-812"><a href="#cb1-812" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-813"><a href="#cb1-813" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="sc">\[</span>**Alexandros Kouretsis**<span class="sc">\]</span></span>
<span id="cb1-814"><a href="#cb1-814" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-815"><a href="#cb1-815" aria-hidden="true" tabindex="-1"></a><span class="fu">### \[**A Web-Based R Application for Forecasting Patient Enrollment in Clinical Trials**\]</span></span>
<span id="cb1-816"><a href="#cb1-816" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-817"><a href="#cb1-817" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="sc">\[</span>**Akifumi Okayama**<span class="sc">\]</span></span>
<span id="cb1-818"><a href="#cb1-818" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-819"><a href="#cb1-819" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="sc">\[</span>**Motoki Oe**<span class="sc">\]</span></span>
<span id="cb1-820"><a href="#cb1-820" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-821"><a href="#cb1-821" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="sc">\[</span>**Nobushige Matsuoka**<span class="sc">\]</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© 2025 <a href="https://www.linkedin.com/in/myrta/">Szymon Myrta</a> | <a href="./about.html#rpharma-2025-workshop-certificates">🎓 11 R/Pharma Workshop Certificates</a></p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/myrta/">
      <i class="bi bi-linkedin" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/ACTN3">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="https://orcid.org/0000-0003-1714-6105">
<p>{{ORCID}}</p>
</a>
  </li>  
</ul>
    </div>
  </div>
</footer>




<script src="site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>